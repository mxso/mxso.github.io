<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Dreamsong&#39;s Blog</title>
  
  <subtitle>隐居山林，潜心研究。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://songit.cn/"/>
  <updated>2020-03-18T02:51:00.457Z</updated>
  <id>http://songit.cn/</id>
  
  <author>
    <name>Dreamsong</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Elasticsearch安装踩坑总结</title>
    <link href="http://songit.cn/installElasticsearch/"/>
    <id>http://songit.cn/installElasticsearch/</id>
    <published>2020-03-18T02:25:45.000Z</published>
    <updated>2020-03-18T02:51:00.457Z</updated>
    
    <content type="html"><![CDATA[<p>Elasticsearch安装命令及其问题解决如下:</p><a id="more"></a><p>tar -zxvf elasticsearch.tar.gz</p><p>cd elasticsearch</p><p>vi ./config/elasticsearch.yml</p><p># elasticsearch.yml 文件简单配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">cluster.name: cluster-test  #集群名称，每个节点集群名称一样</div><div class="line"></div><div class="line">node.name: test-1  #节点名称，每个节点设置唯一的名称</div><div class="line"></div><div class="line">path.data: /data/elasticsearch/data  #数据存储路径</div><div class="line"></div><div class="line">path.logs: /data/elasticsearch/logs  #日志文件存放路径</div><div class="line"></div><div class="line">network.host: 0.0.0.0</div><div class="line"></div><div class="line">http.port: 9200</div><div class="line"></div><div class="line">discovery.zen.ping.unicast.hosts: [&quot;192.168.2.211&quot;, &quot;192.168.2.212&quot;]  #节点列表</div><div class="line"></div><div class="line">discovery.zen.minimum_master_nodes: 2  #候选主节点数量</div><div class="line"></div><div class="line">gateway.recover_after_nodes: 1  #集群中只要有1个节点就正常工作</div><div class="line"></div><div class="line">\# 跨域</div><div class="line"></div><div class="line">http.cors.enabled: true</div><div class="line"></div><div class="line">http.cors.allow-origin: &quot;*&quot;</div></pre></td></tr></table></figure><p>./bin/elasticsearch -d</p><p>vim /etc/security/limits.conf #添加以下内容</p><p>* soft nofile 65536</p><p>* hard nofile 65536</p><p>vim /etc/sysctl.conf #添加以下内容</p><p>vm.max_map_count=262144</p><p>sysctl -p</p><p># 添加用户(elasticsearch不能在root用户启动)</p><p>useradd es</p><p>passwd es es</p><p>su es</p><p># head插件 phantomjs-prebuilt问题解决</p><p> npm install phantomjs-prebuilt@2.1.13 –ignore-scripts</p><p># 关闭指定端口的防火墙</p><p>firewall-cmd –permanent –add-port=9200/tcp</p><p>firewall-cmd –permanent –add-port=9300/tcp</p><p>firewall-cmd –reload</p><p># 安装java11</p><p>yum search jdk</p><p>yum install java-11-openjdk.x86_64</p><p>vi /etc/profile</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">\#set java environment</div><div class="line"></div><div class="line">JAVA_HOME=/usr/lib/jvm/jre-11-openjdk-11.0.6.10-1.el7_7.x86_64</div><div class="line"></div><div class="line">PATH=$PATH:$JAVA_HOME/bin</div><div class="line"></div><div class="line">CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</div><div class="line"></div><div class="line">export JAVA_HOME CLASSPATH PATH</div></pre></td></tr></table></figure><p>source /etc/profile</p><p>java -version</p><p># 安装npm</p><p>cd /usr/local/node</p><p>wget <a href="https://npm.taobao.org/mirrors/node/v10.14.1/node-v10.14.1-linux-x64.tar.gz" target="_blank" rel="external">https://npm.taobao.org/mirrors/node/v10.14.1/node-v10.14.1-linux-x64.tar.gz</a></p><p>tar -xvf node-v10.14.1-linux-x64.tar.xz</p><p>mv node-v10.14.1-linux-x64 node</p><p>vim /etc/profile</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">\#set for nodejs </div><div class="line"></div><div class="line">export NODE_HOME=/usr/local/node </div><div class="line"></div><div class="line">export PATH=$NODE_HOME/bin:$PATH</div></pre></td></tr></table></figure><p>source /etc/profile</p><p>node -v</p><p>npm -v</p><p># 不在sudoers</p><p>vi /etc/sudoers</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">\# User privilege specification </div><div class="line"></div><div class="line">root    ALL=(ALL:ALL) ALL </div><div class="line"></div><div class="line">username  ALL=(ALL:ALL) ALL</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Elasticsearch安装命令及其问题解决如下:&lt;/p&gt;
    
    </summary>
    
      <category term="Tech" scheme="http://songit.cn/categories/Tech/"/>
    
    
      <category term="Elasticsearch" scheme="http://songit.cn/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Pandas基本操作</title>
    <link href="http://songit.cn/Pandas-Basic-Operation/"/>
    <id>http://songit.cn/Pandas-Basic-Operation/</id>
    <published>2019-10-23T02:47:47.000Z</published>
    <updated>2019-10-23T02:51:02.163Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Windows常用的一些软件</title>
    <link href="http://songit.cn/softwares/"/>
    <id>http://songit.cn/softwares/</id>
    <published>2019-07-10T07:51:04.000Z</published>
    <updated>2019-07-10T07:55:37.826Z</updated>
    
    <content type="html"><![CDATA[<ol><li>Google</li><li>typora</li><li>VSCode</li><li>Git</li><li>BandZip</li><li>WeChat</li><li>Office</li><li>Python</li><li>JDK</li><li>Idea</li><li>AcrobatXI</li><li>Everything</li><li>Foxmail</li><li>PotPlayer</li><li>SpeedPan</li><li>Notepad++</li><li>坚果云</li><li>有道云笔记</li><li>火绒安全</li><li>必收</li><li>网易云音乐</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;Google&lt;/li&gt;
&lt;li&gt;typora&lt;/li&gt;
&lt;li&gt;VSCode&lt;/li&gt;
&lt;li&gt;Git&lt;/li&gt;
&lt;li&gt;BandZip&lt;/li&gt;
&lt;li&gt;WeChat&lt;/li&gt;
&lt;li&gt;Office&lt;/li&gt;
&lt;li&gt;Python&lt;/li&gt;
&lt;li&gt;JDK&lt;/
      
    
    </summary>
    
      <category term="Tech" scheme="http://songit.cn/categories/Tech/"/>
    
    
      <category term="Win10" scheme="http://songit.cn/tags/Win10/"/>
    
      <category term="软件" scheme="http://songit.cn/tags/%E8%BD%AF%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>不蒜子无法使用的问题</title>
    <link href="http://songit.cn/busuanzi-question/"/>
    <id>http://songit.cn/busuanzi-question/</id>
    <published>2018-12-06T07:59:14.000Z</published>
    <updated>2018-12-06T08:04:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>又是七牛云，我的博客计数器不蒜子也挂了。来访人数又从零开始了。不蒜子官方解释：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">！！！！2018年9月 - 重要提示 ！！！！</div><div class="line">大家好，因七牛强制过期原有的『dn-lbstatics.qbox.me』域名（预计2018年10月初），与客服沟通数次无果，即使我提出为此付费也不行，只能更换域名到『busuanzi.ibruce.info』！因我是最早的一批七牛用户，为七牛至少带来了数百个邀请用户，很痛心，很无奈！</div><div class="line">各位继续使用不蒜子提供的服务，只需把原有的：</div><div class="line">&lt;script async src=&quot;//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt;</div><div class="line">域名改一下即可：</div><div class="line">&lt;script async src=&quot;//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt;</div><div class="line">只需要修改该js域名，其他均未改变。若有疑问，可以加入不蒜子交流QQ群：`419260983`，对您带来的不便，非常抱歉！！！还是那句话，不蒜子不会中断服务！！！！</div></pre></td></tr></table></figure></p><p>路径：<code>\themes\nextnew\layout\_third-party\analytics\busuanzi-counter.swig</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;又是七牛云，我的博客计数器不蒜子也挂了。来访人数又从零开始了。不蒜子官方解释：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;d
      
    
    </summary>
    
      <category term="Tech" scheme="http://songit.cn/categories/Tech/"/>
    
    
      <category term="Busuanzi" scheme="http://songit.cn/tags/Busuanzi/"/>
    
      <category term="Qiniuyun" scheme="http://songit.cn/tags/Qiniuyun/"/>
    
  </entry>
  
  <entry>
    <title>MarkDownPad2注册码</title>
    <link href="http://songit.cn/MarkDownKey/"/>
    <id>http://songit.cn/MarkDownKey/</id>
    <published>2018-12-06T07:19:16.000Z</published>
    <updated>2018-12-06T08:08:28.000Z</updated>
    
    <content type="html"><![CDATA[<p>在<a href="https://www.jianshu.com/p/9e5cd946696d" target="_blank" rel="external">简书网xwch</a>上发现一个MarkDownPad2的注册码，分享一下。<br>邮箱：<code>Soar360@live.com</code><br>授权密钥：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">GBPduHjWfJU1mZqcPM3BikjYKF6xKhlKIys3i1MU2eJHqWGImDHzWdD6xhMNLGVpbP2M5SN6bnxn2kSE8qHqNY5QaaRxmO3YSMHxlv2EYpjdwLcPwfeTG7kUdnhKE0vVy4RidP6Y2wZ0q74f47fzsZo45JE2hfQBFi2O9Jldjp1mW8HUpTtLA2a5/sQytXJUQl/QKO0jUQY4pa5CCx20sV1ClOTZtAGngSOJtIOFXK599sBr5aIEFyH0K7H4BoNMiiDMnxt1rD8Vb/ikJdhGMMQr0R4B+L3nWU97eaVPTRKfWGDE8/eAgKzpGwrQQoDh+nzX1xoVQ8NAuH+s4UcSeQ==</div></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在&lt;a href=&quot;https://www.jianshu.com/p/9e5cd946696d&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;简书网xwch&lt;/a&gt;上发现一个MarkDownPad2的注册码，分享一下。&lt;br&gt;邮箱：&lt;code&gt;Soar3
      
    
    </summary>
    
      <category term="工具分享" scheme="http://songit.cn/categories/%E5%B7%A5%E5%85%B7%E5%88%86%E4%BA%AB/"/>
    
    
      <category term="Share" scheme="http://songit.cn/tags/Share/"/>
    
      <category term="Markdown" scheme="http://songit.cn/tags/Markdown/"/>
    
  </entry>
  
  <entry>
    <title>从七牛云过期域名中下载文件并部署到github</title>
    <link href="http://songit.cn/qiniuyunover/"/>
    <id>http://songit.cn/qiniuyunover/</id>
    <published>2018-12-05T13:35:55.000Z</published>
    <updated>2018-12-06T07:14:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>好久没写博客了，半年多来，折腾论文，实习和工作，突然发现博客里的图片都挂了，这我就不淡定了。</p><img src="/qiniuyunover/whathappened.jpg" title="whathappened"><a id="more"></a><p>找了下原因，原来是七牛云测试域名收回了，马上登陆七牛云账户，What？七牛云空间还下载不了我上传的图片数据，坑啊。查了下资料，有所眉目。参考<a href="https://blog.csdn.net/lkj345/article/details/83382636" target="_blank" rel="external">链接</a></p><p>简单步骤有以下5步（我是在Ubuntu系统下执行的）：</p><ol><li>下载命令行辅助工具<a href="https://developer.qiniu.com/kodo/tools/1300/qrsctl" target="_blank" rel="external">qrsctl</a>,Windows,Linux,Mac版本都有。</li><li>命令行，进入下载目录，输入<code>./qrsctl login &lt;User&gt; &lt;Passwd&gt;</code>登陆七牛云。</li><li>输入<code>./qrsctl buckets</code>得到自己的bucket。</li><li>输入<code>./qrsctl listprefix &lt;BucketName&gt; &#39;&#39;</code>可以一次性得到picture这个bucket中的所有图片名，当然要注意第一行是七牛云自带的一个标志字符串”marker:”。</li><li>输入<code>./qrsctl get &lt;Bucket&gt; &lt;Key&gt; &lt;DestFile&gt;</code>就可以将文件下载到本地。</li></ol><p>将需要的文件下载后，在根目录<code>source</code>文件夹下创建<code>imgs</code>文件夹，将图片放进去，再将博文中的连接填写其地址即可，<code>eg./imgs/xxx.jpg</code>。</p><p>也可以采用相对路径：</p><ul><li><p>设置站点配置_config.yml，<code>post_asset_folder: true</code></p></li><li><p>安装插件<code>npm install hexo-asset-image --save</code></p></li><li><p>新建博文时，会自动创建一个xxx.md和命名为xxx的文件夹，下一步就是把需要的图片放到新创建的那个文件夹里面去。</p></li><li><p>以下两种方式：</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123;% asset_img 博客的图片.jpg 博客的图片的说明 %&#125;</div></pre></td></tr></table></figure></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">![博客的图片的说明](博客的图片.jpg)</div></pre></td></tr></table></figure></li></ul><p>此两种方法除了操作有些区别之外，在图片的显示上也略有不同，第一种的图片信息是会显示出来的，而第二种中括号里面的信息是不会显示的。</p><p>PS:永久链接那里使用了 <code>:title.html</code>是不行的，在 Windows 下创建 <code>xxx.html</code> 的文件夹失败导致 <code>No such file or directory</code>，改为 <code>:title/</code>后使用正常。</p><p>又折腾了一下午……</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;好久没写博客了，半年多来，折腾论文，实习和工作，突然发现博客里的图片都挂了，这我就不淡定了。&lt;/p&gt;
&lt;img src=&quot;/qiniuyunover/whathappened.jpg&quot; title=&quot;whathappened&quot;&gt;
    
    </summary>
    
      <category term="Tech" scheme="http://songit.cn/categories/Tech/"/>
    
    
      <category term="Hexo" scheme="http://songit.cn/tags/Hexo/"/>
    
      <category term="Qiniuyun" scheme="http://songit.cn/tags/Qiniuyun/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu16.04+CUDA9.0+CUDNN7.0+Faster RCNN+Tensorflow1.5</title>
    <link href="http://songit.cn/RunFaster-R-cnn-TF-OnUbuntu/"/>
    <id>http://songit.cn/RunFaster-R-cnn-TF-OnUbuntu/</id>
    <published>2018-03-18T07:45:42.000Z</published>
    <updated>2018-12-05T09:19:08.000Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章主要记录我在电脑上跑一下Faster RCNN的demo.py的艰辛路程。期间出现了无限问题，好在结果终于成功了。<br><a id="more"></a></p><h1 id="Win10-Ubuntu16-04双系统安装"><a href="#Win10-Ubuntu16-04双系统安装" class="headerlink" title="Win10+Ubuntu16.04双系统安装"></a>Win10+Ubuntu16.04双系统安装</h1><p>关于这部分网上有很多教程，这里就不放链接了。<br>简单的流程就是：</p><ol><li>压缩一未分配空间（最好大于50G）</li><li>UltraISO等软件，将Ubuntu系统写入U盘。</li><li>禁用安全启动和快速启动。</li><li>U盘启动并逐步安装，与Win10并存。（执行第一步，系统会自动选择未分配空间。）</li><li>等待安装完成。<br><em>[注]在安装Faster-R-cnn整个过程我安装了两次系统，期间遇到系统进不去系统，没有引导，最后在网上试了好多引导修复的软件都不行，进入PE系统，最后下载了一个某杀毒软件报毒的软件进去直接修复好了，哈哈，一般情况下是不会出现这样的情况的，放心安装吧</em></li></ol><h1 id="安装CUDA-CUDNN"><a href="#安装CUDA-CUDNN" class="headerlink" title="安装CUDA+CUDNN"></a>安装CUDA+CUDNN</h1><h2 id="安装显卡驱动"><a href="#安装显卡驱动" class="headerlink" title="安装显卡驱动"></a>安装显卡驱动</h2><p>先执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo apt-get update</div><div class="line">sudo apt-get upgrade</div></pre></td></tr></table></figure></p><p>在系统设置-&gt;软件更新-&gt;附加驱动里选择Nvidia最新驱动应用安装即可。<br>在终端执行<code>nvidia-smi</code>，确认是否驱动安装。</p><h2 id="安装CUDA"><a href="#安装CUDA" class="headerlink" title="安装CUDA"></a>安装CUDA</h2><p>我安装的是<a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="external">CUDA9.0</a>，Tensorflow最新版已经支持CUDA9.0，下载安装后执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sudo dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64.deb</div><div class="line">sudo apt-key add /var/cuda-repo-&lt;version&gt;/7fa2af80.pub</div><div class="line">sudo apt-get update</div><div class="line">sudo apt-get install cuda</div></pre></td></tr></table></figure></p><p>然后在<code>.bashrc</code>文件里添加环境变量：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">export PATH=/usr/local/cuda/bin$&#123;PATH:+:$&#123;PATH&#125;&#125;</div><div class="line">export LD_LIBRARY_PATH=/usr/local/cuda/lib64$&#123;LD_LIBRARY_PATH:+:$&#123;LD_LIBRARY_PATH&#125;&#125;</div><div class="line">export CUDA_HOME=/usr/local/cuda</div></pre></td></tr></table></figure></p><p>在终端执行<code>source ~/.bashrc</code>即可生效。</p><h2 id="安装CUDNN"><a href="#安装CUDNN" class="headerlink" title="安装CUDNN"></a>安装CUDNN</h2><p>安装<a href="https://developer.nvidia.com/cudnn" target="_blank" rel="external">CUDNN7.0</a> for CUDA9.0，选择Linux版本。下载（下载需要注册）后解压，然后执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sudo cp cuda/include/cudnn.h /usr/local/cuda/include/</div><div class="line">sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64/ -d</div><div class="line">sudo chmod a+r /usr/local/cuda/include/cudnn.h</div><div class="line">sudo chmod a+r /usr/local/cuda/lib64/libcudnn*</div></pre></td></tr></table></figure></p><h1 id="安装Anaconda3"><a href="#安装Anaconda3" class="headerlink" title="安装Anaconda3"></a>安装Anaconda3</h1><p>安装好了Ubuntu16.04（自带python2.7）后，我有下载安装了<a href="https://www.anaconda.com/download/" target="_blank" rel="external">Anaconda3</a>，anaconda指的是一个开源的Python发行版本，其包含了conda、Python等180多个科学包及其依赖项，还包含了大量的科学包，方便实用，建议使用。</p><h1 id="安装Tensorflow"><a href="#安装Tensorflow" class="headerlink" title="安装Tensorflow"></a>安装Tensorflow</h1><h2 id="创建新环境（python-2-7）"><a href="#创建新环境（python-2-7）" class="headerlink" title="创建新环境（python=2.7）"></a>创建新环境（python=2.7）</h2><p><code>conda create -n tensorflow python=2.7</code><br>代码里tensorflow是环境名称，可以自己定义。<br><em>[注]因为执行网上Faster RCNN代码是用python2写的，python2和3不兼容会产生很多错误，建议安装python2.7，我在这里进了很大一个坑，先前安装的是python3.5版本，也把代码2到3过渡了一下，还是会出现很多错误，坑惨我了。</em></p><h2 id="激活tensorflow环境"><a href="#激活tensorflow环境" class="headerlink" title="激活tensorflow环境"></a>激活tensorflow环境</h2><p><code>source activate tensorflow</code></p><h2 id="安装tensorflow"><a href="#安装tensorflow" class="headerlink" title="安装tensorflow"></a>安装tensorflow</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install python-pip python-dev</div><div class="line">pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.5.0-cp27-none-linux_x86_64.whl</div></pre></td></tr></table></figure><p>安装后验证一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">(tensorflow)$ python  </div><div class="line">&gt;&gt;import tensorflow as tf  </div><div class="line">&gt;&gt;a = tf.constant(&apos;Hello, TensorFlow!&apos;)  </div><div class="line">&gt;&gt;sess = tf.Session()  </div><div class="line">&gt;&gt;sess.run(a)</div></pre></td></tr></table></figure></p><h1 id="安装Opencv"><a href="#安装Opencv" class="headerlink" title="安装Opencv"></a>安装Opencv</h1><h2 id="安装系统依赖包"><a href="#安装系统依赖包" class="headerlink" title="安装系统依赖包"></a>安装系统依赖包</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"># 移除先前安装的x264&lt;/h3&gt;</div><div class="line">sudo apt-get remove x264 libx264-dev</div><div class="line"></div><div class="line">#安装依赖项</div><div class="line">sudo apt-get install build-essential checkinstall cmake pkg-config yasm</div><div class="line">sudo apt-get install git gfortran</div><div class="line">sudo apt-get install libjpeg8-dev libjasper-dev libpng12-dev</div><div class="line"></div><div class="line">#  Ubuntu 14.04</div><div class="line">sudo apt-get install libtiff4-dev</div><div class="line">#  Ubuntu 16.04</div><div class="line">sudo apt-get install libtiff5-dev</div><div class="line"></div><div class="line">sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libdc1394-22-dev</div><div class="line">sudo apt-get install libxine2-dev libv4l-dev</div><div class="line">sudo apt-get install libgstreamer0.10-dev libgstreamer-plugins-base0.10-dev</div><div class="line">sudo apt-get install libqt5-dev libgtk2.0-dev libtbb-dev</div><div class="line">sudo apt-get install libatlas-base-dev</div><div class="line">sudo apt-get install libfaac-dev libmp3lame-dev libtheora-dev</div><div class="line">sudo apt-get install libvorbis-dev libxvidcore-dev</div><div class="line">sudo apt-get install libopencore-amrnb-dev libopencore-amrwb-dev</div><div class="line">sudo apt-get install x264 v4l-utils</div><div class="line"></div><div class="line"># 可选依赖项，一般DL都需要</div><div class="line">sudo apt-get install libprotobuf-dev protobuf-compiler</div><div class="line">sudo apt-get install libgoogle-glog-dev libgflags-dev</div><div class="line">sudo apt-get install libgphoto2-dev libeigen3-dev libhdf5-dev doxygen</div></pre></td></tr></table></figure><h2 id="下载Opencv3-4-1和OpenCV-contrib"><a href="#下载Opencv3-4-1和OpenCV-contrib" class="headerlink" title="下载Opencv3.4.1和OpenCV_contrib"></a>下载Opencv3.4.1和OpenCV_contrib</h2><p>在浏览器上直接下载<a href="https://github.com/opencv/opencv/archive/3.4.1.zip" target="_blank" rel="external">Opencv3.4.1</a>和<a href="https://github.com/opencv/opencv_contrib/archive/3.4.1.zip" target="_blank" rel="external">OpenCV_contrib</a>即可。</p><p>执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">cd opencv-3.4.1</div><div class="line">mkdir build</div><div class="line">cd build</div></pre></td></tr></table></figure></p><p>执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D WITH_TBB=ON -D BUILD_NEW_PYTHON_SUPPORT=ON -D WITH_V4L=ON -D WITH_QT=ON -D WITH_OPENMP=ON -D BUILD_TIFF=ON -D BUILD_opencv_java=OFF -D OPENCV_EXTRA_MODULES_PATH=/home/dreamsong/software/opencv_contrib-3.4.1/modules -D WITH_OPENGL=ON ..</div></pre></td></tr></table></figure></p><p>其中文件地址相应修改成你的文件目录即可。<br><code>-D WITH_OPENMP=ON</code>要加上去，否则会出现<code>Makefile:160: recipe for target &#39;all&#39; failed</code>问题。<br>进一步执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">make -j16  #16是线程，我电脑是8核16线程，所以写的16</div><div class="line">sudo make install</div><div class="line">sudo sh -c &apos;echo &quot;/usr/local/lib&quot; &gt;&gt; /etc/ld.so.conf.d/opencv.conf&apos;</div><div class="line">sudo ldconfig</div></pre></td></tr></table></figure></p><p>制作软连接：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /home/dreamsong/software/anaconda3/envs/tensorflow/lib/python2.7/site-packages</div><div class="line">ln -s /usr/local/lib/python2.7/dist-packages/cv2.so cv2.so</div></pre></td></tr></table></figure></p><p>验证：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$python</div><div class="line">&gt;&gt;import cv2</div><div class="line">&gt;&gt;print cv2.__version__</div></pre></td></tr></table></figure></p><h1 id="Faster-R-CNN运行demo-py"><a href="#Faster-R-CNN运行demo-py" class="headerlink" title="Faster R-CNN运行demo.py"></a>Faster R-CNN运行demo.py</h1><p>在这里有两个项目都可以运行：<br><a href="https://github.com/CharlesShang/TFFRCNN" target="_blank" rel="external">TFFRCNN</a>和<a href="https://github.com/smallcorgi/Faster-RCNN_TF" target="_blank" rel="external">Faster-RCNN_TF</a>，我选的是前者，后者操作没有差别。<br>解压后，修改make.sh为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/env bash</div><div class="line">TF_INC=$(python -c &apos;import tensorflow as tf; print(tf.sysconfig.get_include())&apos;)</div><div class="line">echo $TF_INC</div><div class="line"></div><div class="line">TF_LIB=$(python -c &apos;import tensorflow as tf; print(tf.sysconfig.get_lib())&apos;)</div><div class="line"># echo $TF_LIB</div><div class="line"></div><div class="line">CUDA_PATH=/usr/local/cuda/</div><div class="line"></div><div class="line">cd roi_pooling_layer</div><div class="line"></div><div class="line">nvcc -std=c++11 -c -o roi_pooling_op.cu.o roi_pooling_op_gpu.cu.cc \</div><div class="line">-I $TF_INC -D GOOGLE_CUDA=1 -x cu -Xcompiler -fPIC -arch=sm_52</div><div class="line"></div><div class="line">## if you install tf using already-built binary, or gcc version 4.x, uncomment the two lines below</div><div class="line">#g++ -std=c++11 -shared -D_GLIBCXX_USE_CXX11_ABI=0 -o roi_pooling.so roi_pooling_op.cc \</div><div class="line">#roi_pooling_op.cu.o -I $TF_INC -fPIC -lcudart -L $CUDA_PATH/lib64</div><div class="line"></div><div class="line"># for gcc5-built tf</div><div class="line">#g++ -std=c++11 -shared -D_GLIBCXX_USE_CXX11_ABI=1 -o roi_pooling.so roi_pooling_op.cc \</div><div class="line">#roi_pooling_op.cu.o -I $TF_INC -fPIC -lcudart -L $CUDA_PATH/lib64</div><div class="line">g++ -std=c++11 -shared -o roi_pooling.so roi_pooling_op.cc -D_GLIBCXX_USE_CXX11_ABI=0 \</div><div class="line">roi_pooling_op.cu.o -I $TF_INC -L $TF_LIB -ltensorflow_framework -D GOOGLE_CUDA=1 \</div><div class="line">-fPIC $CXXFLAGS -lcudart -L $CUDA_PATH/lib64</div><div class="line">cd ..</div><div class="line"></div><div class="line"></div><div class="line"># add building psroi_pooling layer</div><div class="line">cd psroi_pooling_layer</div><div class="line">nvcc -std=c++11 -c -o psroi_pooling_op.cu.o psroi_pooling_op_gpu.cu.cc \</div><div class="line">-I $TF_INC -D GOOGLE_CUDA=1 -x cu -Xcompiler -fPIC -arch=sm_52</div><div class="line"></div><div class="line">#g++ -std=c++11 -shared -o psroi_pooling.so psroi_pooling_op.cc \</div><div class="line">#psroi_pooling_op.cu.o -I $TF_INC -fPIC -lcudart -L $CUDA_PATH/lib64</div><div class="line">g++ -std=c++11 -shared -o psroi_pooling.so psroi_pooling_op.cc -D_GLIBCXX_USE_CXX11_ABI=0 \</div><div class="line">psroi_pooling_op.cu.o -I $TF_INC -L $TF_LIB -ltensorflow_framework -D GOOGLE_CUDA=1 \</div><div class="line">-fPIC $CXXFLAGS -lcudart -L $CUDA_PATH/lib64</div><div class="line"></div><div class="line">## if you install tf using already-built binary, or gcc version 4.x, uncomment the two lines below</div><div class="line">#g++ -std=c++11 -shared -D_GLIBCXX_USE_CXX11_ABI=0 -o psroi_pooling.so psroi_pooling_op.cc \</div><div class="line">#psroi_pooling_op.cu.o -I $TF_INC -fPIC -lcudart -L $CUDA_PATH/lib64</div><div class="line"></div><div class="line">cd ..</div></pre></td></tr></table></figure></p><p>执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/CharlesShang/TFFRCNN.git</div><div class="line">cd TFFRCNN/lib</div><div class="line">make</div></pre></td></tr></table></figure></p><p><em>[注]</em></p><ol><li>编译过程中 出现nsync_cv.h: No such file or directory，找到相应文件目录下mutex.h文件，把文件全路径填上去即可，我的是<code>/home/xxx/tensorflow/lib/python2.7/site-packages/external/nsync/public/nsync_cv.h</code>，这个问题参考<a href="https://www.cnblogs.com/danpe/p/7825357.html" target="_blank" rel="external">链接</a></li><li>期间还会出现导入模块错误，没有模块就直接pip install 相应模块即可<br>运行Demo<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd $TFFRCNN</div><div class="line">python ./faster_rcnn/demo.py --model model_path</div></pre></td></tr></table></figure></li></ol><p>下载<a href="https://drive.google.com/file/d/0ByuDEGFYmWsbNVF5eExySUtMZmM/view" target="_blank" rel="external">VGG_imagenet.npy</a><br>demo.py的简单流程：<br><img src="/imgs/FasterRCNNdemo.jpg" alt="FasterRCNNdemo"><br>结果如下：<br><img src="/imgs/TFRRCNN_demo_1.png" alt="TFRRCNN_demo_1.png"><br><img src="/imgs/TFRRCNN_demo_2.png" alt="TFRRCNN_demo_2.png"><br><img src="/imgs/TFRRCNN_demo_3.png" alt="TFRRCNN_demo_3.png"><br><img src="/imgs/TFRRCNN_demo_4.png" alt="TFRRCNN_demo_4.png"><br><img src="/imgs/TFRRCNN_demo_5.png" alt="TFRRCNN_demo_5.png"><br><img src="/imgs/TFRRCNN_demo_6.png" alt="TFRRCNN_demo_6.png"><br><img src="/imgs/TFRRCNN_demo_7.png" alt="TFRRCNN_demo_7.png"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇文章主要记录我在电脑上跑一下Faster RCNN的demo.py的艰辛路程。期间出现了无限问题，好在结果终于成功了。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Tech" scheme="http://songit.cn/categories/Tech/"/>
    
    
      <category term="Python" scheme="http://songit.cn/tags/Python/"/>
    
      <category term="CUDA" scheme="http://songit.cn/tags/CUDA/"/>
    
      <category term="Tensorflow" scheme="http://songit.cn/tags/Tensorflow/"/>
    
      <category term="神经网络" scheme="http://songit.cn/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="Linux" scheme="http://songit.cn/tags/Linux/"/>
    
      <category term="Opencv" scheme="http://songit.cn/tags/Opencv/"/>
    
      <category term="RCNN" scheme="http://songit.cn/tags/RCNN/"/>
    
  </entry>
  
  <entry>
    <title>Object-Detection</title>
    <link href="http://songit.cn/Object-Detection/"/>
    <id>http://songit.cn/Object-Detection/</id>
    <published>2018-03-03T09:00:58.000Z</published>
    <updated>2018-03-30T09:09:28.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文转自<a href="https://handong1587.github.io/deep_learning/2015/10/09/object-detection.html" target="_blank" rel="external">handong1587的个人博客</a>，总结的很详细！辛苦了！</p><a id="more"></a><table><thead><tr><th style="text-align:center">Method</th><th style="text-align:center">backbone</th><th style="text-align:center">test size</th><th style="text-align:center">VOC2007</th><th style="text-align:center">VOC2010</th><th style="text-align:center">VOC2012</th><th style="text-align:center">ILSVRC 2013</th><th style="text-align:center">MSCOCO 2015</th><th style="text-align:center">Speed</th></tr></thead><tbody><tr><td style="text-align:center">OverFeat</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">24.3%</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">R-CNN</td><td style="text-align:center">AlexNet</td><td style="text-align:center"></td><td style="text-align:center">58.5%</td><td style="text-align:center">53.7%</td><td style="text-align:center">53.3%</td><td style="text-align:center">31.4%</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">R-CNN</td><td style="text-align:center">VGG16</td><td style="text-align:center"></td><td style="text-align:center">66.0%</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">SPP_net</td><td style="text-align:center">ZF-5</td><td style="text-align:center"></td><td style="text-align:center">54.2%</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">31.84%</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">DeepID-Net</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">64.1%</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">50.3%</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">NoC</td><td style="text-align:center">73.3%</td><td style="text-align:center"></td><td style="text-align:center">68.8%</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">Fast-RCNN</td><td style="text-align:center">VGG16</td><td style="text-align:center"></td><td style="text-align:center">70.0%</td><td style="text-align:center">68.8%</td><td style="text-align:center">68.4%</td><td style="text-align:center"></td><td style="text-align:center">19.7%(@[0.5-0.95]), 35.9%(@0.5)</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">MR-CNN</td><td style="text-align:center">78.2%</td><td style="text-align:center"></td><td style="text-align:center">73.9%</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">Faster-RCNN</td><td style="text-align:center">VGG16</td><td style="text-align:center"></td><td style="text-align:center">78.8%</td><td style="text-align:center"></td><td style="text-align:center">75.9%</td><td style="text-align:center"></td><td style="text-align:center">21.9%(@[0.5-0.95]), 42.7%(@0.5)</td><td style="text-align:center">198ms</td></tr><tr><td style="text-align:center">Faster-RCNN</td><td style="text-align:center">ResNet101</td><td style="text-align:center"></td><td style="text-align:center">85.6%</td><td style="text-align:center"></td><td style="text-align:center">83.8%</td><td style="text-align:center"></td><td style="text-align:center">37.4%(@[0.5-0.95]), 59.0%(@0.5)</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">YOLO</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">63.4%</td><td style="text-align:center"></td><td style="text-align:center">57.9%</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">45 fps</td></tr><tr><td style="text-align:center">YOLO VGG-16</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">66.4%</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">21 fps</td></tr><tr><td style="text-align:center">YOLOv2</td><td style="text-align:center"></td><td style="text-align:center">448x448</td><td style="text-align:center">78.6%</td><td style="text-align:center"></td><td style="text-align:center">73.4%</td><td style="text-align:center"></td><td style="text-align:center">21.6%(@[0.5-0.95]), 44.0%(@0.5)</td><td style="text-align:center">40 fps</td></tr><tr><td style="text-align:center">SSD</td><td style="text-align:center">VGG16</td><td style="text-align:center">300x300</td><td style="text-align:center">77.2%</td><td style="text-align:center"></td><td style="text-align:center">75.8%</td><td style="text-align:center"></td><td style="text-align:center">25.1%(@[0.5-0.95]), 43.1%(@0.5)</td><td style="text-align:center">46 fps</td></tr><tr><td style="text-align:center">SSD</td><td style="text-align:center">VGG16</td><td style="text-align:center">512x512</td><td style="text-align:center">79.8%</td><td style="text-align:center"></td><td style="text-align:center">78.5%</td><td style="text-align:center"></td><td style="text-align:center">28.8%(@[0.5-0.95]), 48.5%(@0.5)</td><td style="text-align:center">19 fps</td></tr><tr><td style="text-align:center">SSD</td><td style="text-align:center">ResNet101</td><td style="text-align:center">300x300</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">28.0%(@[0.5-0.95])</td><td style="text-align:center">16 fps</td></tr><tr><td style="text-align:center">SSD</td><td style="text-align:center">ResNet101</td><td style="text-align:center">512x512</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">31.2%(@[0.5-0.95])</td><td style="text-align:center">8 fps</td></tr><tr><td style="text-align:center">DSSD</td><td style="text-align:center">ResNet101</td><td style="text-align:center">300x300</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">28.0%(@[0.5-0.95])</td><td style="text-align:center">8 fps</td></tr><tr><td style="text-align:center">DSSD</td><td style="text-align:center">ResNet101</td><td style="text-align:center">500x500</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">33.2%(@[0.5-0.95])</td><td style="text-align:center">6 fps</td></tr><tr><td style="text-align:center">ION</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">79.2%</td><td style="text-align:center"></td><td style="text-align:center">76.4%</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">CRAFT</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">75.7%</td><td style="text-align:center"></td><td style="text-align:center">71.3%</td><td style="text-align:center">48.5%</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">OHEM</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">78.9%</td><td style="text-align:center"></td><td style="text-align:center">76.3%</td><td style="text-align:center"></td><td style="text-align:center">25.5%(@[0.5-0.95]), 45.9%(@0.5)</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">R-FCN</td><td style="text-align:center">ResNet50</td><td style="text-align:center"></td><td style="text-align:center">77.4%</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">0.12sec(K40), 0.09sec(TitianX)</td></tr><tr><td style="text-align:center">R-FCN</td><td style="text-align:center">ResNet101</td><td style="text-align:center"></td><td style="text-align:center">79.5%</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">0.17sec(K40), 0.12sec(TitianX)</td></tr><tr><td style="text-align:center">R-FCN(ms train)</td><td style="text-align:center">ResNet101</td><td style="text-align:center"></td><td style="text-align:center">83.6%</td><td style="text-align:center"></td><td style="text-align:center">82.0%</td><td style="text-align:center"></td><td style="text-align:center">31.5%(@[0.5-0.95]), 53.2%(@0.5)</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">PVANet 9.0</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">84.9%</td><td style="text-align:center"></td><td style="text-align:center">84.2%</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">750ms(CPU), 46ms(TitianX)</td></tr><tr><td style="text-align:center">RetinaNet</td><td style="text-align:center">ResNet101-FPN</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">Light-Head R-CNN</td><td style="text-align:center">Xception*</td><td style="text-align:center">800/1200</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">31.5%@[0.5:0.95]</td><td style="text-align:center">95 fps</td></tr><tr><td style="text-align:center">Light-Head R-CNN</td><td style="text-align:center">Xception*</td><td style="text-align:center">700/1100</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">30.7%@[0.5:0.95]</td><td style="text-align:center">102 fps</td></tr></tbody></table><h1 id="Papers"><a href="#Papers" class="headerlink" title="Papers"></a>Papers</h1><p><strong>Deep Neural Networks for Object Detection</strong></p><ul><li>paper: <a href="http://papers.nips.cc/paper/5207-deep-neural-networks-for-object-detection.pdf" target="_blank" rel="external">http://papers.nips.cc/paper/5207-deep-neural-networks-for-object-detection.pdf</a></li></ul><p><strong>OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1312.6229" target="_blank" rel="external">http://arxiv.org/abs/1312.6229</a></li><li>github: <a href="https://github.com/sermanet/OverFeat" target="_blank" rel="external">https://github.com/sermanet/OverFeat</a></li><li>code: <a href="http://cilvr.nyu.edu/doku.php?id=software:overfeat:start" target="_blank" rel="external">http://cilvr.nyu.edu/doku.php?id=software:overfeat:start</a></li></ul><h2 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h2><p><strong>Rich feature hierarchies for accurate object detection and semantic segmentation</strong></p><ul><li>intro: R-CNN</li><li>arxiv: <a href="http://arxiv.org/abs/1311.2524" target="_blank" rel="external">http://arxiv.org/abs/1311.2524</a></li><li>supp: <a href="http://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr-supp.pdf" target="_blank" rel="external">http://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr-supp.pdf</a></li><li>slides: <a href="http://www.image-net.org/challenges/LSVRC/2013/slides/r-cnn-ilsvrc2013-workshop.pdf" target="_blank" rel="external">http://www.image-net.org/challenges/LSVRC/2013/slides/r-cnn-ilsvrc2013-workshop.pdf</a></li><li>slides: <a href="http://www.cs.berkeley.edu/~rbg/slides/rcnn-cvpr14-slides.pdf" target="_blank" rel="external">http://www.cs.berkeley.edu/~rbg/slides/rcnn-cvpr14-slides.pdf</a></li><li>github: <a href="https://github.com/rbgirshick/rcnn" target="_blank" rel="external">https://github.com/rbgirshick/rcnn</a></li><li>notes: <a href="http://zhangliliang.com/2014/07/23/paper-note-rcnn/" target="_blank" rel="external">http://zhangliliang.com/2014/07/23/paper-note-rcnn/</a></li><li>caffe-pr(“Make R-CNN the Caffe detection example”): <a href="https://github.com/BVLC/caffe/pull/482" target="_blank" rel="external">https://github.com/BVLC/caffe/pull/482</a> </li></ul><h2 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h2><p><strong>Fast R-CNN</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1504.08083" target="_blank" rel="external">http://arxiv.org/abs/1504.08083</a></li><li>slides: <a href="http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-detection.pdf" target="_blank" rel="external">http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-detection.pdf</a></li><li>github: <a href="https://github.com/rbgirshick/fast-rcnn" target="_blank" rel="external">https://github.com/rbgirshick/fast-rcnn</a></li><li>github(COCO-branch): <a href="https://github.com/rbgirshick/fast-rcnn/tree/coco" target="_blank" rel="external">https://github.com/rbgirshick/fast-rcnn/tree/coco</a></li><li>webcam demo: <a href="https://github.com/rbgirshick/fast-rcnn/pull/29" target="_blank" rel="external">https://github.com/rbgirshick/fast-rcnn/pull/29</a></li><li>notes: <a href="http://zhangliliang.com/2015/05/17/paper-note-fast-rcnn/" target="_blank" rel="external">http://zhangliliang.com/2015/05/17/paper-note-fast-rcnn/</a></li><li>notes: <a href="http://blog.csdn.net/linj_m/article/details/48930179" target="_blank" rel="external">http://blog.csdn.net/linj_m/article/details/48930179</a></li><li>github(“Fast R-CNN in MXNet”): <a href="https://github.com/precedenceguo/mx-rcnn" target="_blank" rel="external">https://github.com/precedenceguo/mx-rcnn</a></li><li>github: <a href="https://github.com/mahyarnajibi/fast-rcnn-torch" target="_blank" rel="external">https://github.com/mahyarnajibi/fast-rcnn-torch</a></li><li>github: <a href="https://github.com/apple2373/chainer-simple-fast-rnn" target="_blank" rel="external">https://github.com/apple2373/chainer-simple-fast-rnn</a></li><li>github: <a href="https://github.com/zplizzi/tensorflow-fast-rcnn" target="_blank" rel="external">https://github.com/zplizzi/tensorflow-fast-rcnn</a></li></ul><p><strong>A-Fast-RCNN: Hard Positive Generation via Adversary for Object Detection</strong></p><ul><li>intro: CVPR 2017</li><li>arxiv: <a href="https://arxiv.org/abs/1704.03414" target="_blank" rel="external">https://arxiv.org/abs/1704.03414</a></li><li>paper: <a href="http://abhinavsh.info/papers/pdfs/adversarial_object_detection.pdf" target="_blank" rel="external">http://abhinavsh.info/papers/pdfs/adversarial_object_detection.pdf</a></li><li>github(Caffe): <a href="https://github.com/xiaolonw/adversarial-frcnn" target="_blank" rel="external">https://github.com/xiaolonw/adversarial-frcnn</a></li></ul><h2 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h2><p><strong>Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</strong></p><ul><li>intro: NIPS 2015</li><li>arxiv: <a href="http://arxiv.org/abs/1506.01497" target="_blank" rel="external">http://arxiv.org/abs/1506.01497</a></li><li>gitxiv: <a href="http://www.gitxiv.com/posts/8pfpcvefDYn2gSgXk/faster-r-cnn-towards-real-time-object-detection-with-region" target="_blank" rel="external">http://www.gitxiv.com/posts/8pfpcvefDYn2gSgXk/faster-r-cnn-towards-real-time-object-detection-with-region</a></li><li>slides: <a href="http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2016/bil722/slides/w05-FasterR-CNN.pdf" target="_blank" rel="external">http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2016/bil722/slides/w05-FasterR-CNN.pdf</a></li><li>github(official, Matlab): <a href="https://github.com/ShaoqingRen/faster_rcnn" target="_blank" rel="external">https://github.com/ShaoqingRen/faster_rcnn</a></li><li>github: <a href="https://github.com/rbgirshick/py-faster-rcnn" target="_blank" rel="external">https://github.com/rbgirshick/py-faster-rcnn</a></li><li>github(MXNet): <a href="https://github.com/msracver/Deformable-ConvNets/tree/master/faster_rcnn" target="_blank" rel="external">https://github.com/msracver/Deformable-ConvNets/tree/master/faster_rcnn</a></li><li>github: <a href="https://github.com//jwyang/faster-rcnn.pytorch" target="_blank" rel="external">https://github.com//jwyang/faster-rcnn.pytorch</a></li><li>github: <a href="https://github.com/mitmul/chainer-faster-rcnn" target="_blank" rel="external">https://github.com/mitmul/chainer-faster-rcnn</a></li><li>github: <a href="https://github.com/andreaskoepf/faster-rcnn.torch" target="_blank" rel="external">https://github.com/andreaskoepf/faster-rcnn.torch</a></li><li>github: <a href="https://github.com/ruotianluo/Faster-RCNN-Densecap-torch" target="_blank" rel="external">https://github.com/ruotianluo/Faster-RCNN-Densecap-torch</a></li><li>github: <a href="https://github.com/smallcorgi/Faster-RCNN_TF" target="_blank" rel="external">https://github.com/smallcorgi/Faster-RCNN_TF</a></li><li>github: <a href="https://github.com/CharlesShang/TFFRCNN" target="_blank" rel="external">https://github.com/CharlesShang/TFFRCNN</a></li><li>github(C++ demo): <a href="https://github.com/YihangLou/FasterRCNN-Encapsulation-Cplusplus" target="_blank" rel="external">https://github.com/YihangLou/FasterRCNN-Encapsulation-Cplusplus</a></li><li>github: <a href="https://github.com/yhenon/keras-frcnn" target="_blank" rel="external">https://github.com/yhenon/keras-frcnn</a></li><li>github: <a href="https://github.com/Eniac-Xie/faster-rcnn-resnet" target="_blank" rel="external">https://github.com/Eniac-Xie/faster-rcnn-resnet</a></li><li>github(C++): <a href="https://github.com/D-X-Y/caffe-faster-rcnn/tree/dev" target="_blank" rel="external">https://github.com/D-X-Y/caffe-faster-rcnn/tree/dev</a></li></ul><p><strong>R-CNN minus R</strong></p><ul><li>intro: BMVC 2015</li><li>arxiv: <a href="http://arxiv.org/abs/1506.06981" target="_blank" rel="external">http://arxiv.org/abs/1506.06981</a></li></ul><p><strong>Faster R-CNN in MXNet with distributed implementation and data parallelization</strong></p><ul><li>github: <a href="https://github.com/dmlc/mxnet/tree/master/example/rcnn" target="_blank" rel="external">https://github.com/dmlc/mxnet/tree/master/example/rcnn</a></li></ul><p><strong>Contextual Priming and Feedback for Faster R-CNN</strong></p><ul><li>intro: ECCV 2016. Carnegie Mellon University</li><li>paper: <a href="http://abhinavsh.info/context_priming_feedback.pdf" target="_blank" rel="external">http://abhinavsh.info/context_priming_feedback.pdf</a></li><li>poster: <a href="http://www.eccv2016.org/files/posters/P-1A-20.pdf" target="_blank" rel="external">http://www.eccv2016.org/files/posters/P-1A-20.pdf</a></li></ul><p><strong>An Implementation of Faster RCNN with Study for Region Sampling</strong></p><ul><li>intro: Technical Report, 3 pages. CMU</li><li>arxiv: <a href="https://arxiv.org/abs/1702.02138" target="_blank" rel="external">https://arxiv.org/abs/1702.02138</a></li><li>github: <a href="https://github.com/endernewton/tf-faster-rcnn" target="_blank" rel="external">https://github.com/endernewton/tf-faster-rcnn</a></li></ul><p><strong>Interpretable R-CNN</strong></p><ul><li>intro: North Carolina State University &amp; Alibaba</li><li>keywords: AND-OR Graph (AOG)</li><li>arxiv: <a href="https://arxiv.org/abs/1711.05226" target="_blank" rel="external">https://arxiv.org/abs/1711.05226</a></li></ul><h2 id="Light-Head-R-CNN"><a href="#Light-Head-R-CNN" class="headerlink" title="Light-Head R-CNN"></a>Light-Head R-CNN</h2><p><strong>Light-Head R-CNN: In Defense of Two-Stage Object Detector</strong></p><ul><li>intro: Tsinghua University &amp; Megvii Inc</li><li>arxiv: <a href="https://arxiv.org/abs/1711.07264" target="_blank" rel="external">https://arxiv.org/abs/1711.07264</a></li><li>github: <a href="https://github.com/terrychenism/Deformable-ConvNets/blob/master/rfcn/symbols/resnet_v1_101_rfcn_light.py#L784" target="_blank" rel="external">https://github.com/terrychenism/Deformable-ConvNets/blob/master/rfcn/symbols/resnet_v1_101_rfcn_light.py#L784</a></li></ul><h2 id="Cascade-R-CNN"><a href="#Cascade-R-CNN" class="headerlink" title="Cascade R-CNN"></a>Cascade R-CNN</h2><p><strong>Cascade R-CNN: Delving into High Quality Object Detection</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1712.00726" target="_blank" rel="external">https://arxiv.org/abs/1712.00726</a></li><li>github: <a href="https://github.com/zhaoweicai/cascade-rcnn" target="_blank" rel="external">https://github.com/zhaoweicai/cascade-rcnn</a></li></ul><h2 id="MultiBox"><a href="#MultiBox" class="headerlink" title="MultiBox"></a>MultiBox</h2><p><strong>Scalable Object Detection using Deep Neural Networks</strong></p><ul><li>intro: first MultiBox. Train a CNN to predict Region of Interest.</li><li>arxiv: <a href="http://arxiv.org/abs/1312.2249" target="_blank" rel="external">http://arxiv.org/abs/1312.2249</a></li><li>github: <a href="https://github.com/google/multibox" target="_blank" rel="external">https://github.com/google/multibox</a></li><li>blog: <a href="https://research.googleblog.com/2014/12/high-quality-object-detection-at-scale.html" target="_blank" rel="external">https://research.googleblog.com/2014/12/high-quality-object-detection-at-scale.html</a></li></ul><p><strong>Scalable, High-Quality Object Detection</strong></p><ul><li>intro: second MultiBox</li><li>arxiv: <a href="http://arxiv.org/abs/1412.1441" target="_blank" rel="external">http://arxiv.org/abs/1412.1441</a></li><li>github: <a href="https://github.com/google/multibox" target="_blank" rel="external">https://github.com/google/multibox</a></li></ul><h2 id="SPP-Net"><a href="#SPP-Net" class="headerlink" title="SPP-Net"></a>SPP-Net</h2><p><strong>Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition</strong></p><ul><li>intro: ECCV 2014 / TPAMI 2015</li><li>arxiv: <a href="http://arxiv.org/abs/1406.4729" target="_blank" rel="external">http://arxiv.org/abs/1406.4729</a></li><li>github: <a href="https://github.com/ShaoqingRen/SPP_net" target="_blank" rel="external">https://github.com/ShaoqingRen/SPP_net</a></li><li>notes: <a href="http://zhangliliang.com/2014/09/13/paper-note-sppnet/" target="_blank" rel="external">http://zhangliliang.com/2014/09/13/paper-note-sppnet/</a></li></ul><p><strong>DeepID-Net: Deformable Deep Convolutional Neural Networks for Object Detection</strong></p><ul><li>intro: PAMI 2016</li><li>intro: an extension of R-CNN. box pre-training, cascade on region proposals, deformation layers and context representations</li><li>project page: <a href="http://www.ee.cuhk.edu.hk/%CB%9Cwlouyang/projects/imagenetDeepId/index.html" target="_blank" rel="external">http://www.ee.cuhk.edu.hk/%CB%9Cwlouyang/projects/imagenetDeepId/index.html</a></li><li>arxiv: <a href="http://arxiv.org/abs/1412.5661" target="_blank" rel="external">http://arxiv.org/abs/1412.5661</a></li></ul><p><strong>Object Detectors Emerge in Deep Scene CNNs</strong></p><ul><li>intro: ICLR 2015</li><li>arxiv: <a href="http://arxiv.org/abs/1412.6856" target="_blank" rel="external">http://arxiv.org/abs/1412.6856</a></li><li>paper: <a href="https://www.robots.ox.ac.uk/~vgg/rg/papers/zhou_iclr15.pdf" target="_blank" rel="external">https://www.robots.ox.ac.uk/~vgg/rg/papers/zhou_iclr15.pdf</a></li><li>paper: <a href="https://people.csail.mit.edu/khosla/papers/iclr2015_zhou.pdf" target="_blank" rel="external">https://people.csail.mit.edu/khosla/papers/iclr2015_zhou.pdf</a></li><li>slides: <a href="http://places.csail.mit.edu/slide_iclr2015.pdf" target="_blank" rel="external">http://places.csail.mit.edu/slide_iclr2015.pdf</a></li></ul><p><strong>segDeepM: Exploiting Segmentation and Context in Deep Neural Networks for Object Detection</strong></p><ul><li>intro: CVPR 2015</li><li>project(code+data): <a href="https://www.cs.toronto.edu/~yukun/segdeepm.html" target="_blank" rel="external">https://www.cs.toronto.edu/~yukun/segdeepm.html</a></li><li>arxiv: <a href="https://arxiv.org/abs/1502.04275" target="_blank" rel="external">https://arxiv.org/abs/1502.04275</a></li><li>github: <a href="https://github.com/YknZhu/segDeepM" target="_blank" rel="external">https://github.com/YknZhu/segDeepM</a></li></ul><p><strong>Object Detection Networks on Convolutional Feature Maps</strong></p><ul><li>intro: TPAMI 2015</li><li>keywords: NoC</li><li>arxiv: <a href="http://arxiv.org/abs/1504.06066" target="_blank" rel="external">http://arxiv.org/abs/1504.06066</a></li></ul><p><strong>Improving Object Detection with Deep Convolutional Networks via Bayesian Optimization and Structured Prediction</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1504.03293" target="_blank" rel="external">http://arxiv.org/abs/1504.03293</a></li><li>slides: <a href="http://www.ytzhang.net/files/publications/2015-cvpr-det-slides.pdf" target="_blank" rel="external">http://www.ytzhang.net/files/publications/2015-cvpr-det-slides.pdf</a></li><li>github: <a href="https://github.com/YutingZhang/fgs-obj" target="_blank" rel="external">https://github.com/YutingZhang/fgs-obj</a></li></ul><p><strong>DeepBox: Learning Objectness with Convolutional Networks</strong></p><ul><li>keywords: DeepBox</li><li>arxiv: <a href="http://arxiv.org/abs/1505.02146" target="_blank" rel="external">http://arxiv.org/abs/1505.02146</a></li><li>github: <a href="https://github.com/weichengkuo/DeepBox" target="_blank" rel="external">https://github.com/weichengkuo/DeepBox</a></li></ul><h2 id="MR-CNN"><a href="#MR-CNN" class="headerlink" title="MR-CNN"></a>MR-CNN</h2><p><strong>Object detection via a multi-region &amp; semantic segmentation-aware CNN model</strong></p><ul><li>intro: ICCV 2015. MR-CNN</li><li>arxiv: <a href="http://arxiv.org/abs/1505.01749" target="_blank" rel="external">http://arxiv.org/abs/1505.01749</a></li><li>github: <a href="https://github.com/gidariss/mrcnn-object-detection" target="_blank" rel="external">https://github.com/gidariss/mrcnn-object-detection</a></li><li>notes: <a href="http://zhangliliang.com/2015/05/17/paper-note-ms-cnn/" target="_blank" rel="external">http://zhangliliang.com/2015/05/17/paper-note-ms-cnn/</a></li><li>notes: <a href="http://blog.cvmarcher.com/posts/2015/05/17/multi-region-semantic-segmentation-aware-cnn/" target="_blank" rel="external">http://blog.cvmarcher.com/posts/2015/05/17/multi-region-semantic-segmentation-aware-cnn/</a></li></ul><h2 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h2><p><strong>You Only Look Once: Unified, Real-Time Object Detection</strong></p><p><img src="https://camo.githubusercontent.com/e69d4118b20a42de4e23b9549f9a6ec6dbbb0814/687474703a2f2f706a7265646469652e636f6d2f6d656469612f66696c65732f6461726b6e65742d626c61636b2d736d616c6c2e706e67" alt=""></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1506.02640" target="_blank" rel="external">http://arxiv.org/abs/1506.02640</a></li><li>code: <a href="http://pjreddie.com/darknet/yolo/" target="_blank" rel="external">http://pjreddie.com/darknet/yolo/</a></li><li>github: <a href="https://github.com/pjreddie/darknet" target="_blank" rel="external">https://github.com/pjreddie/darknet</a></li><li>blog: <a href="https://pjreddie.com/publications/yolo/" target="_blank" rel="external">https://pjreddie.com/publications/yolo/</a></li><li>slides: <a href="https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&amp;loop=false&amp;delayms=3000&amp;slide=id.p" target="_blank" rel="external">https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&amp;loop=false&amp;delayms=3000&amp;slide=id.p</a></li><li>reddit: <a href="https://www.reddit.com/r/MachineLearning/comments/3a3m0o/realtime_object_detection_with_yolo/" target="_blank" rel="external">https://www.reddit.com/r/MachineLearning/comments/3a3m0o/realtime_object_detection_with_yolo/</a></li><li>github: <a href="https://github.com/gliese581gg/YOLO_tensorflow" target="_blank" rel="external">https://github.com/gliese581gg/YOLO_tensorflow</a></li><li>github: <a href="https://github.com/xingwangsfu/caffe-yolo" target="_blank" rel="external">https://github.com/xingwangsfu/caffe-yolo</a></li><li>github: <a href="https://github.com/frankzhangrui/Darknet-Yolo" target="_blank" rel="external">https://github.com/frankzhangrui/Darknet-Yolo</a></li><li>github: <a href="https://github.com/BriSkyHekun/py-darknet-yolo" target="_blank" rel="external">https://github.com/BriSkyHekun/py-darknet-yolo</a></li><li>github: <a href="https://github.com/tommy-qichang/yolo.torch" target="_blank" rel="external">https://github.com/tommy-qichang/yolo.torch</a></li><li>github: <a href="https://github.com/frischzenger/yolo-windows" target="_blank" rel="external">https://github.com/frischzenger/yolo-windows</a></li><li>github: <a href="https://github.com/AlexeyAB/yolo-windows" target="_blank" rel="external">https://github.com/AlexeyAB/yolo-windows</a></li><li>github: <a href="https://github.com/nilboy/tensorflow-yolo" target="_blank" rel="external">https://github.com/nilboy/tensorflow-yolo</a></li></ul><p><strong>darkflow - translate darknet to tensorflow. Load trained weights, retrain/fine-tune them using tensorflow, export constant graph def to C++</strong></p><ul><li>blog: <a href="https://thtrieu.github.io/notes/yolo-tensorflow-graph-buffer-cpp" target="_blank" rel="external">https://thtrieu.github.io/notes/yolo-tensorflow-graph-buffer-cpp</a></li><li>github: <a href="https://github.com/thtrieu/darkflow" target="_blank" rel="external">https://github.com/thtrieu/darkflow</a></li></ul><p><strong>Start Training YOLO with Our Own Data</strong></p><p><img src="http://guanghan.info/blog/en/wp-content/uploads/2015/12/images-40.jpg" alt=""></p><ul><li>intro: train with customized data and class numbers/labels. Linux / Windows version for darknet.</li><li>blog: <a href="http://guanghan.info/blog/en/my-works/train-yolo/" target="_blank" rel="external">http://guanghan.info/blog/en/my-works/train-yolo/</a></li><li>github: <a href="https://github.com/Guanghan/darknet" target="_blank" rel="external">https://github.com/Guanghan/darknet</a></li></ul><p><strong>YOLO: Core ML versus MPSNNGraph</strong></p><ul><li>intro: Tiny YOLO for iOS implemented using CoreML but also using the new MPS graph API.</li><li>blog: <a href="http://machinethink.net/blog/yolo-coreml-versus-mps-graph/" target="_blank" rel="external">http://machinethink.net/blog/yolo-coreml-versus-mps-graph/</a></li><li>github: <a href="https://github.com/hollance/YOLO-CoreML-MPSNNGraph" target="_blank" rel="external">https://github.com/hollance/YOLO-CoreML-MPSNNGraph</a></li></ul><p><strong>TensorFlow YOLO object detection on Android</strong></p><ul><li>intro: Real-time object detection on Android using the YOLO network with TensorFlow</li><li>github: <a href="https://github.com/natanielruiz/android-yolo" target="_blank" rel="external">https://github.com/natanielruiz/android-yolo</a></li></ul><p><strong>Computer Vision in iOS – Object Detection</strong></p><ul><li>blog: <a href="https://sriraghu.com/2017/07/12/computer-vision-in-ios-object-detection/" target="_blank" rel="external">https://sriraghu.com/2017/07/12/computer-vision-in-ios-object-detection/</a></li><li>github:<a href="https://github.com/r4ghu/iOS-CoreML-Yolo" target="_blank" rel="external">https://github.com/r4ghu/iOS-CoreML-Yolo</a></li></ul><h2 id="YOLOv2"><a href="#YOLOv2" class="headerlink" title="YOLOv2"></a>YOLOv2</h2><p><strong>YOLO9000: Better, Faster, Stronger</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1612.08242" target="_blank" rel="external">https://arxiv.org/abs/1612.08242</a></li><li>code: <a href="http://pjreddie.com/yolo9000/" target="_blank" rel="external">http://pjreddie.com/yolo9000/</a></li><li>github(Chainer): <a href="https://github.com/leetenki/YOLOv2" target="_blank" rel="external">https://github.com/leetenki/YOLOv2</a></li><li>github(Keras): <a href="https://github.com/allanzelener/YAD2K" target="_blank" rel="external">https://github.com/allanzelener/YAD2K</a></li><li>github(PyTorch): <a href="https://github.com/longcw/yolo2-pytorch" target="_blank" rel="external">https://github.com/longcw/yolo2-pytorch</a></li><li>github(Tensorflow): <a href="https://github.com/hizhangp/yolo_tensorflow" target="_blank" rel="external">https://github.com/hizhangp/yolo_tensorflow</a></li><li>github(Windows): <a href="https://github.com/AlexeyAB/darknet" target="_blank" rel="external">https://github.com/AlexeyAB/darknet</a></li><li>github: <a href="https://github.com/choasUp/caffe-yolo9000" target="_blank" rel="external">https://github.com/choasUp/caffe-yolo9000</a></li><li>github: <a href="https://github.com/philipperemy/yolo-9000" target="_blank" rel="external">https://github.com/philipperemy/yolo-9000</a></li></ul><p><strong>darknet_scripts</strong></p><ul><li>intro: Auxilary scripts to work with (YOLO) darknet deep learning famework. AKA -&gt; How to generate YOLO anchors?</li><li>github: <a href="https://github.com/Jumabek/darknet_scripts" target="_blank" rel="external">https://github.com/Jumabek/darknet_scripts</a></li></ul><p><strong>Yolo_mark: GUI for marking bounded boxes of objects in images for training Yolo v2</strong></p><ul><li>github: <a href="https://github.com/AlexeyAB/Yolo_mark" target="_blank" rel="external">https://github.com/AlexeyAB/Yolo_mark</a></li></ul><p><strong>LightNet: Bringing pjreddie’s DarkNet out of the shadows</strong></p><p><a href="https://github.com//explosion/lightnet" target="_blank" rel="external">https://github.com//explosion/lightnet</a></p><p><strong>YOLO v2 Bounding Box Tool</strong></p><ul><li>intro: Bounding box labeler tool to generate the training data in the format YOLO v2 requires.</li><li>github: <a href="https://github.com/Cartucho/yolo-boundingbox-labeler-GUI" target="_blank" rel="external">https://github.com/Cartucho/yolo-boundingbox-labeler-GUI</a></li></ul><h1 id="YOLOv3"><a href="#YOLOv3" class="headerlink" title="YOLOv3"></a>YOLOv3</h1><p><strong>YOLOv3: An Incremental Improvement</strong></p><ul><li>project page: <a href="https://pjreddie.com/darknet/yolo/" target="_blank" rel="external">https://pjreddie.com/darknet/yolo/</a></li><li>paper: <a href="https://pjreddie.com/media/files/papers/YOLOv3.pdf" target="_blank" rel="external">https://pjreddie.com/media/files/papers/YOLOv3.pdf</a></li></ul><hr><p><strong>AttentionNet: Aggregating Weak Directions for Accurate Object Detection</strong></p><ul><li>intro: ICCV 2015</li><li>intro: state-of-the-art performance of 65% (AP) on PASCAL VOC 2007/2012 human detection task</li><li>arxiv: <a href="http://arxiv.org/abs/1506.07704" target="_blank" rel="external">http://arxiv.org/abs/1506.07704</a></li><li>slides: <a href="https://www.robots.ox.ac.uk/~vgg/rg/slides/AttentionNet.pdf" target="_blank" rel="external">https://www.robots.ox.ac.uk/~vgg/rg/slides/AttentionNet.pdf</a></li><li>slides: <a href="http://image-net.org/challenges/talks/lunit-kaist-slide.pdf" target="_blank" rel="external">http://image-net.org/challenges/talks/lunit-kaist-slide.pdf</a></li></ul><h2 id="DenseBox"><a href="#DenseBox" class="headerlink" title="DenseBox"></a>DenseBox</h2><p><strong>DenseBox: Unifying Landmark Localization with End to End Object Detection</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1509.04874" target="_blank" rel="external">http://arxiv.org/abs/1509.04874</a></li><li>demo: <a href="http://pan.baidu.com/s/1mgoWWsS" target="_blank" rel="external">http://pan.baidu.com/s/1mgoWWsS</a></li><li>KITTI result: <a href="http://www.cvlibs.net/datasets/kitti/eval_object.php" target="_blank" rel="external">http://www.cvlibs.net/datasets/kitti/eval_object.php</a></li></ul><h2 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h2><p><strong>SSD: Single Shot MultiBox Detector</strong></p><p><img src="https://camo.githubusercontent.com/ad9b147ed3a5f48ffb7c3540711c15aa04ce49c6/687474703a2f2f7777772e63732e756e632e6564752f7e776c69752f7061706572732f7373642e706e67" alt=""></p><ul><li>intro: ECCV 2016 Oral</li><li>arxiv: <a href="http://arxiv.org/abs/1512.02325" target="_blank" rel="external">http://arxiv.org/abs/1512.02325</a></li><li>paper: <a href="http://www.cs.unc.edu/~wliu/papers/ssd.pdf" target="_blank" rel="external">http://www.cs.unc.edu/~wliu/papers/ssd.pdf</a></li><li>slides: <a href="http://www.cs.unc.edu/%7Ewliu/papers/ssd_eccv2016_slide.pdf" target="_blank" rel="external">http://www.cs.unc.edu/%7Ewliu/papers/ssd_eccv2016_slide.pdf</a></li><li>github(Official): <a href="https://github.com/weiliu89/caffe/tree/ssd" target="_blank" rel="external">https://github.com/weiliu89/caffe/tree/ssd</a></li><li>video: <a href="http://weibo.com/p/2304447a2326da963254c963c97fb05dd3a973" target="_blank" rel="external">http://weibo.com/p/2304447a2326da963254c963c97fb05dd3a973</a></li><li>github: <a href="https://github.com/zhreshold/mxnet-ssd" target="_blank" rel="external">https://github.com/zhreshold/mxnet-ssd</a></li><li>github: <a href="https://github.com/zhreshold/mxnet-ssd.cpp" target="_blank" rel="external">https://github.com/zhreshold/mxnet-ssd.cpp</a></li><li>github: <a href="https://github.com/rykov8/ssd_keras" target="_blank" rel="external">https://github.com/rykov8/ssd_keras</a></li><li>github: <a href="https://github.com/balancap/SSD-Tensorflow" target="_blank" rel="external">https://github.com/balancap/SSD-Tensorflow</a></li><li>github: <a href="https://github.com/amdegroot/ssd.pytorch" target="_blank" rel="external">https://github.com/amdegroot/ssd.pytorch</a></li><li>github(Caffe): <a href="https://github.com/chuanqi305/MobileNet-SSD" target="_blank" rel="external">https://github.com/chuanqi305/MobileNet-SSD</a></li></ul><p><strong>What’s the diffience in performance between this new code you pushed and the previous code? #327</strong></p><p><a href="https://github.com/weiliu89/caffe/issues/327" target="_blank" rel="external">https://github.com/weiliu89/caffe/issues/327</a></p><h2 id="DSSD"><a href="#DSSD" class="headerlink" title="DSSD"></a>DSSD</h2><p><strong>DSSD : Deconvolutional Single Shot Detector</strong></p><ul><li>intro: UNC Chapel Hill &amp; Amazon Inc</li><li>arxiv: <a href="https://arxiv.org/abs/1701.06659" target="_blank" rel="external">https://arxiv.org/abs/1701.06659</a></li><li>github: <a href="https://github.com/chengyangfu/caffe/tree/dssd" target="_blank" rel="external">https://github.com/chengyangfu/caffe/tree/dssd</a></li><li>github: <a href="https://github.com/MTCloudVision/mxnet-dssd" target="_blank" rel="external">https://github.com/MTCloudVision/mxnet-dssd</a></li><li>demo: <a href="http://120.52.72.53/www.cs.unc.edu/c3pr90ntc0td/~cyfu/dssd_lalaland.mp4" target="_blank" rel="external">http://120.52.72.53/www.cs.unc.edu/c3pr90ntc0td/~cyfu/dssd_lalaland.mp4</a></li></ul><p><strong>Enhancement of SSD by concatenating feature maps for object detection</strong></p><ul><li>intro: rainbow SSD (R-SSD)</li><li>arxiv: <a href="https://arxiv.org/abs/1705.09587" target="_blank" rel="external">https://arxiv.org/abs/1705.09587</a></li></ul><p><strong>Context-aware Single-Shot Detector</strong></p><ul><li>keywords: CSSD, DiCSSD, DeCSSD, effective receptive fields (ERFs),  theoretical receptive fields (TRFs)</li><li>arxiv: <a href="https://arxiv.org/abs/1707.08682" target="_blank" rel="external">https://arxiv.org/abs/1707.08682</a></li></ul><p><strong>Feature-Fused SSD: Fast Detection for Small Objects</strong></p><p><a href="https://arxiv.org/abs/1709.05054" target="_blank" rel="external">https://arxiv.org/abs/1709.05054</a></p><h2 id="FSSD"><a href="#FSSD" class="headerlink" title="FSSD"></a>FSSD</h2><p><strong>FSSD: Feature Fusion Single Shot Multibox Detector</strong></p><p><a href="https://arxiv.org/abs/1712.00960" target="_blank" rel="external">https://arxiv.org/abs/1712.00960</a></p><p><strong>Weaving Multi-scale Context for Single Shot Detector</strong></p><ul><li>intro: WeaveNet</li><li>keywords: fuse multi-scale information</li><li>arxiv: <a href="https://arxiv.org/abs/1712.03149" target="_blank" rel="external">https://arxiv.org/abs/1712.03149</a></li></ul><h2 id="ESSD"><a href="#ESSD" class="headerlink" title="ESSD"></a>ESSD</h2><p><strong>Extend the shallow part of Single Shot MultiBox Detector via Convolutional Neural Network</strong></p><p><a href="https://arxiv.org/abs/1801.05918" target="_blank" rel="external">https://arxiv.org/abs/1801.05918</a></p><p><strong>Tiny SSD: A Tiny Single-shot Detection Deep Convolutional Neural Network for Real-time Embedded Object Detection</strong></p><p><a href="https://arxiv.org/abs/1802.06488" target="_blank" rel="external">https://arxiv.org/abs/1802.06488</a></p><h2 id="Inside-Outside-Net-ION"><a href="#Inside-Outside-Net-ION" class="headerlink" title="Inside-Outside Net (ION)"></a>Inside-Outside Net (ION)</h2><p><strong>Inside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks</strong></p><ul><li>intro: “0.8s per image on a Titan X GPU (excluding proposal generation) without two-stage bounding-box regression<br>and 1.15s per image with it”.</li><li>arxiv: <a href="http://arxiv.org/abs/1512.04143" target="_blank" rel="external">http://arxiv.org/abs/1512.04143</a></li><li>slides: <a href="http://www.seanbell.ca/tmp/ion-coco-talk-bell2015.pdf" target="_blank" rel="external">http://www.seanbell.ca/tmp/ion-coco-talk-bell2015.pdf</a></li><li>coco-leaderboard: <a href="http://mscoco.org/dataset/#detections-leaderboard" target="_blank" rel="external">http://mscoco.org/dataset/#detections-leaderboard</a></li></ul><p><strong>Adaptive Object Detection Using Adjacency and Zoom Prediction</strong></p><ul><li>intro: CVPR 2016. AZ-Net</li><li>arxiv: <a href="http://arxiv.org/abs/1512.07711" target="_blank" rel="external">http://arxiv.org/abs/1512.07711</a></li><li>github: <a href="https://github.com/luyongxi/az-net" target="_blank" rel="external">https://github.com/luyongxi/az-net</a></li><li>youtube: <a href="https://www.youtube.com/watch?v=YmFtuNwxaNM" target="_blank" rel="external">https://www.youtube.com/watch?v=YmFtuNwxaNM</a></li></ul><p><strong>G-CNN: an Iterative Grid Based Object Detector</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1512.07729" target="_blank" rel="external">http://arxiv.org/abs/1512.07729</a></li></ul><p><strong>Factors in Finetuning Deep Model for object detection</strong></p><p><strong>Factors in Finetuning Deep Model for Object Detection with Long-tail Distribution</strong></p><ul><li>intro: CVPR 2016.rank 3rd for provided data and 2nd for external data on ILSVRC 2015 object detection</li><li>project page: <a href="http://www.ee.cuhk.edu.hk/~wlouyang/projects/ImageNetFactors/CVPR16.html" target="_blank" rel="external">http://www.ee.cuhk.edu.hk/~wlouyang/projects/ImageNetFactors/CVPR16.html</a></li><li>arxiv: <a href="http://arxiv.org/abs/1601.05150" target="_blank" rel="external">http://arxiv.org/abs/1601.05150</a></li></ul><p><strong>We don’t need no bounding-boxes: Training object class detectors using only human verification</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1602.08405" target="_blank" rel="external">http://arxiv.org/abs/1602.08405</a></li></ul><p><strong>HyperNet: Towards Accurate Region Proposal Generation and Joint Object Detection</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1604.00600" target="_blank" rel="external">http://arxiv.org/abs/1604.00600</a></li></ul><p><strong>A MultiPath Network for Object Detection</strong></p><ul><li>intro: BMVC 2016. Facebook AI Research (FAIR)</li><li>arxiv: <a href="http://arxiv.org/abs/1604.02135" target="_blank" rel="external">http://arxiv.org/abs/1604.02135</a></li><li>github: <a href="https://github.com/facebookresearch/multipathnet" target="_blank" rel="external">https://github.com/facebookresearch/multipathnet</a></li></ul><h2 id="CRAFT"><a href="#CRAFT" class="headerlink" title="CRAFT"></a>CRAFT</h2><p><strong>CRAFT Objects from Images</strong></p><ul><li>intro: CVPR 2016. Cascade Region-proposal-network And FasT-rcnn. an extension of Faster R-CNN</li><li>project page: <a href="http://byangderek.github.io/projects/craft.html" target="_blank" rel="external">http://byangderek.github.io/projects/craft.html</a></li><li>arxiv: <a href="https://arxiv.org/abs/1604.03239" target="_blank" rel="external">https://arxiv.org/abs/1604.03239</a></li><li>paper: <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Yang_CRAFT_Objects_From_CVPR_2016_paper.pdf" target="_blank" rel="external">http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Yang_CRAFT_Objects_From_CVPR_2016_paper.pdf</a></li><li>github: <a href="https://github.com/byangderek/CRAFT" target="_blank" rel="external">https://github.com/byangderek/CRAFT</a></li></ul><h2 id="OHEM"><a href="#OHEM" class="headerlink" title="OHEM"></a>OHEM</h2><p><strong>Training Region-based Object Detectors with Online Hard Example Mining</strong></p><ul><li>intro: CVPR 2016 Oral. Online hard example mining (OHEM)</li><li>arxiv: <a href="http://arxiv.org/abs/1604.03540" target="_blank" rel="external">http://arxiv.org/abs/1604.03540</a></li><li>paper: <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Shrivastava_Training_Region-Based_Object_CVPR_2016_paper.pdf" target="_blank" rel="external">http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Shrivastava_Training_Region-Based_Object_CVPR_2016_paper.pdf</a></li><li>github(Official): <a href="https://github.com/abhi2610/ohem" target="_blank" rel="external">https://github.com/abhi2610/ohem</a></li><li>author page: <a href="http://abhinav-shrivastava.info/" target="_blank" rel="external">http://abhinav-shrivastava.info/</a></li></ul><p><strong>S-OHEM: Stratified Online Hard Example Mining for Object Detection</strong></p><p><a href="https://arxiv.org/abs/1705.02233" target="_blank" rel="external">https://arxiv.org/abs/1705.02233</a></p><hr><p><strong>Exploit All the Layers: Fast and Accurate CNN Object Detector with Scale Dependent Pooling and Cascaded Rejection Classifiers</strong></p><ul><li>intro: CVPR 2016</li><li>keywords: scale-dependent pooling  (SDP), cascaded rejection classifiers (CRC)</li><li>paper: <a href="http://www-personal.umich.edu/~wgchoi/SDP-CRC_camready.pdf" target="_blank" rel="external">http://www-personal.umich.edu/~wgchoi/SDP-CRC_camready.pdf</a></li></ul><h2 id="R-FCN"><a href="#R-FCN" class="headerlink" title="R-FCN"></a>R-FCN</h2><p><strong>R-FCN: Object Detection via Region-based Fully Convolutional Networks</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1605.06409" target="_blank" rel="external">http://arxiv.org/abs/1605.06409</a></li><li>github: <a href="https://github.com/daijifeng001/R-FCN" target="_blank" rel="external">https://github.com/daijifeng001/R-FCN</a></li><li>github(MXNet): <a href="https://github.com/msracver/Deformable-ConvNets/tree/master/rfcn" target="_blank" rel="external">https://github.com/msracver/Deformable-ConvNets/tree/master/rfcn</a></li><li>github: <a href="https://github.com/Orpine/py-R-FCN" target="_blank" rel="external">https://github.com/Orpine/py-R-FCN</a></li><li>github: <a href="https://github.com/PureDiors/pytorch_RFCN" target="_blank" rel="external">https://github.com/PureDiors/pytorch_RFCN</a></li><li>github: <a href="https://github.com/bharatsingh430/py-R-FCN-multiGPU" target="_blank" rel="external">https://github.com/bharatsingh430/py-R-FCN-multiGPU</a></li><li>github: <a href="https://github.com/xdever/RFCN-tensorflow" target="_blank" rel="external">https://github.com/xdever/RFCN-tensorflow</a></li></ul><p><strong>R-FCN-3000 at 30fps: Decoupling Detection and Classification</strong></p><p><a href="https://arxiv.org/abs/1712.01802" target="_blank" rel="external">https://arxiv.org/abs/1712.01802</a></p><p><strong>Recycle deep features for better object detection</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1607.05066" target="_blank" rel="external">http://arxiv.org/abs/1607.05066</a></li></ul><h2 id="MS-CNN"><a href="#MS-CNN" class="headerlink" title="MS-CNN"></a>MS-CNN</h2><p><strong>A Unified Multi-scale Deep Convolutional Neural Network for Fast Object Detection</strong></p><ul><li>intro: ECCV 2016</li><li>intro: 640×480: 15 fps, 960×720: 8 fps</li><li>arxiv: <a href="http://arxiv.org/abs/1607.07155" target="_blank" rel="external">http://arxiv.org/abs/1607.07155</a></li><li>github: <a href="https://github.com/zhaoweicai/mscnn" target="_blank" rel="external">https://github.com/zhaoweicai/mscnn</a></li><li>poster: <a href="http://www.eccv2016.org/files/posters/P-2B-38.pdf" target="_blank" rel="external">http://www.eccv2016.org/files/posters/P-2B-38.pdf</a></li></ul><p><strong>Multi-stage Object Detection with Group Recursive Learning</strong></p><ul><li>intro: VOC2007: 78.6%, VOC2012: 74.9%</li><li>arxiv: <a href="http://arxiv.org/abs/1608.05159" target="_blank" rel="external">http://arxiv.org/abs/1608.05159</a></li></ul><p><strong>Subcategory-aware Convolutional Neural Networks for Object Proposals and Detection</strong></p><ul><li>intro: WACV 2017. SubCNN</li><li>arxiv: <a href="http://arxiv.org/abs/1604.04693" target="_blank" rel="external">http://arxiv.org/abs/1604.04693</a></li><li>github: <a href="https://github.com/tanshen/SubCNN" target="_blank" rel="external">https://github.com/tanshen/SubCNN</a></li></ul><h2 id="PVANET"><a href="#PVANET" class="headerlink" title="PVANET"></a>PVANET</h2><p><strong>PVANet: Lightweight Deep Neural Networks for Real-time Object Detection</strong></p><ul><li>intro: Presented at NIPS 2016 Workshop on Efficient Methods for Deep Neural Networks (EMDNN).<br>Continuation of <a href="https://arxiv.org/abs/1608.08021" target="_blank" rel="external">arXiv:1608.08021</a></li><li>arxiv: <a href="https://arxiv.org/abs/1611.08588" target="_blank" rel="external">https://arxiv.org/abs/1611.08588</a></li><li>github: <a href="https://github.com/sanghoon/pva-faster-rcnn" target="_blank" rel="external">https://github.com/sanghoon/pva-faster-rcnn</a></li><li>leaderboard(PVANet 9.0): <a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=4" target="_blank" rel="external">http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=4</a></li></ul><h2 id="GBD-Net"><a href="#GBD-Net" class="headerlink" title="GBD-Net"></a>GBD-Net</h2><p><strong>Gated Bi-directional CNN for Object Detection</strong></p><ul><li>intro: The Chinese University of Hong Kong &amp; Sensetime Group Limited</li><li>paper: <a href="http://link.springer.com/chapter/10.1007/978-3-319-46478-7_22" target="_blank" rel="external">http://link.springer.com/chapter/10.1007/978-3-319-46478-7_22</a></li><li>mirror: <a href="https://pan.baidu.com/s/1dFohO7v" target="_blank" rel="external">https://pan.baidu.com/s/1dFohO7v</a></li></ul><p><strong>Crafting GBD-Net for Object Detection</strong></p><ul><li>intro: winner of the ImageNet object detection challenge of 2016. CUImage and CUVideo</li><li>intro: gated bi-directional CNN (GBD-Net)</li><li>arxiv: <a href="https://arxiv.org/abs/1610.02579" target="_blank" rel="external">https://arxiv.org/abs/1610.02579</a></li><li>github: <a href="https://github.com/craftGBD/craftGBD" target="_blank" rel="external">https://github.com/craftGBD/craftGBD</a></li></ul><p><strong>StuffNet: Using ‘Stuff’ to Improve Object Detection</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1610.05861" target="_blank" rel="external">https://arxiv.org/abs/1610.05861</a></li></ul><p><strong>Generalized Haar Filter based Deep Networks for Real-Time Object Detection in Traffic Scene</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1610.09609" target="_blank" rel="external">https://arxiv.org/abs/1610.09609</a></li></ul><p><strong>Hierarchical Object Detection with Deep Reinforcement Learning</strong></p><ul><li>intro: Deep Reinforcement Learning Workshop (NIPS 2016)</li><li>project page: <a href="https://imatge-upc.github.io/detection-2016-nipsws/" target="_blank" rel="external">https://imatge-upc.github.io/detection-2016-nipsws/</a></li><li>arxiv: <a href="https://arxiv.org/abs/1611.03718" target="_blank" rel="external">https://arxiv.org/abs/1611.03718</a></li><li>slides: <a href="http://www.slideshare.net/xavigiro/hierarchical-object-detection-with-deep-reinforcement-learning" target="_blank" rel="external">http://www.slideshare.net/xavigiro/hierarchical-object-detection-with-deep-reinforcement-learning</a></li><li>github: <a href="https://github.com/imatge-upc/detection-2016-nipsws" target="_blank" rel="external">https://github.com/imatge-upc/detection-2016-nipsws</a></li><li>blog: <a href="http://jorditorres.org/nips/" target="_blank" rel="external">http://jorditorres.org/nips/</a></li></ul><p><strong>Learning to detect and localize many objects from few examples</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1611.05664" target="_blank" rel="external">https://arxiv.org/abs/1611.05664</a></li></ul><p><strong>Speed/accuracy trade-offs for modern convolutional object detectors</strong></p><ul><li>intro: CVPR 2017. Google Research</li><li>arxiv: <a href="https://arxiv.org/abs/1611.10012" target="_blank" rel="external">https://arxiv.org/abs/1611.10012</a></li></ul><p><strong>SqueezeDet: Unified, Small, Low Power Fully Convolutional Neural Networks for Real-Time Object Detection for Autonomous Driving</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1612.01051" target="_blank" rel="external">https://arxiv.org/abs/1612.01051</a></li><li>github: <a href="https://github.com/BichenWuUCB/squeezeDet" target="_blank" rel="external">https://github.com/BichenWuUCB/squeezeDet</a></li><li>github: <a href="https://github.com/fregu856/2D_detection" target="_blank" rel="external">https://github.com/fregu856/2D_detection</a></li></ul><h2 id="Feature-Pyramid-Network-FPN"><a href="#Feature-Pyramid-Network-FPN" class="headerlink" title="Feature Pyramid Network (FPN)"></a>Feature Pyramid Network (FPN)</h2><p><strong>Feature Pyramid Networks for Object Detection</strong></p><ul><li>intro: Facebook AI Research</li><li>arxiv: <a href="https://arxiv.org/abs/1612.03144" target="_blank" rel="external">https://arxiv.org/abs/1612.03144</a></li></ul><p><strong>Action-Driven Object Detection with Top-Down Visual Attentions</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1612.06704" target="_blank" rel="external">https://arxiv.org/abs/1612.06704</a></li></ul><p><strong>Beyond Skip Connections: Top-Down Modulation for Object Detection</strong></p><ul><li>intro: CMU &amp; UC Berkeley &amp; Google Research</li><li>arxiv: <a href="https://arxiv.org/abs/1612.06851" target="_blank" rel="external">https://arxiv.org/abs/1612.06851</a></li></ul><p><strong>Wide-Residual-Inception Networks for Real-time Object Detection</strong></p><ul><li>intro: Inha University</li><li>arxiv: <a href="https://arxiv.org/abs/1702.01243" target="_blank" rel="external">https://arxiv.org/abs/1702.01243</a></li></ul><p><strong>Attentional Network for Visual Object Detection</strong></p><ul><li>intro: University of Maryland &amp; Mitsubishi Electric Research Laboratories</li><li>arxiv: <a href="https://arxiv.org/abs/1702.01478" target="_blank" rel="external">https://arxiv.org/abs/1702.01478</a></li></ul><p><strong>Learning Chained Deep Features and Classifiers for Cascade in Object Detection</strong></p><ul><li>keykwords: CC-Net</li><li>intro: chained cascade network (CC-Net). 81.1% mAP on PASCAL VOC 2007</li><li>arxiv: <a href="https://arxiv.org/abs/1702.07054" target="_blank" rel="external">https://arxiv.org/abs/1702.07054</a></li></ul><p><strong>DeNet: Scalable Real-time Object Detection with Directed Sparse Sampling</strong></p><ul><li>intro: ICCV 2017 (poster)</li><li>arxiv: <a href="https://arxiv.org/abs/1703.10295" target="_blank" rel="external">https://arxiv.org/abs/1703.10295</a></li></ul><p><strong>Discriminative Bimodal Networks for Visual Localization and Detection with Natural Language Queries</strong></p><ul><li>intro: CVPR 2017</li><li>arxiv: <a href="https://arxiv.org/abs/1704.03944" target="_blank" rel="external">https://arxiv.org/abs/1704.03944</a></li></ul><p><strong>Spatial Memory for Context Reasoning in Object Detection</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1704.04224" target="_blank" rel="external">https://arxiv.org/abs/1704.04224</a></li></ul><p><strong>Accurate Single Stage Detector Using Recurrent Rolling Convolution</strong></p><ul><li>intro: CVPR 2017. SenseTime</li><li>keywords: Recurrent Rolling Convolution (RRC)</li><li>arxiv: <a href="https://arxiv.org/abs/1704.05776" target="_blank" rel="external">https://arxiv.org/abs/1704.05776</a></li><li>github: <a href="https://github.com/xiaohaoChen/rrc_detection" target="_blank" rel="external">https://github.com/xiaohaoChen/rrc_detection</a></li></ul><p><strong>Deep Occlusion Reasoning for Multi-Camera Multi-Target Detection</strong></p><p><a href="https://arxiv.org/abs/1704.05775" target="_blank" rel="external">https://arxiv.org/abs/1704.05775</a></p><p><strong>LCDet: Low-Complexity Fully-Convolutional Neural Networks for Object Detection in Embedded Systems</strong></p><ul><li>intro: Embedded Vision Workshop in CVPR. UC San Diego &amp; Qualcomm Inc</li><li>arxiv: <a href="https://arxiv.org/abs/1705.05922" target="_blank" rel="external">https://arxiv.org/abs/1705.05922</a></li></ul><p><strong>Point Linking Network for Object Detection</strong></p><ul><li>intro: Point Linking Network (PLN)</li><li>arxiv: <a href="https://arxiv.org/abs/1706.03646" target="_blank" rel="external">https://arxiv.org/abs/1706.03646</a></li></ul><p><strong>Perceptual Generative Adversarial Networks for Small Object Detection</strong></p><p><a href="https://arxiv.org/abs/1706.05274" target="_blank" rel="external">https://arxiv.org/abs/1706.05274</a></p><p><strong>Few-shot Object Detection</strong></p><p><a href="https://arxiv.org/abs/1706.08249" target="_blank" rel="external">https://arxiv.org/abs/1706.08249</a></p><p><strong>Yes-Net: An effective Detector Based on Global Information</strong></p><p><a href="https://arxiv.org/abs/1706.09180" target="_blank" rel="external">https://arxiv.org/abs/1706.09180</a></p><p><strong>SMC Faster R-CNN: Toward a scene-specialized multi-object detector</strong></p><p><a href="https://arxiv.org/abs/1706.10217" target="_blank" rel="external">https://arxiv.org/abs/1706.10217</a></p><p><strong>Towards lightweight convolutional neural networks for object detection</strong></p><p><a href="https://arxiv.org/abs/1707.01395" target="_blank" rel="external">https://arxiv.org/abs/1707.01395</a></p><p><strong>RON: Reverse Connection with Objectness Prior Networks for Object Detection</strong></p><ul><li>intro: CVPR 2017</li><li>arxiv: <a href="https://arxiv.org/abs/1707.01691" target="_blank" rel="external">https://arxiv.org/abs/1707.01691</a></li><li>github: <a href="https://github.com/taokong/RON" target="_blank" rel="external">https://github.com/taokong/RON</a></li></ul><p><strong>Mimicking Very Efficient Network for Object Detection</strong></p><ul><li>intro: CVPR 2017. SenseTime &amp; Beihang University</li><li>paper: <a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Mimicking_Very_Efficient_CVPR_2017_paper.pdf" target="_blank" rel="external">http://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Mimicking_Very_Efficient_CVPR_2017_paper.pdf</a></li></ul><p><strong>Residual Features and Unified Prediction Network for Single Stage Detection</strong></p><p><a href="https://arxiv.org/abs/1707.05031" target="_blank" rel="external">https://arxiv.org/abs/1707.05031</a></p><p><strong>Deformable Part-based Fully Convolutional Network for Object Detection</strong></p><ul><li>intro: BMVC 2017 (oral). Sorbonne Universités &amp; CEDRIC</li><li>arxiv: <a href="https://arxiv.org/abs/1707.06175" target="_blank" rel="external">https://arxiv.org/abs/1707.06175</a></li></ul><p><strong>Adaptive Feeding: Achieving Fast and Accurate Detections by Adaptively Combining Object Detectors</strong></p><ul><li>intro: ICCV 2017</li><li>arxiv: <a href="https://arxiv.org/abs/1707.06399" target="_blank" rel="external">https://arxiv.org/abs/1707.06399</a></li></ul><p><strong>Recurrent Scale Approximation for Object Detection in CNN</strong></p><ul><li>intro: ICCV 2017</li><li>keywords: Recurrent Scale Approximation (RSA)</li><li>arxiv: <a href="https://arxiv.org/abs/1707.09531" target="_blank" rel="external">https://arxiv.org/abs/1707.09531</a></li><li>github: <a href="https://github.com/sciencefans/RSA-for-object-detection" target="_blank" rel="external">https://github.com/sciencefans/RSA-for-object-detection</a></li></ul><h2 id="DSOD"><a href="#DSOD" class="headerlink" title="DSOD"></a>DSOD</h2><p><strong>DSOD: Learning Deeply Supervised Object Detectors from Scratch</strong></p><p><img src="https://user-images.githubusercontent.com/3794909/28934967-718c9302-78b5-11e7-89ee-8b514e53e23c.png" alt=""></p><ul><li>intro: ICCV 2017. Fudan University &amp; Tsinghua University &amp; Intel Labs China</li><li>arxiv: <a href="https://arxiv.org/abs/1708.01241" target="_blank" rel="external">https://arxiv.org/abs/1708.01241</a></li><li>github: <a href="https://github.com/szq0214/DSOD" target="_blank" rel="external">https://github.com/szq0214/DSOD</a></li></ul><h2 id="RetinaNet"><a href="#RetinaNet" class="headerlink" title="RetinaNet"></a>RetinaNet</h2><p><strong>Focal Loss for Dense Object Detection</strong></p><ul><li>intro: ICCV 2017 Best student paper award. Facebook AI Research</li><li>keywords: RetinaNet</li><li>arxiv: <a href="https://arxiv.org/abs/1708.02002" target="_blank" rel="external">https://arxiv.org/abs/1708.02002</a></li></ul><p><strong>CoupleNet: Coupling Global Structure with Local Parts for Object Detection</strong></p><ul><li>intro: ICCV 2017</li><li>arxiv: <a href="https://arxiv.org/abs/1708.02863" target="_blank" rel="external">https://arxiv.org/abs/1708.02863</a></li></ul><p><strong>Incremental Learning of Object Detectors without Catastrophic Forgetting</strong></p><ul><li>intro: ICCV 2017. Inria</li><li>arxiv: <a href="https://arxiv.org/abs/1708.06977" target="_blank" rel="external">https://arxiv.org/abs/1708.06977</a></li></ul><p><strong>Zoom Out-and-In Network with Map Attention Decision for Region Proposal and Object Detection</strong></p><p><a href="https://arxiv.org/abs/1709.04347" target="_blank" rel="external">https://arxiv.org/abs/1709.04347</a></p><p><strong>StairNet: Top-Down Semantic Aggregation for Accurate One Shot Detection</strong></p><p><a href="https://arxiv.org/abs/1709.05788" target="_blank" rel="external">https://arxiv.org/abs/1709.05788</a></p><p><strong>Dynamic Zoom-in Network for Fast Object Detection in Large Images</strong></p><p><a href="https://arxiv.org/abs/1711.05187" target="_blank" rel="external">https://arxiv.org/abs/1711.05187</a></p><p><strong>Zero-Annotation Object Detection with Web Knowledge Transfer</strong></p><ul><li>intro: NTU, Singapore &amp; Amazon</li><li>keywords: multi-instance multi-label domain adaption learning framework</li><li>arxiv: <a href="https://arxiv.org/abs/1711.05954" target="_blank" rel="external">https://arxiv.org/abs/1711.05954</a></li></ul><h2 id="MegDet"><a href="#MegDet" class="headerlink" title="MegDet"></a>MegDet</h2><p><strong>MegDet: A Large Mini-Batch Object Detector</strong></p><ul><li>intro: Peking University &amp; Tsinghua University &amp; Megvii Inc</li><li>arxiv: <a href="https://arxiv.org/abs/1711.07240" target="_blank" rel="external">https://arxiv.org/abs/1711.07240</a></li></ul><p><strong>Single-Shot Refinement Neural Network for Object Detection</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1711.06897" target="_blank" rel="external">https://arxiv.org/abs/1711.06897</a></li><li>github: <a href="https://github.com/sfzhang15/RefineDet" target="_blank" rel="external">https://github.com/sfzhang15/RefineDet</a></li></ul><p><strong>Receptive Field Block Net for Accurate and Fast Object Detection</strong></p><ul><li>intro: RFBNet</li><li>arxiv: <a href="https://arxiv.org/abs/1711.07767" target="_blank" rel="external">https://arxiv.org/abs/1711.07767</a></li><li>github: <a href="https://github.com//ruinmessi/RFBNet" target="_blank" rel="external">https://github.com//ruinmessi/RFBNet</a></li></ul><p><strong>An Analysis of Scale Invariance in Object Detection - SNIP</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1711.08189" target="_blank" rel="external">https://arxiv.org/abs/1711.08189</a></li><li>github: <a href="https://github.com/bharatsingh430/snip" target="_blank" rel="external">https://github.com/bharatsingh430/snip</a></li></ul><p><strong>Feature Selective Networks for Object Detection</strong></p><p><a href="https://arxiv.org/abs/1711.08879" target="_blank" rel="external">https://arxiv.org/abs/1711.08879</a></p><p><strong>Learning a Rotation Invariant Detector with Rotatable Bounding Box</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1711.09405" target="_blank" rel="external">https://arxiv.org/abs/1711.09405</a></li><li>github: <a href="https://github.com/liulei01/DRBox" target="_blank" rel="external">https://github.com/liulei01/DRBox</a></li></ul><p><strong>Scalable Object Detection for Stylized Objects</strong></p><ul><li>intro: Microsoft AI &amp; Research Munich</li><li>arxiv: <a href="https://arxiv.org/abs/1711.09822" target="_blank" rel="external">https://arxiv.org/abs/1711.09822</a></li></ul><p><strong>Learning Object Detectors from Scratch with Gated Recurrent Feature Pyramids</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1712.00886" target="_blank" rel="external">https://arxiv.org/abs/1712.00886</a></li><li>github: <a href="https://github.com/szq0214/GRP-DSOD" target="_blank" rel="external">https://github.com/szq0214/GRP-DSOD</a></li></ul><p><strong>Deep Regionlets for Object Detection</strong></p><ul><li>keywords: region selection network, gating network</li><li>arxiv: <a href="https://arxiv.org/abs/1712.02408" target="_blank" rel="external">https://arxiv.org/abs/1712.02408</a></li></ul><p><strong>Training and Testing Object Detectors with Virtual Images</strong></p><ul><li>intro: IEEE/CAA Journal of Automatica Sinica</li><li>arxiv: <a href="https://arxiv.org/abs/1712.08470" target="_blank" rel="external">https://arxiv.org/abs/1712.08470</a></li></ul><p><strong>Large-Scale Object Discovery and Detector Adaptation from Unlabeled Video</strong></p><ul><li>keywords: object mining, object tracking, unsupervised object discovery by appearance-based clustering, self-supervised detector adaptation</li><li>arxiv: <a href="https://arxiv.org/abs/1712.08832" target="_blank" rel="external">https://arxiv.org/abs/1712.08832</a></li></ul><p><strong>Spot the Difference by Object Detection</strong></p><ul><li>intro: Tsinghua University &amp; JD Group</li><li>arxiv: <a href="https://arxiv.org/abs/1801.01051" target="_blank" rel="external">https://arxiv.org/abs/1801.01051</a></li></ul><p><strong>Localization-Aware Active Learning for Object Detection</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1801.05124" target="_blank" rel="external">https://arxiv.org/abs/1801.05124</a></li></ul><p><strong>Object Detection with Mask-based Feature Encoding</strong></p><p><a href="https://arxiv.org/abs/1802.03934" target="_blank" rel="external">https://arxiv.org/abs/1802.03934</a></p><p><strong>LSTD: A Low-Shot Transfer Detector for Object Detection</strong></p><ul><li>intro: AAAI 2018</li><li>arxiv: <a href="https://arxiv.org/abs/1803.01529" target="_blank" rel="external">https://arxiv.org/abs/1803.01529</a></li></ul><p><strong>Domain Adaptive Faster R-CNN for Object Detection in the Wild</strong></p><ul><li>intro: CVPR 2018. ETH Zurich &amp; ESAT/PSI</li><li>arxiv: <a href="https://arxiv.org/abs/1803.03243" target="_blank" rel="external">https://arxiv.org/abs/1803.03243</a></li></ul><p><strong>Pseudo Mask Augmented Object Detection</strong></p><p><a href="https://arxiv.org/abs/1803.05858" target="_blank" rel="external">https://arxiv.org/abs/1803.05858</a></p><p><strong>Revisiting RCNN: On Awakening the Classification Power of Faster RCNN</strong></p><p><a href="https://arxiv.org/abs/1803.06799" target="_blank" rel="external">https://arxiv.org/abs/1803.06799</a></p><p><strong>Zero-Shot Detection</strong></p><ul><li>intro: Australian National University</li><li>keywords: YOLO</li><li>arxiv: <a href="https://arxiv.org/abs/1803.07113" target="_blank" rel="external">https://arxiv.org/abs/1803.07113</a></li></ul><p><strong>Learning Region Features for Object Detection</strong></p><ul><li>intro: Peking University &amp; MSRA</li><li>arxiv: <a href="https://arxiv.org/abs/1803.07066" target="_blank" rel="external">https://arxiv.org/abs/1803.07066</a></li></ul><p><strong>Single-Shot Bidirectional Pyramid Networks for High-Quality Object Detection</strong></p><p><a href="https://arxiv.org/abs/1803.08208" target="_blank" rel="external">https://arxiv.org/abs/1803.08208</a></p><p><strong>Object Detection for Comics using Manga109 Annotations</strong></p><ul><li>intro: University of Tokyo &amp; National Institute of Informatics, Japan</li><li>arxiv: <a href="https://arxiv.org/abs/1803.08670" target="_blank" rel="external">https://arxiv.org/abs/1803.08670</a></li></ul><h1 id="Non-Maximum-Suppression-NMS"><a href="#Non-Maximum-Suppression-NMS" class="headerlink" title="Non-Maximum Suppression (NMS)"></a>Non-Maximum Suppression (NMS)</h1><p><strong>End-to-End Integration of a Convolutional Network, Deformable Parts Model and Non-Maximum Suppression</strong></p><ul><li>intro: CVPR 2015</li><li>arxiv: <a href="http://arxiv.org/abs/1411.5309" target="_blank" rel="external">http://arxiv.org/abs/1411.5309</a></li><li>paper: <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Wan_End-to-End_Integration_of_2015_CVPR_paper.pdf" target="_blank" rel="external">http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Wan_End-to-End_Integration_of_2015_CVPR_paper.pdf</a></li></ul><p><strong>A convnet for non-maximum suppression</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1511.06437" target="_blank" rel="external">http://arxiv.org/abs/1511.06437</a></li></ul><p><strong>Improving Object Detection With One Line of Code</strong></p><p><strong>Soft-NMS – Improving Object Detection With One Line of Code</strong></p><ul><li>intro: ICCV 2017. University of Maryland</li><li>keywords: Soft-NMS</li><li>arxiv: <a href="https://arxiv.org/abs/1704.04503" target="_blank" rel="external">https://arxiv.org/abs/1704.04503</a></li><li>github: <a href="https://github.com/bharatsingh430/soft-nms" target="_blank" rel="external">https://github.com/bharatsingh430/soft-nms</a></li></ul><p><strong>Learning non-maximum suppression</strong></p><ul><li>intro: CVPR 2017</li><li>project page: <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/object-recognition-and-scene-understanding/learning-nms/" target="_blank" rel="external">https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/object-recognition-and-scene-understanding/learning-nms/</a></li><li>arxiv: <a href="https://arxiv.org/abs/1705.02950" target="_blank" rel="external">https://arxiv.org/abs/1705.02950</a></li><li>github: <a href="https://github.com/hosang/gossipnet" target="_blank" rel="external">https://github.com/hosang/gossipnet</a></li></ul><p><strong>Relation Networks for Object Detection</strong></p><p><a href="https://arxiv.org/abs/1711.11575" target="_blank" rel="external">https://arxiv.org/abs/1711.11575</a></p><h1 id="Adversarial-Examples"><a href="#Adversarial-Examples" class="headerlink" title="Adversarial Examples"></a>Adversarial Examples</h1><p><strong>Adversarial Examples that Fool Detectors</strong></p><ul><li>intro: University of Illinois</li><li>arxiv: <a href="https://arxiv.org/abs/1712.02494" target="_blank" rel="external">https://arxiv.org/abs/1712.02494</a></li></ul><p><strong>Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods</strong></p><ul><li>project page: <a href="http://nicholas.carlini.com/code/nn_breaking_detection/" target="_blank" rel="external">http://nicholas.carlini.com/code/nn_breaking_detection/</a></li><li>arxiv: <a href="https://arxiv.org/abs/1705.07263" target="_blank" rel="external">https://arxiv.org/abs/1705.07263</a></li><li>github: <a href="https://github.com/carlini/nn_breaking_detection" target="_blank" rel="external">https://github.com/carlini/nn_breaking_detection</a></li></ul><h1 id="Weakly-Supervised-Object-Detection"><a href="#Weakly-Supervised-Object-Detection" class="headerlink" title="Weakly Supervised Object Detection"></a>Weakly Supervised Object Detection</h1><p><strong>Track and Transfer: Watching Videos to Simulate Strong Human Supervision for Weakly-Supervised Object Detection</strong></p><ul><li>intro: CVPR 2016</li><li>arxiv: <a href="http://arxiv.org/abs/1604.05766" target="_blank" rel="external">http://arxiv.org/abs/1604.05766</a></li></ul><p><strong>Weakly supervised object detection using pseudo-strong labels</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1607.04731" target="_blank" rel="external">http://arxiv.org/abs/1607.04731</a></li></ul><p><strong>Saliency Guided End-to-End Learning for Weakly Supervised Object Detection</strong></p><ul><li>intro: IJCAI 2017</li><li>arxiv: <a href="https://arxiv.org/abs/1706.06768" target="_blank" rel="external">https://arxiv.org/abs/1706.06768</a></li></ul><p><strong>Visual and Semantic Knowledge Transfer for Large Scale Semi-supervised Object Detection</strong></p><ul><li>intro: TPAMI 2017. National Institutes of Health (NIH) Clinical Center</li><li>arxiv: <a href="https://arxiv.org/abs/1801.03145" target="_blank" rel="external">https://arxiv.org/abs/1801.03145</a></li></ul><h1 id="Video-Object-Detection"><a href="#Video-Object-Detection" class="headerlink" title="Video Object Detection"></a>Video Object Detection</h1><p><strong>Learning Object Class Detectors from Weakly Annotated Video</strong></p><ul><li>intro: CVPR 2012</li><li>paper: <a href="https://www.vision.ee.ethz.ch/publications/papers/proceedings/eth_biwi_00905.pdf" target="_blank" rel="external">https://www.vision.ee.ethz.ch/publications/papers/proceedings/eth_biwi_00905.pdf</a></li></ul><p><strong>Analysing domain shift factors between videos and images for object detection</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1501.01186" target="_blank" rel="external">https://arxiv.org/abs/1501.01186</a></li></ul><p><strong>Video Object Recognition</strong></p><ul><li>slides: <a href="http://vision.princeton.edu/courses/COS598/2015sp/slides/VideoRecog/Video%20Object%20Recognition.pptx" target="_blank" rel="external">http://vision.princeton.edu/courses/COS598/2015sp/slides/VideoRecog/Video%20Object%20Recognition.pptx</a></li></ul><p><strong>Deep Learning for Saliency Prediction in Natural Video</strong></p><ul><li>intro: Submitted on 12 Jan 2016</li><li>keywords: Deep learning, saliency map, optical flow, convolution network, contrast features</li><li>paper: <a href="https://hal.archives-ouvertes.fr/hal-01251614/document" target="_blank" rel="external">https://hal.archives-ouvertes.fr/hal-01251614/document</a></li></ul><p><strong>T-CNN: Tubelets with Convolutional Neural Networks for Object Detection from Videos</strong></p><ul><li>intro: Winning solution in ILSVRC2015 Object Detection from Video(VID) Task</li><li>arxiv: <a href="http://arxiv.org/abs/1604.02532" target="_blank" rel="external">http://arxiv.org/abs/1604.02532</a></li><li>github: <a href="https://github.com/myfavouritekk/T-CNN" target="_blank" rel="external">https://github.com/myfavouritekk/T-CNN</a></li></ul><p><strong>Object Detection from Video Tubelets with Convolutional Neural Networks</strong></p><ul><li>intro: CVPR 2016 Spotlight paper</li><li>arxiv: <a href="https://arxiv.org/abs/1604.04053" target="_blank" rel="external">https://arxiv.org/abs/1604.04053</a></li><li>paper: <a href="http://www.ee.cuhk.edu.hk/~wlouyang/Papers/KangVideoDet_CVPR16.pdf" target="_blank" rel="external">http://www.ee.cuhk.edu.hk/~wlouyang/Papers/KangVideoDet_CVPR16.pdf</a></li><li>gihtub: <a href="https://github.com/myfavouritekk/vdetlib" target="_blank" rel="external">https://github.com/myfavouritekk/vdetlib</a></li></ul><p><strong>Object Detection in Videos with Tubelets and Multi-context Cues</strong></p><ul><li>intro: SenseTime Group</li><li>slides: <a href="http://www.ee.cuhk.edu.hk/~xgwang/CUvideo.pdf" target="_blank" rel="external">http://www.ee.cuhk.edu.hk/~xgwang/CUvideo.pdf</a></li><li>slides: <a href="http://image-net.org/challenges/talks/Object%20Detection%20in%20Videos%20with%20Tubelets%20and%20Multi-context%20Cues%20-%20Final.pdf" target="_blank" rel="external">http://image-net.org/challenges/talks/Object%20Detection%20in%20Videos%20with%20Tubelets%20and%20Multi-context%20Cues%20-%20Final.pdf</a></li></ul><p><strong>Context Matters: Refining Object Detection in Video with Recurrent Neural Networks</strong></p><ul><li>intro: BMVC 2016</li><li>keywords: pseudo-labeler</li><li>arxiv: <a href="http://arxiv.org/abs/1607.04648" target="_blank" rel="external">http://arxiv.org/abs/1607.04648</a></li><li>paper: <a href="http://vision.cornell.edu/se3/wp-content/uploads/2016/07/video_object_detection_BMVC.pdf" target="_blank" rel="external">http://vision.cornell.edu/se3/wp-content/uploads/2016/07/video_object_detection_BMVC.pdf</a></li></ul><p><strong>CNN Based Object Detection in Large Video Images</strong></p><ul><li>intro: WangTao @ 爱奇艺</li><li>keywords: object retrieval, object detection, scene classification</li><li>slides: <a href="http://on-demand.gputechconf.com/gtc/2016/presentation/s6362-wang-tao-cnn-based-object-detection-large-video-images.pdf" target="_blank" rel="external">http://on-demand.gputechconf.com/gtc/2016/presentation/s6362-wang-tao-cnn-based-object-detection-large-video-images.pdf</a></li></ul><p><strong>Object Detection in Videos with Tubelet Proposal Networks</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1702.06355" target="_blank" rel="external">https://arxiv.org/abs/1702.06355</a></li></ul><p><strong>Flow-Guided Feature Aggregation for Video Object Detection</strong></p><ul><li>intro: MSRA</li><li>arxiv: <a href="https://arxiv.org/abs/1703.10025" target="_blank" rel="external">https://arxiv.org/abs/1703.10025</a></li></ul><p><strong>Video Object Detection using Faster R-CNN</strong></p><ul><li>blog: <a href="http://andrewliao11.github.io/object_detection/faster_rcnn/" target="_blank" rel="external">http://andrewliao11.github.io/object_detection/faster_rcnn/</a></li><li>github: <a href="https://github.com/andrewliao11/py-faster-rcnn-imagenet" target="_blank" rel="external">https://github.com/andrewliao11/py-faster-rcnn-imagenet</a></li></ul><p><strong>Improving Context Modeling for Video Object Detection and Tracking</strong></p><p><a href="http://image-net.org/challenges/talks_2017/ilsvrc2017_short(poster" target="_blank" rel="external">http://image-net.org/challenges/talks_2017/ilsvrc2017_short(poster).pdf</a>.pdf)</p><p><strong>Temporal Dynamic Graph LSTM for Action-driven Video Object Detection</strong></p><ul><li>intro: ICCV 2017</li><li>arxiv: <a href="https://arxiv.org/abs/1708.00666" target="_blank" rel="external">https://arxiv.org/abs/1708.00666</a></li></ul><p><strong>Mobile Video Object Detection with Temporally-Aware Feature Maps</strong></p><p><a href="https://arxiv.org/abs/1711.06368" target="_blank" rel="external">https://arxiv.org/abs/1711.06368</a></p><p><strong>Towards High Performance Video Object Detection</strong></p><p><a href="https://arxiv.org/abs/1711.11577" target="_blank" rel="external">https://arxiv.org/abs/1711.11577</a></p><p><strong>Impression Network for Video Object Detection</strong></p><p><a href="https://arxiv.org/abs/1712.05896" target="_blank" rel="external">https://arxiv.org/abs/1712.05896</a></p><p><strong>Spatial-Temporal Memory Networks for Video Object Detection</strong></p><p><a href="https://arxiv.org/abs/1712.06317" target="_blank" rel="external">https://arxiv.org/abs/1712.06317</a></p><p><strong>3D-DETNet: a Single Stage Video-Based Vehicle Detector</strong></p><p><a href="https://arxiv.org/abs/1801.01769" target="_blank" rel="external">https://arxiv.org/abs/1801.01769</a></p><p><strong>Object Detection in Videos by Short and Long Range Object Linking</strong></p><p><a href="https://arxiv.org/abs/1801.09823" target="_blank" rel="external">https://arxiv.org/abs/1801.09823</a></p><p><strong>Object Detection in Video with Spatiotemporal Sampling Networks</strong></p><ul><li>intro: University of Pennsylvania, 2Dartmouth College</li><li>arxiv: <a href="https://arxiv.org/abs/1803.05549" target="_blank" rel="external">https://arxiv.org/abs/1803.05549</a></li></ul><h1 id="Object-Detection-in-3D"><a href="#Object-Detection-in-3D" class="headerlink" title="Object Detection in 3D"></a>Object Detection in 3D</h1><p><strong>Vote3Deep: Fast Object Detection in 3D Point Clouds Using Efficient Convolutional Neural Networks</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1609.06666" target="_blank" rel="external">https://arxiv.org/abs/1609.06666</a></li></ul><p><strong>Complex-YOLO: Real-time 3D Object Detection on Point Clouds</strong></p><ul><li>intro: Valeo Schalter und Sensoren GmbH &amp; Ilmenau University of Technology</li><li>arxiv: <a href="https://arxiv.org/abs/1803.06199" target="_blank" rel="external">https://arxiv.org/abs/1803.06199</a></li></ul><h1 id="Object-Detection-on-RGB-D"><a href="#Object-Detection-on-RGB-D" class="headerlink" title="Object Detection on RGB-D"></a>Object Detection on RGB-D</h1><p><strong>Learning Rich Features from RGB-D Images for Object Detection and Segmentation</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1407.5736" target="_blank" rel="external">http://arxiv.org/abs/1407.5736</a></li></ul><p><strong>Differential Geometry Boosts Convolutional Neural Networks for Object Detection</strong></p><ul><li>intro: CVPR 2016</li><li>paper: <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016_workshops/w23/html/Wang_Differential_Geometry_Boosts_CVPR_2016_paper.html" target="_blank" rel="external">http://www.cv-foundation.org/openaccess/content_cvpr_2016_workshops/w23/html/Wang_Differential_Geometry_Boosts_CVPR_2016_paper.html</a></li></ul><p><strong>A Self-supervised Learning System for Object Detection using Physics Simulation and Multi-view Pose Estimation</strong></p><p><a href="https://arxiv.org/abs/1703.03347" target="_blank" rel="external">https://arxiv.org/abs/1703.03347</a></p><h1 id="Salient-Object-Detection"><a href="#Salient-Object-Detection" class="headerlink" title="Salient Object Detection"></a>Salient Object Detection</h1><p>This task involves predicting the salient regions of an image given by human eye fixations.</p><p><strong>Best Deep Saliency Detection Models (CVPR 2016 &amp; 2015)</strong></p><p><a href="http://i.cs.hku.hk/~yzyu/vision.html" target="_blank" rel="external">http://i.cs.hku.hk/~yzyu/vision.html</a></p><p><strong>Large-scale optimization of hierarchical features for saliency prediction in natural images</strong></p><ul><li>paper: <a href="http://coxlab.org/pdfs/cvpr2014_vig_saliency.pdf" target="_blank" rel="external">http://coxlab.org/pdfs/cvpr2014_vig_saliency.pdf</a></li></ul><p><strong>Predicting Eye Fixations using Convolutional Neural Networks</strong></p><ul><li>paper: <a href="http://www.escience.cn/system/file?fileId=72648" target="_blank" rel="external">http://www.escience.cn/system/file?fileId=72648</a></li></ul><p><strong>Saliency Detection by Multi-Context Deep Learning</strong></p><ul><li>paper: <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Zhao_Saliency_Detection_by_2015_CVPR_paper.pdf" target="_blank" rel="external">http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Zhao_Saliency_Detection_by_2015_CVPR_paper.pdf</a></li></ul><p><strong>DeepSaliency: Multi-Task Deep Neural Network Model for Salient Object Detection</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1510.05484" target="_blank" rel="external">http://arxiv.org/abs/1510.05484</a></li></ul><p><strong>SuperCNN: A Superpixelwise Convolutional Neural Network for Salient Object Detection</strong></p><ul><li>paper: <a href="www.shengfenghe.com/supercnn-a-superpixelwise-convolutional-neural-network-for-salient-object-detection.html">www.shengfenghe.com/supercnn-a-superpixelwise-convolutional-neural-network-for-salient-object-detection.html</a></li></ul><p><strong>Shallow and Deep Convolutional Networks for Saliency Prediction</strong></p><ul><li>intro: CVPR 2016</li><li>arxiv: <a href="http://arxiv.org/abs/1603.00845" target="_blank" rel="external">http://arxiv.org/abs/1603.00845</a></li><li>github: <a href="https://github.com/imatge-upc/saliency-2016-cvpr" target="_blank" rel="external">https://github.com/imatge-upc/saliency-2016-cvpr</a></li></ul><p><strong>Recurrent Attentional Networks for Saliency Detection</strong></p><ul><li>intro: CVPR 2016. recurrent attentional convolutional-deconvolution network (RACDNN)</li><li>arxiv: <a href="http://arxiv.org/abs/1604.03227" target="_blank" rel="external">http://arxiv.org/abs/1604.03227</a></li></ul><p><strong>Two-Stream Convolutional Networks for Dynamic Saliency Prediction</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1607.04730" target="_blank" rel="external">http://arxiv.org/abs/1607.04730</a></li></ul><p><strong>Unconstrained Salient Object Detection</strong></p><p><strong>Unconstrained Salient Object Detection via Proposal Subset Optimization</strong></p><p><img src="http://cs-people.bu.edu/jmzhang/images/pasted%20image%201465x373.jpg" alt=""></p><ul><li>intro: CVPR 2016</li><li>project page: <a href="http://cs-people.bu.edu/jmzhang/sod.html" target="_blank" rel="external">http://cs-people.bu.edu/jmzhang/sod.html</a></li><li>paper: <a href="http://cs-people.bu.edu/jmzhang/SOD/CVPR16SOD_camera_ready.pdf" target="_blank" rel="external">http://cs-people.bu.edu/jmzhang/SOD/CVPR16SOD_camera_ready.pdf</a></li><li>github: <a href="https://github.com/jimmie33/SOD" target="_blank" rel="external">https://github.com/jimmie33/SOD</a></li><li>caffe model zoo: <a href="https://github.com/BVLC/caffe/wiki/Model-Zoo#cnn-object-proposal-models-for-salient-object-detection" target="_blank" rel="external">https://github.com/BVLC/caffe/wiki/Model-Zoo#cnn-object-proposal-models-for-salient-object-detection</a></li></ul><p><strong>DHSNet: Deep Hierarchical Saliency Network for Salient Object Detection</strong></p><ul><li>paper: <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_DHSNet_Deep_Hierarchical_CVPR_2016_paper.pdf" target="_blank" rel="external">http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_DHSNet_Deep_Hierarchical_CVPR_2016_paper.pdf</a></li></ul><p><strong>Salient Object Subitizing</strong></p><p><img src="http://cs-people.bu.edu/jmzhang/images/frontpage.png?crc=123070793" alt=""></p><ul><li>intro: CVPR 2015</li><li>intro: predicting the existence and the number of salient objects in an image using holistic cues</li><li>project page: <a href="http://cs-people.bu.edu/jmzhang/sos.html" target="_blank" rel="external">http://cs-people.bu.edu/jmzhang/sos.html</a></li><li>arxiv: <a href="http://arxiv.org/abs/1607.07525" target="_blank" rel="external">http://arxiv.org/abs/1607.07525</a></li><li>paper: <a href="http://cs-people.bu.edu/jmzhang/SOS/SOS_preprint.pdf" target="_blank" rel="external">http://cs-people.bu.edu/jmzhang/SOS/SOS_preprint.pdf</a></li><li>caffe model zoo: <a href="https://github.com/BVLC/caffe/wiki/Model-Zoo#cnn-models-for-salient-object-subitizing" target="_blank" rel="external">https://github.com/BVLC/caffe/wiki/Model-Zoo#cnn-models-for-salient-object-subitizing</a></li></ul><p><strong>Deeply-Supervised Recurrent Convolutional Neural Network for Saliency Detection</strong></p><ul><li>intro: ACMMM 2016. deeply-supervised recurrent convolutional neural network (DSRCNN)</li><li>arxiv: <a href="http://arxiv.org/abs/1608.05177" target="_blank" rel="external">http://arxiv.org/abs/1608.05177</a></li></ul><p><strong>Saliency Detection via Combining Region-Level and Pixel-Level Predictions with CNNs</strong></p><ul><li>intro: ECCV 2016</li><li>arxiv: <a href="http://arxiv.org/abs/1608.05186" target="_blank" rel="external">http://arxiv.org/abs/1608.05186</a></li></ul><p><strong>Edge Preserving and Multi-Scale Contextual Neural Network for Salient Object Detection</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1608.08029" target="_blank" rel="external">http://arxiv.org/abs/1608.08029</a></li></ul><p><strong>A Deep Multi-Level Network for Saliency Prediction</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1609.01064" target="_blank" rel="external">http://arxiv.org/abs/1609.01064</a></li></ul><p><strong>Visual Saliency Detection Based on Multiscale Deep CNN Features</strong></p><ul><li>intro: IEEE Transactions on Image Processing</li><li>arxiv: <a href="http://arxiv.org/abs/1609.02077" target="_blank" rel="external">http://arxiv.org/abs/1609.02077</a></li></ul><p><strong>A Deep Spatial Contextual Long-term Recurrent Convolutional Network for Saliency Detection</strong></p><ul><li>intro: DSCLRCN</li><li>arxiv: <a href="https://arxiv.org/abs/1610.01708" target="_blank" rel="external">https://arxiv.org/abs/1610.01708</a></li></ul><p><strong>Deeply supervised salient object detection with short connections</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1611.04849" target="_blank" rel="external">https://arxiv.org/abs/1611.04849</a></li></ul><p><strong>Weakly Supervised Top-down Salient Object Detection</strong></p><ul><li>intro: Nanyang Technological University</li><li>arxiv: <a href="https://arxiv.org/abs/1611.05345" target="_blank" rel="external">https://arxiv.org/abs/1611.05345</a></li></ul><p><strong>SalGAN: Visual Saliency Prediction with Generative Adversarial Networks</strong></p><ul><li>project page: <a href="https://imatge-upc.github.io/saliency-salgan-2017/" target="_blank" rel="external">https://imatge-upc.github.io/saliency-salgan-2017/</a></li><li>arxiv: <a href="https://arxiv.org/abs/1701.01081" target="_blank" rel="external">https://arxiv.org/abs/1701.01081</a></li></ul><p><strong>Visual Saliency Prediction Using a Mixture of Deep Neural Networks</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1702.00372" target="_blank" rel="external">https://arxiv.org/abs/1702.00372</a></li></ul><p><strong>A Fast and Compact Salient Score Regression Network Based on Fully Convolutional Network</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1702.00615" target="_blank" rel="external">https://arxiv.org/abs/1702.00615</a></li></ul><p><strong>Saliency Detection by Forward and Backward Cues in Deep-CNNs</strong></p><p><a href="https://arxiv.org/abs/1703.00152" target="_blank" rel="external">https://arxiv.org/abs/1703.00152</a></p><p><strong>Supervised Adversarial Networks for Image Saliency Detection</strong></p><p><a href="https://arxiv.org/abs/1704.07242" target="_blank" rel="external">https://arxiv.org/abs/1704.07242</a></p><p><strong>Group-wise Deep Co-saliency Detection</strong></p><p><a href="https://arxiv.org/abs/1707.07381" target="_blank" rel="external">https://arxiv.org/abs/1707.07381</a></p><p><strong>Towards the Success Rate of One: Real-time Unconstrained Salient Object Detection</strong></p><ul><li>intro: University of Maryland College Park &amp; eBay Inc</li><li>arxiv: <a href="https://arxiv.org/abs/1708.00079" target="_blank" rel="external">https://arxiv.org/abs/1708.00079</a></li></ul><p><strong>Amulet: Aggregating Multi-level Convolutional Features for Salient Object Detection</strong></p><ul><li>intro: ICCV 2017</li><li>arixv: <a href="https://arxiv.org/abs/1708.02001" target="_blank" rel="external">https://arxiv.org/abs/1708.02001</a></li></ul><p><strong>Learning Uncertain Convolutional Features for Accurate Saliency Detection</strong></p><ul><li>intro: Accepted as a poster in ICCV 2017</li><li>arxiv: <a href="https://arxiv.org/abs/1708.02031" target="_blank" rel="external">https://arxiv.org/abs/1708.02031</a></li></ul><p><strong>Deep Edge-Aware Saliency Detection</strong></p><p><a href="https://arxiv.org/abs/1708.04366" target="_blank" rel="external">https://arxiv.org/abs/1708.04366</a></p><p><strong>Self-explanatory Deep Salient Object Detection</strong></p><ul><li>intro: National University of Defense Technology, China &amp; National University of Singapore</li><li>arxiv: <a href="https://arxiv.org/abs/1708.05595" target="_blank" rel="external">https://arxiv.org/abs/1708.05595</a></li></ul><p><strong>PiCANet: Learning Pixel-wise Contextual Attention in ConvNets and Its Application in Saliency Detection</strong></p><p><a href="https://arxiv.org/abs/1708.06433" target="_blank" rel="external">https://arxiv.org/abs/1708.06433</a></p><p><strong>DeepFeat: A Bottom Up and Top Down Saliency Model Based on Deep Features of Convolutional Neural Nets</strong></p><p><a href="https://arxiv.org/abs/1709.02495" target="_blank" rel="external">https://arxiv.org/abs/1709.02495</a></p><p><strong>Deep saliency: What is learnt by a deep network about saliency?</strong></p><ul><li>intro: 2nd Workshop on Visualisation for Deep Learning in the 34th International Conference On Machine Learning</li><li>arxiv: <a href="https://arxiv.org/abs/1801.04261" target="_blank" rel="external">https://arxiv.org/abs/1801.04261</a></li></ul><h1 id="Video-Saliency-Detection"><a href="#Video-Saliency-Detection" class="headerlink" title="Video Saliency Detection"></a>Video Saliency Detection</h1><p><strong>Deep Learning For Video Saliency Detection</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1702.00871" target="_blank" rel="external">https://arxiv.org/abs/1702.00871</a></li></ul><p><strong>Video Salient Object Detection Using Spatiotemporal Deep Features</strong></p><p><a href="https://arxiv.org/abs/1708.01447" target="_blank" rel="external">https://arxiv.org/abs/1708.01447</a></p><p><strong>Predicting Video Saliency with Object-to-Motion CNN and Two-layer Convolutional LSTM</strong></p><p><a href="https://arxiv.org/abs/1709.06316" target="_blank" rel="external">https://arxiv.org/abs/1709.06316</a></p><h1 id="Visual-Relationship-Detection"><a href="#Visual-Relationship-Detection" class="headerlink" title="Visual Relationship Detection"></a>Visual Relationship Detection</h1><p><strong>Visual Relationship Detection with Language Priors</strong></p><ul><li>intro: ECCV 2016 oral</li><li>paper: <a href="https://cs.stanford.edu/people/ranjaykrishna/vrd/vrd.pdf" target="_blank" rel="external">https://cs.stanford.edu/people/ranjaykrishna/vrd/vrd.pdf</a></li><li>github: <a href="https://github.com/Prof-Lu-Cewu/Visual-Relationship-Detection" target="_blank" rel="external">https://github.com/Prof-Lu-Cewu/Visual-Relationship-Detection</a></li></ul><p><strong>ViP-CNN: A Visual Phrase Reasoning Convolutional Neural Network for Visual Relationship Detection</strong></p><ul><li>intro: Visual Phrase reasoning Convolutional Neural Network (ViP-CNN), Visual Phrase Reasoning Structure (VPRS)</li><li>arxiv: <a href="https://arxiv.org/abs/1702.07191" target="_blank" rel="external">https://arxiv.org/abs/1702.07191</a></li></ul><p><strong>Visual Translation Embedding Network for Visual Relation Detection</strong></p><ul><li>arxiv: <a href="https://www.arxiv.org/abs/1702.08319" target="_blank" rel="external">https://www.arxiv.org/abs/1702.08319</a></li></ul><p><strong>Deep Variation-structured Reinforcement Learning for Visual Relationship and Attribute Detection</strong></p><ul><li>intro: CVPR 2017 spotlight paper</li><li>arxiv: <a href="https://arxiv.org/abs/1703.03054" target="_blank" rel="external">https://arxiv.org/abs/1703.03054</a></li></ul><p><strong>Detecting Visual Relationships with Deep Relational Networks</strong></p><ul><li>intro: CVPR 2017 oral. The Chinese University of Hong Kong</li><li>arxiv: <a href="https://arxiv.org/abs/1704.03114" target="_blank" rel="external">https://arxiv.org/abs/1704.03114</a></li></ul><p><strong>Identifying Spatial Relations in Images using Convolutional Neural Networks</strong></p><p><a href="https://arxiv.org/abs/1706.04215" target="_blank" rel="external">https://arxiv.org/abs/1706.04215</a></p><p><strong>PPR-FCN: Weakly Supervised Visual Relation Detection via Parallel Pairwise R-FCN</strong></p><ul><li>intro: ICCV</li><li>arxiv: <a href="https://arxiv.org/abs/1708.01956" target="_blank" rel="external">https://arxiv.org/abs/1708.01956</a></li></ul><p><strong>Natural Language Guided Visual Relationship Detection</strong></p><p><a href="https://arxiv.org/abs/1711.06032" target="_blank" rel="external">https://arxiv.org/abs/1711.06032</a></p><h1 id="Face-Deteciton"><a href="#Face-Deteciton" class="headerlink" title="Face Deteciton"></a>Face Deteciton</h1><p><strong>Multi-view Face Detection Using Deep Convolutional Neural Networks</strong></p><ul><li>intro: Yahoo</li><li>arxiv: <a href="http://arxiv.org/abs/1502.02766" target="_blank" rel="external">http://arxiv.org/abs/1502.02766</a></li><li>github: <a href="https://github.com/guoyilin/FaceDetection_CNN" target="_blank" rel="external">https://github.com/guoyilin/FaceDetection_CNN</a></li></ul><p><strong>From Facial Parts Responses to Face Detection: A Deep Learning Approach</strong></p><p><img src="http://personal.ie.cuhk.edu.hk/~ys014/projects/Faceness/support/index.png" alt=""></p><ul><li>intro: ICCV 2015. CUHK</li><li>project page: <a href="http://personal.ie.cuhk.edu.hk/~ys014/projects/Faceness/Faceness.html" target="_blank" rel="external">http://personal.ie.cuhk.edu.hk/~ys014/projects/Faceness/Faceness.html</a></li><li>arxiv: <a href="https://arxiv.org/abs/1509.06451" target="_blank" rel="external">https://arxiv.org/abs/1509.06451</a></li><li>paper: <a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Yang_From_Facial_Parts_ICCV_2015_paper.pdf" target="_blank" rel="external">http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Yang_From_Facial_Parts_ICCV_2015_paper.pdf</a></li></ul><p><strong>Compact Convolutional Neural Network Cascade for Face Detection</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1508.01292" target="_blank" rel="external">http://arxiv.org/abs/1508.01292</a></li><li>github: <a href="https://github.com/Bkmz21/FD-Evaluation" target="_blank" rel="external">https://github.com/Bkmz21/FD-Evaluation</a></li><li>github: <a href="https://github.com/Bkmz21/CompactCNNCascade" target="_blank" rel="external">https://github.com/Bkmz21/CompactCNNCascade</a></li></ul><p><strong>Face Detection with End-to-End Integration of a ConvNet and a 3D Model</strong></p><ul><li>intro: ECCV 2016</li><li>arxiv: <a href="https://arxiv.org/abs/1606.00850" target="_blank" rel="external">https://arxiv.org/abs/1606.00850</a></li><li>github(MXNet): <a href="https://github.com/tfwu/FaceDetection-ConvNet-3D" target="_blank" rel="external">https://github.com/tfwu/FaceDetection-ConvNet-3D</a></li></ul><p><strong>CMS-RCNN: Contextual Multi-Scale Region-based CNN for Unconstrained Face Detection</strong></p><ul><li>intro: CMU</li><li>arxiv: <a href="https://arxiv.org/abs/1606.05413" target="_blank" rel="external">https://arxiv.org/abs/1606.05413</a></li></ul><p><strong>Towards a Deep Learning Framework for Unconstrained Face Detection</strong></p><ul><li>intro: overlap with CMS-RCNN</li><li>arxiv: <a href="https://arxiv.org/abs/1612.05322" target="_blank" rel="external">https://arxiv.org/abs/1612.05322</a></li></ul><p><strong>Supervised Transformer Network for Efficient Face Detection</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1607.05477" target="_blank" rel="external">http://arxiv.org/abs/1607.05477</a></li></ul><p><strong>UnitBox: An Advanced Object Detection Network</strong></p><ul><li>intro: ACM MM 2016</li><li>keywords: IOULoss</li><li>arxiv: <a href="http://arxiv.org/abs/1608.01471" target="_blank" rel="external">http://arxiv.org/abs/1608.01471</a></li></ul><p><strong>Bootstrapping Face Detection with Hard Negative Examples</strong></p><ul><li>author: 万韶华 @ 小米.</li><li>intro: Faster R-CNN, hard negative mining. state-of-the-art on the FDDB dataset</li><li>arxiv: <a href="http://arxiv.org/abs/1608.02236" target="_blank" rel="external">http://arxiv.org/abs/1608.02236</a></li></ul><p><strong>Grid Loss: Detecting Occluded Faces</strong></p><ul><li>intro: ECCV 2016</li><li>arxiv: <a href="https://arxiv.org/abs/1609.00129" target="_blank" rel="external">https://arxiv.org/abs/1609.00129</a></li><li>paper: <a href="http://lrs.icg.tugraz.at/pubs/opitz_eccv_16.pdf" target="_blank" rel="external">http://lrs.icg.tugraz.at/pubs/opitz_eccv_16.pdf</a></li><li>poster: <a href="http://www.eccv2016.org/files/posters/P-2A-34.pdf" target="_blank" rel="external">http://www.eccv2016.org/files/posters/P-2A-34.pdf</a></li></ul><p><strong>A Multi-Scale Cascade Fully Convolutional Network Face Detector</strong></p><ul><li>intro: ICPR 2016</li><li>arxiv: <a href="http://arxiv.org/abs/1609.03536" target="_blank" rel="external">http://arxiv.org/abs/1609.03536</a></li></ul><h2 id="MTCNN"><a href="#MTCNN" class="headerlink" title="MTCNN"></a>MTCNN</h2><p><strong>Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks</strong></p><p><strong>Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Neural Networks</strong></p><p><img src="https://kpzhang93.github.io/MTCNN_face_detection_alignment/support/index.png" alt=""></p><ul><li>project page: <a href="https://kpzhang93.github.io/MTCNN_face_detection_alignment/index.html" target="_blank" rel="external">https://kpzhang93.github.io/MTCNN_face_detection_alignment/index.html</a></li><li>arxiv: <a href="https://arxiv.org/abs/1604.02878" target="_blank" rel="external">https://arxiv.org/abs/1604.02878</a></li><li>github(official, Matlab): <a href="https://github.com/kpzhang93/MTCNN_face_detection_alignment" target="_blank" rel="external">https://github.com/kpzhang93/MTCNN_face_detection_alignment</a></li><li>github: <a href="https://github.com/pangyupo/mxnet_mtcnn_face_detection" target="_blank" rel="external">https://github.com/pangyupo/mxnet_mtcnn_face_detection</a></li><li>github: <a href="https://github.com/DaFuCoding/MTCNN_Caffe" target="_blank" rel="external">https://github.com/DaFuCoding/MTCNN_Caffe</a></li><li>github(MXNet): <a href="https://github.com/Seanlinx/mtcnn" target="_blank" rel="external">https://github.com/Seanlinx/mtcnn</a></li><li>github: <a href="https://github.com/Pi-DeepLearning/RaspberryPi-FaceDetection-MTCNN-Caffe-With-Motion" target="_blank" rel="external">https://github.com/Pi-DeepLearning/RaspberryPi-FaceDetection-MTCNN-Caffe-With-Motion</a></li><li>github(Caffe): <a href="https://github.com/foreverYoungGitHub/MTCNN" target="_blank" rel="external">https://github.com/foreverYoungGitHub/MTCNN</a></li><li>github: <a href="https://github.com/CongWeilin/mtcnn-caffe" target="_blank" rel="external">https://github.com/CongWeilin/mtcnn-caffe</a></li><li>github(OpenCV+OpenBlas): <a href="https://github.com/AlphaQi/MTCNN-light" target="_blank" rel="external">https://github.com/AlphaQi/MTCNN-light</a></li><li>github(Tensorflow+golang): <a href="https://github.com/jdeng/goface" target="_blank" rel="external">https://github.com/jdeng/goface</a></li></ul><p><strong>Face Detection using Deep Learning: An Improved Faster RCNN Approach</strong></p><ul><li>intro: DeepIR Inc</li><li>arxiv: <a href="https://arxiv.org/abs/1701.08289" target="_blank" rel="external">https://arxiv.org/abs/1701.08289</a></li></ul><p><strong>Faceness-Net: Face Detection through Deep Facial Part Responses</strong></p><ul><li>intro: An extended version of ICCV 2015 paper</li><li>arxiv: <a href="https://arxiv.org/abs/1701.08393" target="_blank" rel="external">https://arxiv.org/abs/1701.08393</a></li></ul><p><strong>Multi-Path Region-Based Convolutional Neural Network for Accurate Detection of Unconstrained “Hard Faces”</strong></p><ul><li>intro: CVPR 2017. MP-RCNN, MP-RPN</li><li>arxiv: <a href="https://arxiv.org/abs/1703.09145" target="_blank" rel="external">https://arxiv.org/abs/1703.09145</a></li></ul><p><strong>End-To-End Face Detection and Recognition</strong></p><p><a href="https://arxiv.org/abs/1703.10818" target="_blank" rel="external">https://arxiv.org/abs/1703.10818</a></p><p><strong>Face R-CNN</strong></p><p><a href="https://arxiv.org/abs/1706.01061" target="_blank" rel="external">https://arxiv.org/abs/1706.01061</a></p><p><strong>Face Detection through Scale-Friendly Deep Convolutional Networks</strong></p><p><a href="https://arxiv.org/abs/1706.02863" target="_blank" rel="external">https://arxiv.org/abs/1706.02863</a></p><p><strong>Scale-Aware Face Detection</strong></p><ul><li>intro: CVPR 2017. SenseTime &amp; Tsinghua University</li><li>arxiv: <a href="https://arxiv.org/abs/1706.09876" target="_blank" rel="external">https://arxiv.org/abs/1706.09876</a></li></ul><p><strong>Multi-Branch Fully Convolutional Network for Face Detection</strong></p><p><a href="https://arxiv.org/abs/1707.06330" target="_blank" rel="external">https://arxiv.org/abs/1707.06330</a></p><p><strong>SSH: Single Stage Headless Face Detector</strong></p><ul><li>intro: ICCV 2017. University of Maryland</li><li>arxiv: <a href="https://arxiv.org/abs/1708.03979" target="_blank" rel="external">https://arxiv.org/abs/1708.03979</a></li><li>github(official, Caffe): <a href="https://github.com/mahyarnajibi/SSH" target="_blank" rel="external">https://github.com/mahyarnajibi/SSH</a></li></ul><p><strong>Dockerface: an easy to install and use Faster R-CNN face detector in a Docker container</strong></p><p><a href="https://arxiv.org/abs/1708.04370" target="_blank" rel="external">https://arxiv.org/abs/1708.04370</a></p><p><strong>FaceBoxes: A CPU Real-time Face Detector with High Accuracy</strong></p><ul><li>intro: IJCB 2017</li><li>keywords: Rapidly Digested Convolutional Layers (RDCL), Multiple Scale Convolutional Layers (MSCL)</li><li>intro: the proposed detector runs at 20 FPS on a single CPU core and 125 FPS using a GPU for VGA-resolution images</li><li>arxiv: <a href="https://arxiv.org/abs/1708.05234" target="_blank" rel="external">https://arxiv.org/abs/1708.05234</a></li></ul><p><strong>S3FD: Single Shot Scale-invariant Face Detector</strong></p><ul><li>intro: ICCV 2017. Chinese Academy of Sciences</li><li>intro: can run at 36 FPS on a Nvidia Titan X (Pascal) for VGA-resolution images</li><li>arxiv: <a href="https://arxiv.org/abs/1708.05237" target="_blank" rel="external">https://arxiv.org/abs/1708.05237</a></li><li>github: <a href="https://github.com//clcarwin/SFD_pytorch" target="_blank" rel="external">https://github.com//clcarwin/SFD_pytorch</a></li></ul><p><strong>Detecting Faces Using Region-based Fully Convolutional Networks</strong></p><p><a href="https://arxiv.org/abs/1709.05256" target="_blank" rel="external">https://arxiv.org/abs/1709.05256</a></p><p><strong>AffordanceNet: An End-to-End Deep Learning Approach for Object Affordance Detection</strong></p><p><a href="https://arxiv.org/abs/1709.07326" target="_blank" rel="external">https://arxiv.org/abs/1709.07326</a></p><p><strong>Face Attention Network: An effective Face Detector for the Occluded Faces</strong></p><p><a href="https://arxiv.org/abs/1711.07246" target="_blank" rel="external">https://arxiv.org/abs/1711.07246</a></p><p><strong>Feature Agglomeration Networks for Single Stage Face Detection</strong></p><p><a href="https://arxiv.org/abs/1712.00721" target="_blank" rel="external">https://arxiv.org/abs/1712.00721</a></p><p><strong>Face Detection Using Improved Faster RCNN</strong></p><ul><li>intro: Huawei Cloud BU</li><li>arxiv: <a href="https://arxiv.org/abs/1802.02142" target="_blank" rel="external">https://arxiv.org/abs/1802.02142</a></li></ul><p><strong>PyramidBox: A Context-assisted Single Shot Face Detector</strong></p><ul><li>intro: Baidu, Inc</li><li>arxiv: <a href="https://arxiv.org/abs/1803.07737" target="_blank" rel="external">https://arxiv.org/abs/1803.07737</a></li></ul><h2 id="Detect-Small-Faces"><a href="#Detect-Small-Faces" class="headerlink" title="Detect Small Faces"></a>Detect Small Faces</h2><p><strong>Finding Tiny Faces</strong></p><ul><li>intro: CVPR 2017. CMU</li><li>project page: <a href="http://www.cs.cmu.edu/~peiyunh/tiny/index.html" target="_blank" rel="external">http://www.cs.cmu.edu/~peiyunh/tiny/index.html</a></li><li>arxiv: <a href="https://arxiv.org/abs/1612.04402" target="_blank" rel="external">https://arxiv.org/abs/1612.04402</a></li><li>github(official, Matlab): <a href="https://github.com/peiyunh/tiny" target="_blank" rel="external">https://github.com/peiyunh/tiny</a></li><li>github(inference-only): <a href="https://github.com/chinakook/hr101_mxnet" target="_blank" rel="external">https://github.com/chinakook/hr101_mxnet</a></li><li>github: <a href="https://github.com/cydonia999/Tiny_Faces_in_Tensorflow" target="_blank" rel="external">https://github.com/cydonia999/Tiny_Faces_in_Tensorflow</a></li></ul><p><strong>Detecting and counting tiny faces</strong></p><ul><li>intro: ENS Paris-Saclay. ExtendedTinyFaces</li><li>intro: Detecting and counting small objects - Analysis, review and application to counting</li><li>arxiv: <a href="https://arxiv.org/abs/1801.06504" target="_blank" rel="external">https://arxiv.org/abs/1801.06504</a></li><li>github: <a href="https://github.com/alexattia/ExtendedTinyFaces" target="_blank" rel="external">https://github.com/alexattia/ExtendedTinyFaces</a></li></ul><p><strong>Seeing Small Faces from Robust Anchor’s Perspective</strong></p><ul><li>intro: CVPR 2018</li><li>arxiv: <a href="https://arxiv.org/abs/1802.09058" target="_blank" rel="external">https://arxiv.org/abs/1802.09058</a></li></ul><p><strong>Face-MagNet: Magnifying Feature Maps to Detect Small Faces</strong></p><ul><li>intro: WACV 2018</li><li>keywords: Face Magnifier Network (Face-MageNet)</li><li>arxiv: <a href="https://arxiv.org/abs/1803.05258" target="_blank" rel="external">https://arxiv.org/abs/1803.05258</a></li><li>github: <a href="https://github.com/po0ya/face-magnet" target="_blank" rel="external">https://github.com/po0ya/face-magnet</a></li></ul><h1 id="Person-Head-Detection"><a href="#Person-Head-Detection" class="headerlink" title="Person Head Detection"></a>Person Head Detection</h1><p><strong>Context-aware CNNs for person head detection</strong></p><ul><li>intro: ICCV 2015</li><li>project page: <a href="http://www.di.ens.fr/willow/research/headdetection/" target="_blank" rel="external">http://www.di.ens.fr/willow/research/headdetection/</a></li><li>arxiv: <a href="http://arxiv.org/abs/1511.07917" target="_blank" rel="external">http://arxiv.org/abs/1511.07917</a></li><li>github: <a href="https://github.com/aosokin/cnn_head_detection" target="_blank" rel="external">https://github.com/aosokin/cnn_head_detection</a></li></ul><h1 id="Pedestrian-Detection-People-Detection"><a href="#Pedestrian-Detection-People-Detection" class="headerlink" title="Pedestrian Detection / People Detection"></a>Pedestrian Detection / People Detection</h1><p><strong>Pedestrian Detection aided by Deep Learning Semantic Tasks</strong></p><ul><li>intro: CVPR 2015</li><li>project page: <a href="http://mmlab.ie.cuhk.edu.hk/projects/TA-CNN/" target="_blank" rel="external">http://mmlab.ie.cuhk.edu.hk/projects/TA-CNN/</a></li><li>arxiv: <a href="http://arxiv.org/abs/1412.0069" target="_blank" rel="external">http://arxiv.org/abs/1412.0069</a></li></ul><p><strong>Deep Learning Strong Parts for Pedestrian Detection</strong></p><ul><li>intro: ICCV 2015. CUHK. DeepParts</li><li>intro: Achieving 11.89% average miss rate on Caltech Pedestrian Dataset</li><li>paper: <a href="http://personal.ie.cuhk.edu.hk/~pluo/pdf/tianLWTiccv15.pdf" target="_blank" rel="external">http://personal.ie.cuhk.edu.hk/~pluo/pdf/tianLWTiccv15.pdf</a></li></ul><p><strong>Taking a Deeper Look at Pedestrians</strong></p><ul><li>intro: CVPR 2015</li><li>arxiv: <a href="https://arxiv.org/abs/1501.05790" target="_blank" rel="external">https://arxiv.org/abs/1501.05790</a></li></ul><p><strong>Convolutional Channel Features</strong></p><ul><li>intro: ICCV 2015</li><li>arxiv: <a href="https://arxiv.org/abs/1504.07339" target="_blank" rel="external">https://arxiv.org/abs/1504.07339</a></li><li>github: <a href="https://github.com/byangderek/CCF" target="_blank" rel="external">https://github.com/byangderek/CCF</a></li></ul><p><strong>End-to-end people detection in crowded scenes</strong></p><p><img src="/assets/object-detection-materials/end_to_end_people_detection_in_crowded_scenes.jpg" alt=""></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1506.04878" target="_blank" rel="external">http://arxiv.org/abs/1506.04878</a></li><li>github: <a href="https://github.com/Russell91/reinspect" target="_blank" rel="external">https://github.com/Russell91/reinspect</a></li><li>ipn: <a href="http://nbviewer.ipython.org/github/Russell91/ReInspect/blob/master/evaluation_reinspect.ipynb" target="_blank" rel="external">http://nbviewer.ipython.org/github/Russell91/ReInspect/blob/master/evaluation_reinspect.ipynb</a></li><li>youtube: <a href="https://www.youtube.com/watch?v=QeWl0h3kQ24" target="_blank" rel="external">https://www.youtube.com/watch?v=QeWl0h3kQ24</a></li></ul><p><strong>Learning Complexity-Aware Cascades for Deep Pedestrian Detection</strong></p><ul><li>intro: ICCV 2015</li><li>arxiv: <a href="https://arxiv.org/abs/1507.05348" target="_blank" rel="external">https://arxiv.org/abs/1507.05348</a></li></ul><p><strong>Deep convolutional neural networks for pedestrian detection</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1510.03608" target="_blank" rel="external">http://arxiv.org/abs/1510.03608</a></li><li>github: <a href="https://github.com/DenisTome/DeepPed" target="_blank" rel="external">https://github.com/DenisTome/DeepPed</a></li></ul><p><strong>Scale-aware Fast R-CNN for Pedestrian Detection</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1510.08160" target="_blank" rel="external">https://arxiv.org/abs/1510.08160</a></li></ul><p><strong>New algorithm improves speed and accuracy of pedestrian detection</strong></p><ul><li>blog: <a href="http://www.eurekalert.org/pub_releases/2016-02/uoc--nai020516.php" target="_blank" rel="external">http://www.eurekalert.org/pub_releases/2016-02/uoc–nai020516.php</a></li></ul><p><strong>Pushing the Limits of Deep CNNs for Pedestrian Detection</strong></p><ul><li>intro: “set a new record on the Caltech pedestrian dataset, lowering the log-average miss rate from 11.7% to 8.9%”</li><li>arxiv: <a href="http://arxiv.org/abs/1603.04525" target="_blank" rel="external">http://arxiv.org/abs/1603.04525</a></li></ul><p><strong>A Real-Time Deep Learning Pedestrian Detector for Robot Navigation</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1607.04436" target="_blank" rel="external">http://arxiv.org/abs/1607.04436</a></li></ul><p><strong>A Real-Time Pedestrian Detector using Deep Learning for Human-Aware Navigation</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1607.04441" target="_blank" rel="external">http://arxiv.org/abs/1607.04441</a></li></ul><p><strong>Is Faster R-CNN Doing Well for Pedestrian Detection?</strong></p><ul><li>intro: ECCV 2016</li><li>arxiv: <a href="http://arxiv.org/abs/1607.07032" target="_blank" rel="external">http://arxiv.org/abs/1607.07032</a></li><li>github: <a href="https://github.com/zhangliliang/RPN_BF/tree/RPN-pedestrian" target="_blank" rel="external">https://github.com/zhangliliang/RPN_BF/tree/RPN-pedestrian</a></li></ul><p><strong>Unsupervised Deep Domain Adaptation for Pedestrian Detection</strong></p><ul><li>intro: ECCV Workshop 2016</li><li>arxiv: <a href="https://arxiv.org/abs/1802.03269" target="_blank" rel="external">https://arxiv.org/abs/1802.03269</a></li></ul><p><strong>Reduced Memory Region Based Deep Convolutional Neural Network Detection</strong></p><ul><li>intro: IEEE 2016 ICCE-Berlin</li><li>arxiv: <a href="http://arxiv.org/abs/1609.02500" target="_blank" rel="external">http://arxiv.org/abs/1609.02500</a></li></ul><p><strong>Fused DNN: A deep neural network fusion approach to fast and robust pedestrian detection</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1610.03466" target="_blank" rel="external">https://arxiv.org/abs/1610.03466</a></li></ul><p><strong>Detecting People in Artwork with CNNs</strong></p><ul><li>intro: ECCV 2016 Workshops</li><li>arxiv: <a href="https://arxiv.org/abs/1610.08871" target="_blank" rel="external">https://arxiv.org/abs/1610.08871</a></li></ul><p><strong>Multispectral Deep Neural Networks for Pedestrian Detection</strong></p><ul><li>intro: BMVC 2016 oral</li><li>arxiv: <a href="https://arxiv.org/abs/1611.02644" target="_blank" rel="external">https://arxiv.org/abs/1611.02644</a></li></ul><p><strong>Deep Multi-camera People Detection</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1702.04593" target="_blank" rel="external">https://arxiv.org/abs/1702.04593</a></li></ul><p><strong>Expecting the Unexpected: Training Detectors for Unusual Pedestrians with Adversarial Imposters</strong></p><ul><li>intro: CVPR 2017</li><li>project page: <a href="http://ml.cs.tsinghua.edu.cn:5000/publications/synunity/" target="_blank" rel="external">http://ml.cs.tsinghua.edu.cn:5000/publications/synunity/</a></li><li>arxiv: <a href="https://arxiv.org/abs/1703.06283" target="_blank" rel="external">https://arxiv.org/abs/1703.06283</a></li><li>github(Tensorflow): <a href="https://github.com/huangshiyu13/RPNplus" target="_blank" rel="external">https://github.com/huangshiyu13/RPNplus</a></li></ul><p><strong>Illuminating Pedestrians via Simultaneous Detection &amp; Segmentation</strong></p><p>[<a href="https://arxiv.org/abs/1706.08564](https://arxiv.org/abs/1706.08564" target="_blank" rel="external">https://arxiv.org/abs/1706.08564](https://arxiv.org/abs/1706.08564</a></p><p><strong>Rotational Rectification Network for Robust Pedestrian Detection</strong></p><ul><li>intro: CMU &amp; Volvo Construction</li><li>arxiv: <a href="https://arxiv.org/abs/1706.08917" target="_blank" rel="external">https://arxiv.org/abs/1706.08917</a></li></ul><p><strong>STD-PD: Generating Synthetic Training Data for Pedestrian Detection in Unannotated Videos</strong></p><ul><li>intro: The University of North Carolina at Chapel Hill</li><li>arxiv: <a href="https://arxiv.org/abs/1707.09100" target="_blank" rel="external">https://arxiv.org/abs/1707.09100</a></li></ul><p><strong>Too Far to See? Not Really! — Pedestrian Detection with Scale-aware Localization Policy</strong></p><p><a href="https://arxiv.org/abs/1709.00235" target="_blank" rel="external">https://arxiv.org/abs/1709.00235</a></p><p><strong>Repulsion Loss: Detecting Pedestrians in a Crowd</strong></p><p><a href="https://arxiv.org/abs/1711.07752" target="_blank" rel="external">https://arxiv.org/abs/1711.07752</a></p><p><strong>Aggregated Channels Network for Real-Time Pedestrian Detection</strong></p><p><a href="https://arxiv.org/abs/1801.00476" target="_blank" rel="external">https://arxiv.org/abs/1801.00476</a></p><p><strong>Illumination-aware Faster R-CNN for Robust Multispectral Pedestrian Detection</strong></p><ul><li>intro: State Key Lab of CAD&amp;CG, Zhejiang University</li><li>arxiv: <a href="https://arxiv.org/abs/1803.05347" target="_blank" rel="external">https://arxiv.org/abs/1803.05347</a></li></ul><h1 id="Vehicle-Detection"><a href="#Vehicle-Detection" class="headerlink" title="Vehicle Detection"></a>Vehicle Detection</h1><p><strong>DAVE: A Unified Framework for Fast Vehicle Detection and Annotation</strong></p><ul><li>intro: ECCV 2016</li><li>arxiv: <a href="http://arxiv.org/abs/1607.04564" target="_blank" rel="external">http://arxiv.org/abs/1607.04564</a></li></ul><p><strong>Evolving Boxes for fast Vehicle Detection</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1702.00254" target="_blank" rel="external">https://arxiv.org/abs/1702.00254</a></li></ul><p><strong>Fine-Grained Car Detection for Visual Census Estimation</strong></p><ul><li>intro: AAAI 2016</li><li>arxiv: <a href="https://arxiv.org/abs/1709.02480" target="_blank" rel="external">https://arxiv.org/abs/1709.02480</a></li></ul><h1 id="Traffic-Sign-Detection"><a href="#Traffic-Sign-Detection" class="headerlink" title="Traffic-Sign Detection"></a>Traffic-Sign Detection</h1><p><strong>Traffic-Sign Detection and Classification in the Wild</strong></p><ul><li>project page(code+dataset): <a href="http://cg.cs.tsinghua.edu.cn/traffic-sign/" target="_blank" rel="external">http://cg.cs.tsinghua.edu.cn/traffic-sign/</a></li><li>paper: <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhu_Traffic-Sign_Detection_and_CVPR_2016_paper.pdf" target="_blank" rel="external">http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhu_Traffic-Sign_Detection_and_CVPR_2016_paper.pdf</a></li><li>code &amp; model: <a href="http://cg.cs.tsinghua.edu.cn/traffic-sign/data_model_code/newdata0411.zip" target="_blank" rel="external">http://cg.cs.tsinghua.edu.cn/traffic-sign/data_model_code/newdata0411.zip</a></li></ul><p><strong>Detecting Small Signs from Large Images</strong></p><ul><li>intro: IEEE Conference on Information Reuse and Integration (IRI) 2017 oral</li><li>arxiv: <a href="https://arxiv.org/abs/1706.08574" target="_blank" rel="external">https://arxiv.org/abs/1706.08574</a></li></ul><h1 id="Skeleton-Detection"><a href="#Skeleton-Detection" class="headerlink" title="Skeleton Detection"></a>Skeleton Detection</h1><p><strong>Object Skeleton Extraction in Natural Images by Fusing Scale-associated Deep Side Outputs</strong></p><p><img src="https://camo.githubusercontent.com/88a65f132aa4ae4b0477e3ad02c13cdc498377d9/687474703a2f2f37786e37777a2e636f6d312e7a302e676c622e636c6f7564646e2e636f6d2f44656570536b656c65746f6e2e706e673f696d61676556696577322f322f772f353030" alt=""></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1603.09446" target="_blank" rel="external">http://arxiv.org/abs/1603.09446</a></li><li>github: <a href="https://github.com/zeakey/DeepSkeleton" target="_blank" rel="external">https://github.com/zeakey/DeepSkeleton</a></li></ul><p><strong>DeepSkeleton: Learning Multi-task Scale-associated Deep Side Outputs for Object Skeleton Extraction in Natural Images</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1609.03659" target="_blank" rel="external">http://arxiv.org/abs/1609.03659</a></li></ul><p><strong>SRN: Side-output Residual Network for Object Symmetry Detection in the Wild</strong></p><ul><li>intro: CVPR 2017</li><li>arxiv: <a href="https://arxiv.org/abs/1703.02243" target="_blank" rel="external">https://arxiv.org/abs/1703.02243</a></li><li>github: <a href="https://github.com/KevinKecc/SRN" target="_blank" rel="external">https://github.com/KevinKecc/SRN</a></li></ul><p><strong>Hi-Fi: Hierarchical Feature Integration for Skeleton Detection</strong></p><p><a href="https://arxiv.org/abs/1801.01849" target="_blank" rel="external">https://arxiv.org/abs/1801.01849</a></p><h1 id="Fruit-Detection"><a href="#Fruit-Detection" class="headerlink" title="Fruit Detection"></a>Fruit Detection</h1><p><strong>Deep Fruit Detection in Orchards</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1610.03677" target="_blank" rel="external">https://arxiv.org/abs/1610.03677</a></li></ul><p><strong>Image Segmentation for Fruit Detection and Yield Estimation in Apple Orchards</strong></p><ul><li>intro: The Journal of Field Robotics in May 2016</li><li>project page: <a href="http://confluence.acfr.usyd.edu.au/display/AGPub/" target="_blank" rel="external">http://confluence.acfr.usyd.edu.au/display/AGPub/</a></li><li>arxiv: <a href="https://arxiv.org/abs/1610.08120" target="_blank" rel="external">https://arxiv.org/abs/1610.08120</a></li></ul><h2 id="Shadow-Detection"><a href="#Shadow-Detection" class="headerlink" title="Shadow Detection"></a>Shadow Detection</h2><p><strong>Fast Shadow Detection from a Single Image Using a Patched Convolutional Neural Network</strong></p><p><a href="https://arxiv.org/abs/1709.09283" target="_blank" rel="external">https://arxiv.org/abs/1709.09283</a></p><p><strong>A+D-Net: Shadow Detection with Adversarial Shadow Attenuation</strong></p><p><a href="https://arxiv.org/abs/1712.01361" target="_blank" rel="external">https://arxiv.org/abs/1712.01361</a></p><p><strong>Stacked Conditional Generative Adversarial Networks for Jointly Learning Shadow Detection and Shadow Removal</strong></p><p><a href="https://arxiv.org/abs/1712.02478" target="_blank" rel="external">https://arxiv.org/abs/1712.02478</a></p><p><strong>Direction-aware Spatial Context Features for Shadow Detection</strong></p><p><a href="https://arxiv.org/abs/1712.04142" target="_blank" rel="external">https://arxiv.org/abs/1712.04142</a></p><h1 id="Others-Deteciton"><a href="#Others-Deteciton" class="headerlink" title="Others Deteciton"></a>Others Deteciton</h1><p><strong>Deep Deformation Network for Object Landmark Localization</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1605.01014" target="_blank" rel="external">http://arxiv.org/abs/1605.01014</a></li></ul><p><strong>Fashion Landmark Detection in the Wild</strong></p><ul><li>intro: ECCV 2016</li><li>project page: <a href="http://personal.ie.cuhk.edu.hk/~lz013/projects/FashionLandmarks.html" target="_blank" rel="external">http://personal.ie.cuhk.edu.hk/~lz013/projects/FashionLandmarks.html</a></li><li>arxiv: <a href="http://arxiv.org/abs/1608.03049" target="_blank" rel="external">http://arxiv.org/abs/1608.03049</a></li><li>github(Caffe): <a href="https://github.com/liuziwei7/fashion-landmarks" target="_blank" rel="external">https://github.com/liuziwei7/fashion-landmarks</a></li></ul><p><strong>Deep Learning for Fast and Accurate Fashion Item Detection</strong></p><ul><li>intro: Kuznech Inc.</li><li>intro: MultiBox and Fast R-CNN</li><li>paper: <a href="https://kddfashion2016.mybluemix.net/kddfashion_finalSubmissions/Deep%20Learning%20for%20Fast%20and%20Accurate%20Fashion%20Item%20Detection.pdf" target="_blank" rel="external">https://kddfashion2016.mybluemix.net/kddfashion_finalSubmissions/Deep%20Learning%20for%20Fast%20and%20Accurate%20Fashion%20Item%20Detection.pdf</a></li></ul><p><strong>OSMDeepOD - OSM and Deep Learning based Object Detection from Aerial Imagery (formerly known as “OSM-Crosswalk-Detection”)</strong></p><p><img src="https://raw.githubusercontent.com/geometalab/OSMDeepOD/master/imgs/process.png" alt=""></p><ul><li>github: <a href="https://github.com/geometalab/OSMDeepOD" target="_blank" rel="external">https://github.com/geometalab/OSMDeepOD</a></li></ul><p><strong>Selfie Detection by Synergy-Constraint Based Convolutional Neural Network</strong></p><ul><li>intro:  IEEE SITIS 2016</li><li>arxiv: <a href="https://arxiv.org/abs/1611.04357" target="_blank" rel="external">https://arxiv.org/abs/1611.04357</a></li></ul><p><strong>Associative Embedding:End-to-End Learning for Joint Detection and Grouping</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1611.05424" target="_blank" rel="external">https://arxiv.org/abs/1611.05424</a></li></ul><p><strong>Deep Cuboid Detection: Beyond 2D Bounding Boxes</strong></p><ul><li>intro: CMU &amp; Magic Leap</li><li>arxiv: <a href="https://arxiv.org/abs/1611.10010" target="_blank" rel="external">https://arxiv.org/abs/1611.10010</a></li></ul><p><strong>Automatic Model Based Dataset Generation for Fast and Accurate Crop and Weeds Detection</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1612.03019" target="_blank" rel="external">https://arxiv.org/abs/1612.03019</a></li></ul><p><strong>Deep Learning Logo Detection with Data Expansion by Synthesising Context</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1612.09322" target="_blank" rel="external">https://arxiv.org/abs/1612.09322</a></li></ul><p><strong>Pixel-wise Ear Detection with Convolutional Encoder-Decoder Networks</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1702.00307" target="_blank" rel="external">https://arxiv.org/abs/1702.00307</a></li></ul><p><strong>Automatic Handgun Detection Alarm in Videos Using Deep Learning</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1702.05147" target="_blank" rel="external">https://arxiv.org/abs/1702.05147</a></li><li>results: <a href="https://github.com/SihamTabik/Pistol-Detection-in-Videos" target="_blank" rel="external">https://github.com/SihamTabik/Pistol-Detection-in-Videos</a></li></ul><p><strong>Objects as context for part detection</strong></p><p><a href="https://arxiv.org/abs/1703.09529" target="_blank" rel="external">https://arxiv.org/abs/1703.09529</a></p><p><strong>Using Deep Networks for Drone Detection</strong></p><ul><li>intro: AVSS 2017</li><li>arxiv: <a href="https://arxiv.org/abs/1706.05726" target="_blank" rel="external">https://arxiv.org/abs/1706.05726</a></li></ul><p><strong>Cut, Paste and Learn: Surprisingly Easy Synthesis for Instance Detection</strong></p><ul><li>intro: ICCV 2017</li><li>arxiv: <a href="https://arxiv.org/abs/1708.01642" target="_blank" rel="external">https://arxiv.org/abs/1708.01642</a></li></ul><p><strong>Target Driven Instance Detection</strong></p><p><a href="https://arxiv.org/abs/1803.04610" target="_blank" rel="external">https://arxiv.org/abs/1803.04610</a></p><p><strong>DeepVoting: An Explainable Framework for Semantic Part Detection under Partial Occlusion</strong></p><p><a href="https://arxiv.org/abs/1709.04577" target="_blank" rel="external">https://arxiv.org/abs/1709.04577</a></p><p><strong>VPGNet: Vanishing Point Guided Network for Lane and Road Marking Detection and Recognition</strong></p><ul><li>intro: ICCV 2017</li><li>arxiv: <a href="https://arxiv.org/abs/1710.06288" target="_blank" rel="external">https://arxiv.org/abs/1710.06288</a></li><li>github: <a href="https://github.com/SeokjuLee/VPGNet" target="_blank" rel="external">https://github.com/SeokjuLee/VPGNet</a></li></ul><p><strong>Grab, Pay and Eat: Semantic Food Detection for Smart Restaurants</strong></p><p><a href="https://arxiv.org/abs/1711.05128" target="_blank" rel="external">https://arxiv.org/abs/1711.05128</a></p><p><strong>ReMotENet: Efficient Relevant Motion Event Detection for Large-scale Home Surveillance Videos</strong></p><ul><li>intro: WACV 2018</li><li>arxiv: <a href="https://arxiv.org/abs/1801.02031" target="_blank" rel="external">https://arxiv.org/abs/1801.02031</a></li></ul><h1 id="Object-Proposal"><a href="#Object-Proposal" class="headerlink" title="Object Proposal"></a>Object Proposal</h1><p><strong>DeepProposal: Hunting Objects by Cascading Deep Convolutional Layers</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1510.04445" target="_blank" rel="external">http://arxiv.org/abs/1510.04445</a></li><li>github: <a href="https://github.com/aghodrati/deepproposal" target="_blank" rel="external">https://github.com/aghodrati/deepproposal</a></li></ul><p><strong>Scale-aware Pixel-wise Object Proposal Networks</strong></p><ul><li>intro: IEEE Transactions on Image Processing</li><li>arxiv: <a href="http://arxiv.org/abs/1601.04798" target="_blank" rel="external">http://arxiv.org/abs/1601.04798</a></li></ul><p><strong>Attend Refine Repeat: Active Box Proposal Generation via In-Out Localization</strong></p><ul><li>intro: BMVC 2016. AttractioNet</li><li>arxiv: <a href="https://arxiv.org/abs/1606.04446" target="_blank" rel="external">https://arxiv.org/abs/1606.04446</a></li><li>github: <a href="https://github.com/gidariss/AttractioNet" target="_blank" rel="external">https://github.com/gidariss/AttractioNet</a></li></ul><p><strong>Learning to Segment Object Proposals via Recursive Neural Networks</strong></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1612.01057" target="_blank" rel="external">https://arxiv.org/abs/1612.01057</a></li></ul><p><strong>Learning Detection with Diverse Proposals</strong></p><ul><li>intro: CVPR 2017</li><li>keywords: differentiable Determinantal Point Process (DPP) layer, Learning Detection with Diverse Proposals (LDDP)</li><li>arxiv: <a href="https://arxiv.org/abs/1704.03533" target="_blank" rel="external">https://arxiv.org/abs/1704.03533</a></li></ul><p><strong>ScaleNet: Guiding Object Proposal Generation in Supermarkets and Beyond</strong></p><ul><li>keywords: product detection</li><li>arxiv: <a href="https://arxiv.org/abs/1704.06752" target="_blank" rel="external">https://arxiv.org/abs/1704.06752</a></li></ul><p><strong>Improving Small Object Proposals for Company Logo Detection</strong></p><ul><li>intro: ICMR 2017</li><li>arxiv: <a href="https://arxiv.org/abs/1704.08881" target="_blank" rel="external">https://arxiv.org/abs/1704.08881</a></li></ul><h1 id="Localization"><a href="#Localization" class="headerlink" title="Localization"></a>Localization</h1><p><strong>Beyond Bounding Boxes: Precise Localization of Objects in Images</strong></p><ul><li>intro: PhD Thesis</li><li>homepage: <a href="http://www.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-193.html" target="_blank" rel="external">http://www.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-193.html</a></li><li>phd-thesis: <a href="http://www.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-193.pdf" target="_blank" rel="external">http://www.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-193.pdf</a></li><li>github(“SDS using hypercolumns”): <a href="https://github.com/bharath272/sds" target="_blank" rel="external">https://github.com/bharath272/sds</a></li></ul><p><strong>Weakly Supervised Object Localization with Multi-fold Multiple Instance Learning</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1503.00949" target="_blank" rel="external">http://arxiv.org/abs/1503.00949</a></li></ul><p><strong>Weakly Supervised Object Localization Using Size Estimates</strong></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1608.04314" target="_blank" rel="external">http://arxiv.org/abs/1608.04314</a></li></ul><p><strong>Active Object Localization with Deep Reinforcement Learning</strong></p><ul><li>intro: ICCV 2015</li><li>keywords: Markov Decision Process</li><li>arxiv: <a href="https://arxiv.org/abs/1511.06015" target="_blank" rel="external">https://arxiv.org/abs/1511.06015</a></li></ul><p><strong>Localizing objects using referring expressions</strong></p><ul><li>intro: ECCV 2016</li><li>keywords: LSTM, multiple instance learning (MIL)</li><li>paper: <a href="http://www.umiacs.umd.edu/~varun/files/refexp-ECCV16.pdf" target="_blank" rel="external">http://www.umiacs.umd.edu/~varun/files/refexp-ECCV16.pdf</a></li><li>github: <a href="https://github.com/varun-nagaraja/referring-expressions" target="_blank" rel="external">https://github.com/varun-nagaraja/referring-expressions</a></li></ul><p><strong>LocNet: Improving Localization Accuracy for Object Detection</strong></p><ul><li>intro: CVPR 2016 oral</li><li>arxiv: <a href="http://arxiv.org/abs/1511.07763" target="_blank" rel="external">http://arxiv.org/abs/1511.07763</a></li><li>github: <a href="https://github.com/gidariss/LocNet" target="_blank" rel="external">https://github.com/gidariss/LocNet</a></li></ul><p><strong>Learning Deep Features for Discriminative Localization</strong></p><p><img src="http://cnnlocalization.csail.mit.edu/framework.jpg" alt=""></p><ul><li>homepage: <a href="http://cnnlocalization.csail.mit.edu/" target="_blank" rel="external">http://cnnlocalization.csail.mit.edu/</a></li><li>arxiv: <a href="http://arxiv.org/abs/1512.04150" target="_blank" rel="external">http://arxiv.org/abs/1512.04150</a></li><li>github(Tensorflow): <a href="https://github.com/jazzsaxmafia/Weakly_detector" target="_blank" rel="external">https://github.com/jazzsaxmafia/Weakly_detector</a></li><li>github: <a href="https://github.com/metalbubble/CAM" target="_blank" rel="external">https://github.com/metalbubble/CAM</a></li><li>github: <a href="https://github.com/tdeboissiere/VGG16CAM-keras" target="_blank" rel="external">https://github.com/tdeboissiere/VGG16CAM-keras</a></li></ul><p><strong>ContextLocNet: Context-Aware Deep Network Models for Weakly Supervised Localization</strong></p><p><img src="http://www.di.ens.fr/willow/research/contextlocnet/model.png" alt=""></p><ul><li>intro: ECCV 2016</li><li>project page: <a href="http://www.di.ens.fr/willow/research/contextlocnet/" target="_blank" rel="external">http://www.di.ens.fr/willow/research/contextlocnet/</a></li><li>arxiv: <a href="http://arxiv.org/abs/1609.04331" target="_blank" rel="external">http://arxiv.org/abs/1609.04331</a></li><li>github: <a href="https://github.com/vadimkantorov/contextlocnet" target="_blank" rel="external">https://github.com/vadimkantorov/contextlocnet</a></li></ul><p><strong>Ensemble of Part Detectors for Simultaneous Classification and Localization</strong></p><p><a href="https://arxiv.org/abs/1705.10034" target="_blank" rel="external">https://arxiv.org/abs/1705.10034</a></p><p><strong>STNet: Selective Tuning of Convolutional Networks for Object Localization</strong></p><p><a href="https://arxiv.org/abs/1708.06418" target="_blank" rel="external">https://arxiv.org/abs/1708.06418</a></p><p><strong>Soft Proposal Networks for Weakly Supervised Object Localization</strong></p><ul><li>intro: ICCV 2017</li><li>arxiv: <a href="https://arxiv.org/abs/1709.01829" target="_blank" rel="external">https://arxiv.org/abs/1709.01829</a></li></ul><p><strong>Fine-grained Discriminative Localization via Saliency-guided Faster R-CNN</strong></p><ul><li>intro: ACM MM 2017</li><li>arxiv: <a href="https://arxiv.org/abs/1709.08295" target="_blank" rel="external">https://arxiv.org/abs/1709.08295</a></li></ul><h1 id="Tutorials-Talks"><a href="#Tutorials-Talks" class="headerlink" title="Tutorials / Talks"></a>Tutorials / Talks</h1><p><strong>Convolutional Feature Maps: Elements of efficient (and accurate) CNN-based object detection</strong></p><ul><li>slides: <a href="http://research.microsoft.com/en-us/um/people/kahe/iccv15tutorial/iccv2015_tutorial_convolutional_feature_maps_kaiminghe.pdf" target="_blank" rel="external">http://research.microsoft.com/en-us/um/people/kahe/iccv15tutorial/iccv2015_tutorial_convolutional_feature_maps_kaiminghe.pdf</a></li></ul><p><strong>Towards Good Practices for Recognition &amp; Detection</strong></p><ul><li>intro: Hikvision Research Institute. Supervised Data Augmentation (SDA)</li><li>slides: <a href="http://image-net.org/challenges/talks/2016/Hikvision_at_ImageNet_2016.pdf" target="_blank" rel="external">http://image-net.org/challenges/talks/2016/Hikvision_at_ImageNet_2016.pdf</a></li></ul><h1 id="Projects"><a href="#Projects" class="headerlink" title="Projects"></a>Projects</h1><p><strong>Detectron</strong></p><ul><li>intro: FAIR’s research platform for object detection research, implementing popular algorithms like Mask R-CNN and RetinaNet.</li><li>github: <a href="https://github.com/facebookresearch/Detectron" target="_blank" rel="external">https://github.com/facebookresearch/Detectron</a></li></ul><p><strong>TensorBox: a simple framework for training neural networks to detect objects in images</strong></p><ul><li>intro: “The basic model implements the simple and robust GoogLeNet-OverFeat algorithm.<br>We additionally provide an implementation of the <a href="https://github.com/Russell91/ReInspect/" target="_blank" rel="external">ReInspect</a> algorithm”</li><li>github: <a href="https://github.com/Russell91/TensorBox" target="_blank" rel="external">https://github.com/Russell91/TensorBox</a></li></ul><p><strong>Object detection in torch: Implementation of some object detection frameworks in torch</strong></p><ul><li>github: <a href="https://github.com/fmassa/object-detection.torch" target="_blank" rel="external">https://github.com/fmassa/object-detection.torch</a></li></ul><p><strong>Using DIGITS to train an Object Detection network</strong></p><ul><li>github: <a href="https://github.com/NVIDIA/DIGITS/blob/master/examples/object-detection/README.md" target="_blank" rel="external">https://github.com/NVIDIA/DIGITS/blob/master/examples/object-detection/README.md</a></li></ul><p><strong>FCN-MultiBox Detector</strong></p><ul><li>intro: Full convolution MultiBox Detector (like SSD) implemented in Torch.</li><li>github: <a href="https://github.com/teaonly/FMD.torch" target="_blank" rel="external">https://github.com/teaonly/FMD.torch</a></li></ul><p><strong>KittiBox: A car detection model implemented in Tensorflow.</strong></p><ul><li>keywords: MultiNet</li><li>intro: KittiBox is a collection of scripts to train out model FastBox on the Kitti Object Detection Dataset</li><li>github: <a href="https://github.com/MarvinTeichmann/KittiBox" target="_blank" rel="external">https://github.com/MarvinTeichmann/KittiBox</a></li></ul><p><strong>Deformable Convolutional Networks + MST + Soft-NMS</strong></p><ul><li>github: <a href="https://github.com/bharatsingh430/Deformable-ConvNets" target="_blank" rel="external">https://github.com/bharatsingh430/Deformable-ConvNets</a></li></ul><p><strong>How to Build a Real-time Hand-Detector using Neural Networks (SSD) on Tensorflow</strong></p><ul><li>blog: <a href="https://towardsdatascience.com/how-to-build-a-real-time-hand-detector-using-neural-networks-ssd-on-tensorflow-d6bac0e4b2ce" target="_blank" rel="external">https://towardsdatascience.com/how-to-build-a-real-time-hand-detector-using-neural-networks-ssd-on-tensorflow-d6bac0e4b2ce</a></li><li>github: <a href="https://github.com//victordibia/handtracking" target="_blank" rel="external">https://github.com//victordibia/handtracking</a></li></ul><h1 id="Leaderboard"><a href="#Leaderboard" class="headerlink" title="Leaderboard"></a>Leaderboard</h1><p><strong>Detection Results: VOC2012</strong></p><ul><li>intro: Competition “comp4” (train on additional data)</li><li>homepage: <a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=4" target="_blank" rel="external">http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=4</a></li></ul><h1 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a>Tools</h1><p><strong>BeaverDam: Video annotation tool for deep learning training labels</strong></p><p><a href="https://github.com/antingshen/BeaverDam" target="_blank" rel="external">https://github.com/antingshen/BeaverDam</a></p><h1 id="Blogs"><a href="#Blogs" class="headerlink" title="Blogs"></a>Blogs</h1><p><strong>Convolutional Neural Networks for Object Detection</strong></p><p><a href="http://rnd.azoft.com/convolutional-neural-networks-object-detection/" target="_blank" rel="external">http://rnd.azoft.com/convolutional-neural-networks-object-detection/</a></p><p><strong>Introducing automatic object detection to visual search (Pinterest)</strong></p><ul><li>keywords: Faster R-CNN</li><li>blog: <a href="https://engineering.pinterest.com/blog/introducing-automatic-object-detection-visual-search" target="_blank" rel="external">https://engineering.pinterest.com/blog/introducing-automatic-object-detection-visual-search</a></li><li>demo: <a href="https://engineering.pinterest.com/sites/engineering/files/Visual%20Search%20V1%20-%20Video.mp4" target="_blank" rel="external">https://engineering.pinterest.com/sites/engineering/files/Visual%20Search%20V1%20-%20Video.mp4</a></li><li>review: <a href="https://news.developer.nvidia.com/pinterest-introduces-the-future-of-visual-search/?mkt_tok=eyJpIjoiTnpaa01UWXpPRE0xTURFMiIsInQiOiJJRjcybjkwTmtmallORUhLOFFFODBDclFqUlB3SWlRVXJXb1MrQ013TDRIMGxLQWlBczFIeWg0TFRUdnN2UHY2ZWFiXC9QQVwvQzBHM3B0UzBZblpOSmUyU1FcLzNPWXI4cml2VERwTTJsOFwvOEk9In0%3D" target="_blank" rel="external">https://news.developer.nvidia.com/pinterest-introduces-the-future-of-visual-search/?mkt_tok=eyJpIjoiTnpaa01UWXpPRE0xTURFMiIsInQiOiJJRjcybjkwTmtmallORUhLOFFFODBDclFqUlB3SWlRVXJXb1MrQ013TDRIMGxLQWlBczFIeWg0TFRUdnN2UHY2ZWFiXC9QQVwvQzBHM3B0UzBZblpOSmUyU1FcLzNPWXI4cml2VERwTTJsOFwvOEk9In0%3D</a></li></ul><p><strong>Deep Learning for Object Detection with DIGITS</strong></p><ul><li>blog: <a href="https://devblogs.nvidia.com/parallelforall/deep-learning-object-detection-digits/" target="_blank" rel="external">https://devblogs.nvidia.com/parallelforall/deep-learning-object-detection-digits/</a></li></ul><p><strong>Analyzing The Papers Behind Facebook’s Computer Vision Approach</strong></p><ul><li>keywords: DeepMask, SharpMask, MultiPathNet</li><li>blog: <a href="https://adeshpande3.github.io/adeshpande3.github.io/Analyzing-the-Papers-Behind-Facebook&#39;s-Computer-Vision-Approach/" target="_blank" rel="external">https://adeshpande3.github.io/adeshpande3.github.io/Analyzing-the-Papers-Behind-Facebook’s-Computer-Vision-Approach/</a></li></ul><p><strong>Easily Create High Quality Object Detectors with Deep Learning</strong></p><ul><li>intro: dlib v19.2</li><li>blog: <a href="http://blog.dlib.net/2016/10/easily-create-high-quality-object.html" target="_blank" rel="external">http://blog.dlib.net/2016/10/easily-create-high-quality-object.html</a></li></ul><p><strong>How to Train a Deep-Learned Object Detection Model in the Microsoft Cognitive Toolkit</strong></p><ul><li>blog: <a href="https://blogs.technet.microsoft.com/machinelearning/2016/10/25/how-to-train-a-deep-learned-object-detection-model-in-cntk/" target="_blank" rel="external">https://blogs.technet.microsoft.com/machinelearning/2016/10/25/how-to-train-a-deep-learned-object-detection-model-in-cntk/</a></li><li>github: <a href="https://github.com/Microsoft/CNTK/tree/master/Examples/Image/Detection/FastRCNN" target="_blank" rel="external">https://github.com/Microsoft/CNTK/tree/master/Examples/Image/Detection/FastRCNN</a></li></ul><p><strong>Object Detection in Satellite Imagery, a Low Overhead Approach</strong></p><ul><li>part 1: <a href="https://medium.com/the-downlinq/object-detection-in-satellite-imagery-a-low-overhead-approach-part-i-cbd96154a1b7#.2csh4iwx9" target="_blank" rel="external">https://medium.com/the-downlinq/object-detection-in-satellite-imagery-a-low-overhead-approach-part-i-cbd96154a1b7#.2csh4iwx9</a></li><li>part 2: <a href="https://medium.com/the-downlinq/object-detection-in-satellite-imagery-a-low-overhead-approach-part-ii-893f40122f92#.f9b7dgf64" target="_blank" rel="external">https://medium.com/the-downlinq/object-detection-in-satellite-imagery-a-low-overhead-approach-part-ii-893f40122f92#.f9b7dgf64</a></li></ul><p><strong>You Only Look Twice — Multi-Scale Object Detection in Satellite Imagery With Convolutional Neural Networks</strong></p><ul><li>part 1: <a href="https://medium.com/the-downlinq/you-only-look-twice-multi-scale-object-detection-in-satellite-imagery-with-convolutional-neural-38dad1cf7571#.fmmi2o3of" target="_blank" rel="external">https://medium.com/the-downlinq/you-only-look-twice-multi-scale-object-detection-in-satellite-imagery-with-convolutional-neural-38dad1cf7571#.fmmi2o3of</a></li><li>part 2: <a href="https://medium.com/the-downlinq/you-only-look-twice-multi-scale-object-detection-in-satellite-imagery-with-convolutional-neural-34f72f659588#.nwzarsz1t" target="_blank" rel="external">https://medium.com/the-downlinq/you-only-look-twice-multi-scale-object-detection-in-satellite-imagery-with-convolutional-neural-34f72f659588#.nwzarsz1t</a></li></ul><p><strong>Faster R-CNN Pedestrian and Car Detection</strong></p><ul><li>blog: <a href="https://bigsnarf.wordpress.com/2016/11/07/faster-r-cnn-pedestrian-and-car-detection/" target="_blank" rel="external">https://bigsnarf.wordpress.com/2016/11/07/faster-r-cnn-pedestrian-and-car-detection/</a></li><li>ipn: <a href="https://gist.github.com/bigsnarfdude/2f7b2144065f6056892a98495644d3e0#file-demo_faster_rcnn_notebook-ipynb" target="_blank" rel="external">https://gist.github.com/bigsnarfdude/2f7b2144065f6056892a98495644d3e0#file-demo_faster_rcnn_notebook-ipynb</a></li><li>github: <a href="https://github.com/bigsnarfdude/Faster-RCNN_TF" target="_blank" rel="external">https://github.com/bigsnarfdude/Faster-RCNN_TF</a></li></ul><p><strong>Small U-Net for vehicle detection</strong></p><ul><li>blog: <a href="https://medium.com/@vivek.yadav/small-u-net-for-vehicle-detection-9eec216f9fd6#.md4u80kad" target="_blank" rel="external">https://medium.com/@vivek.yadav/small-u-net-for-vehicle-detection-9eec216f9fd6#.md4u80kad</a></li></ul><p><strong>Region of interest pooling explained</strong></p><ul><li>blog: <a href="https://deepsense.io/region-of-interest-pooling-explained/" target="_blank" rel="external">https://deepsense.io/region-of-interest-pooling-explained/</a></li><li>github: <a href="https://github.com/deepsense-io/roi-pooling" target="_blank" rel="external">https://github.com/deepsense-io/roi-pooling</a></li></ul><p><strong>Supercharge your Computer Vision models with the TensorFlow Object Detection API</strong></p><ul><li>blog: <a href="https://research.googleblog.com/2017/06/supercharge-your-computer-vision-models.html" target="_blank" rel="external">https://research.googleblog.com/2017/06/supercharge-your-computer-vision-models.html</a></li><li>github: <a href="https://github.com/tensorflow/models/tree/master/object_detection" target="_blank" rel="external">https://github.com/tensorflow/models/tree/master/object_detection</a></li></ul><p><strong>Understanding SSD MultiBox — Real-Time Object Detection In Deep Learning</strong></p><p><a href="https://towardsdatascience.com/understanding-ssd-multibox-real-time-object-detection-in-deep-learning-495ef744fab" target="_blank" rel="external">https://towardsdatascience.com/understanding-ssd-multibox-real-time-object-detection-in-deep-learning-495ef744fab</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文转自&lt;a href=&quot;https://handong1587.github.io/deep_learning/2015/10/09/object-detection.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;handong1587的个人博客&lt;/a&gt;，总结的很详细！辛苦了！&lt;/p&gt;
    
    </summary>
    
      <category term="Tech" scheme="http://songit.cn/categories/Tech/"/>
    
    
      <category term="Github" scheme="http://songit.cn/tags/Github/"/>
    
      <category term="DeepLearning" scheme="http://songit.cn/tags/DeepLearning/"/>
    
      <category term="ObjectDetection" scheme="http://songit.cn/tags/ObjectDetection/"/>
    
      <category term="Paper" scheme="http://songit.cn/tags/Paper/"/>
    
  </entry>
  
  <entry>
    <title>数据集（持续更新）</title>
    <link href="http://songit.cn/Datasets/"/>
    <id>http://songit.cn/Datasets/</id>
    <published>2018-01-27T03:10:02.000Z</published>
    <updated>2018-03-27T09:31:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章主要收集网上的一些数据集，记录下来，方便查阅。<br><a id="more"></a></p><ol><li><a href="http://yann.lecun.com/exdb/mnist/index.html" target="_blank" rel="external">MNIST</a>:手写数字数据库;</li><li><a href="http://www.image-net.org/about-stats" target="_blank" rel="external">Imagenet</a>:1400多万幅图片，涵盖2万多个类别;</li><li><a href="http://mscoco.org/" target="_blank" rel="external">COCO</a>:由微软赞助，对于图像的标注信息不仅有类别、位置信息，还有对图像的语义文本描述;</li><li><a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html" target="_blank" rel="external">PASCAL VOC</a>:图片集包括20个目录;</li><li><a href="http://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="external">CIFAR</a>:对图像分类算法测试来说是一个非常不错的中小规模数据集;</li><li><a href="https://github.com/openimages/dataset" target="_blank" rel="external">Open Image</a>:包含900万张图像URL的数据集，里面的图片通过标签注释被分为6000多类;</li><li><a href="https://research.google.com/youtube8m/" target="_blank" rel="external">Youtube-8M</a>:谷歌开源的视频数据集，视频来自youtube，共计8百万个视频，总时长50万小时，4800类;</li><li><a href="http://deeplearning.net/datasets/" target="_blank" rel="external">深度学习数据集收集网站</a>:收集大量的各深度学习相关的数据集;</li><li><a href="http://horatio.cs.nyu.edu/mit/tiny/data/index.html" target="_blank" rel="external">Tiny Images Dataset</a>:包含8000万的32x32图像，CIFAR-10和CIFAR-100便是从中挑选的;</li><li><a href="http://cophir.isti.cnr.it/whatis.html" target="_blank" rel="external">CoPhIR</a>:雅虎发布的超大Flickr数据集，包含1亿多张图片;</li><li><a href="http://press.liacs.nl/mirflickr/" target="_blank" rel="external">MirFlickr1M</a>:Flickr数据集中挑选出的100万图像集;</li><li><a href="http://dsl1.cewit.stonybrook.edu/~vicente/sbucaptions/" target="_blank" rel="external">SBU captioned photo dataset</a>:Flickr的一个子集，包含100万的图像集;</li><li><a href="http://lms.comp.nus.edu.sg/research/NUS-WIDE.htm" target="_blank" rel="external">NUS-WIDE</a>:Flickr中的27万的图像集;</li><li><a href="http://cpl.cc.gatech.edu/projects/VisualSynset/" target="_blank" rel="external">Large-Scale Image Annotation using Visual Synset(ICCV 2011)</a>:机器标注的一个超大规模数据集，包含2亿图像;</li><li><a href="http://people.csail.mit.edu/jxiao/SUN/" target="_blank" rel="external">SUN dataset</a>:包含13万的图像的数据集;</li><li><a href="http://research.microsoft.com/en-us/projects/msrammdata/" target="_blank" rel="external">MSRA-MM</a>:包含100万的图像，23000视频；微软亚洲研究院出品，质量应该有保障;</li><li><a href="https://github.com/awesomedata/awesome-public-datasets" target="_blank" rel="external">农业、生物、数据竞赛、教育、金融、健康汇总</a></li><li><a href="http://www.face-rec.org/databases/" target="_blank" rel="external">人脸识别数据集</a></li><li><a href="http://yahoolabs.tumblr.com/post/89783581601/one-hundred-million-creative-commons-flickr-images-for" target="_blank" rel="external">Yahoo实验室公开1亿Flickr图像和视频</a></li><li><a href="http://riemenschneider.hayko.at/vision/dataset/" target="_blank" rel="external">比较新的一个计算机视觉数据库网站</a></li><li><a href="http://konect.uni-koblenz.de/" target="_blank" rel="external">KONECT 网络图结构和网络科学数据合辑</a></li><li><a href="https://www.kaggle.com/c/facial-keypoints-detection" target="_blank" rel="external">【Kaggle竞赛】人脸关键点标定竞赛数据</a></li><li><a href="http://dataju.cn/Dataju/web/datasetInstanceDetail/332" target="_blank" rel="external">【Kaggle竞赛】根据手机应用软件使用行为预测用户性别年龄竞赛数据</a></li><li><a href="https://www.kaggle.com/c/dstl-satellite-imagery-feature-detection" target="_blank" rel="external">【Kaggle竞赛】DSTL 卫星图像识别竞赛数据</a></li><li><a href="https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition" target="_blank" rel="external">【Kaggle竞赛】猫和狗图像分类数据</a></li><li><a href="https://www.kaggle.com/c/passenger-screening-algorithm-challenge" target="_blank" rel="external">【Kaggle竞赛】根据安检人体扫描成像预测威胁竞赛</a></li><li><a href="https://www.kaggle.com/c/titanic" target="_blank" rel="external">【Kaggle竞赛】泰坦尼克灾难数据</a></li><li><a href="https://www.kaggle.com/mchirico/philadelphiacrimedata" target="_blank" rel="external">【Kaggle竞赛】费城犯罪记录数据</a></li><li><a href="https://www.kaggle.com/zurfer/rtb" target="_blank" rel="external">【Kaggle竞赛】广告实时竞价数据</a></li><li><a href="https://www.kaggle.com/c/outbrain-click-prediction" target="_blank" rel="external">【Kaggle竞赛】新闻和网页内容推荐及点击竞赛</a></li><li><a href="https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset" target="_blank" rel="external">【Kaggle数据】IMDB五千部电影数据</a></li><li><a href="https://www.kaggle.com/hugomathien/soccer" target="_blank" rel="external">【Kaagle数据】欧洲足球运动员赛事表现数据</a></li><li><a href="https://www.kaggle.com/worldbank/world-development-indicators" target="_blank" rel="external">【Kaagle数据】世界各国经济发展数据</a></li><li><a href="http://socialcomputing.asu.edu/" target="_blank" rel="external">Social Computing Data Repository 社交网络数据</a></li><li><a href="http://data.cma.cn/" target="_blank" rel="external">国际地面交换站日间数据</a></li><li><a href="http://saliency.mit.edu/" target="_blank" rel="external">MIT Saliency 眼睛浏览轨迹数据集</a></li><li><a href="https://github.com/candlewill/Dialog_Corpus" target="_blank" rel="external">聊天机器人语料</a></li><li><a href="https://www.kaggle.com/c/billion-word-imputation/data" target="_blank" rel="external">英语语言模型单词预测竞赛数据</a></li><li><a href="http://crcv.ucf.edu/data/ALOV++/" target="_blank" rel="external">ALOV++ 物体追踪视频数据</a></li><li><a href="https://www.nist.gov/property-fieldsection/nist-special-database-10" target="_blank" rel="external">NIST Supplemental Fingerprint Card Data (SFCD) 指纹识别数据</a></li><li><a href="http://www.robots.ox.ac.uk/~vgg/data/pose_evaluation/" target="_blank" rel="external">Human Pose Evaluator 人体轮廓识别图像数据</a></li><li><a href="https://github.com/zygmuntz/goodbooks-10k" target="_blank" rel="external">1万本畅销书的6百万读者评分数据</a></li><li><a href="http://visualgenome.org/" target="_blank" rel="external">Visual Genome 图像及语义数据集</a></li><li><a href="http://cbcl.mit.edu/software-datasets/streetscenes/" target="_blank" rel="external">CBCL StreetScenes Challenge 场景数据</a></li><li><a href="https://www.kaggle.com/c/the-winton-stock-market-challenge" target="_blank" rel="external">Winton 股票回报率预测竞赛数据</a></li><li><a href="https://www.capitalbikeshare.com/system-data" target="_blank" rel="external">Capital 共享单车骑行数据</a></li><li><a href="http://www.vision.caltech.edu/Image_Datasets/Caltech256/" target="_blank" rel="external">Caltech数据集</a></li></ol><p><a href="https://blog.csdn.net/yangdashi888/article/details/70503874" target="_blank" rel="external">参考链接1</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇文章主要收集网上的一些数据集，记录下来，方便查阅。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Tech" scheme="http://songit.cn/categories/Tech/"/>
    
    
      <category term="Datasets" scheme="http://songit.cn/tags/Datasets/"/>
    
  </entry>
  
  <entry>
    <title>Top Deep Learning Projects</title>
    <link href="http://songit.cn/Top-Deep-Learning-Projects/"/>
    <id>http://songit.cn/Top-Deep-Learning-Projects/</id>
    <published>2017-11-10T12:01:16.000Z</published>
    <updated>2017-11-21T01:36:23.000Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;&nbsp;&nbsp;<a href="https://github.com/aymericdamien/TopDeepLearning" target="_blank" rel="external">Top Deep Learning Projects</a></p><a id="more"></a><h1 id="Top-Deep-Learning-Projects"><a href="#Top-Deep-Learning-Projects" class="headerlink" title="Top Deep Learning Projects"></a>Top Deep Learning Projects</h1><p>A list of popular github projects related to deep learning (ranked by stars).</p><p>Last Update: 2016.08.09</p><table><thead><tr><th>Project Name</th><th>Stars</th><th>Description</th></tr></thead><tbody><tr><td><a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="external">TensorFlow</a></td><td>29622</td><td>Computation using data flow graphs for scalable machine learning.</td></tr><tr><td><a href="https://github.com/BVLC/caffe" target="_blank" rel="external">Caffe</a></td><td>11799</td><td>Caffe: a fast open framework for deep learning.</td></tr><tr><td><a href="https://github.com/jcjohnson/neural-style" target="_blank" rel="external">Neural Style</a></td><td>10148</td><td>Torch implementation of neural style algorithm.</td></tr><tr><td><a href="https://github.com/google/deepdream" target="_blank" rel="external">Deep Dream</a></td><td>9042</td><td>Deep Dream.</td></tr><tr><td><a href="https://github.com/fchollet/keras" target="_blank" rel="external">Keras</a></td><td>7502</td><td>Deep Learning library for Python. Convnets, recurrent neural networks, and more. Runs on Theano and TensorFlow.</td></tr><tr><td><a href="https://github.com/Rochester-NRT/RocAlphaGo" target="_blank" rel="external">Roc AlphaGo</a></td><td>7170</td><td>An independent, student-led replication of DeepMind’s 2016 Nature publication, “Mastering the game of Go with deep neural networks and tree search” (Nature 529, 484-489, 28 Jan 2016).</td></tr><tr><td><a href="https://github.com/tensorflow/models" target="_blank" rel="external">TensorFlow Models</a></td><td>6671</td><td>Models built with TensorFlow</td></tr><tr><td><a href="https://github.com/alexjc/neural-doodle" target="_blank" rel="external">Neural Doodle</a></td><td>6275</td><td>Turn your two-bit doodles into fine artworks with deep neural networks, generate seamless textures from photos, transfer style from one image to another, perform example-based upscaling, but wait… there’s more! (An implementation of Semantic Style Transfer.)</td></tr><tr><td><a href="https://github.com/Microsoft/CNTK" target="_blank" rel="external">CNTK</a></td><td>5957</td><td>Computational Network Toolkit (CNTK).</td></tr><tr><td><a href="https://github.com/aymericdamien/TensorFlow-Examples" target="_blank" rel="external">TensorFlow Examples</a></td><td>5872</td><td>TensorFlow tutorials and code examples for beginners.</td></tr><tr><td><a href="https://github.com/karpathy/convnetjs" target="_blank" rel="external">ConvNet JS</a></td><td>5231</td><td>Deep Learning in Javascript. Train Convolutional Neural Networks (or ordinary ones) in your browser.</td></tr><tr><td><a href="https://github.com/torch/torch7" target="_blank" rel="external">Torch</a></td><td>5133</td><td>Torch7, Deep Learning Library.</td></tr><tr><td><a href="https://github.com/cmusatyalab/openface" target="_blank" rel="external">OpenFace</a></td><td>4855</td><td>Face recognition with deep neural networks.</td></tr><tr><td><a href="https://github.com/dmlc/mxnet" target="_blank" rel="external">MXNet</a></td><td>4685</td><td>Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Scala, Go, Javascript and more.</td></tr><tr><td><a href="https://github.com/Theano/Theano" target="_blank" rel="external">Theano</a></td><td>4286</td><td>Theano is a Python library that allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. It can use GPUs and perform efficient symbolic differentiation.</td></tr><tr><td><a href="https://github.com/autumnai/leaf" target="_blank" rel="external">Leaf</a></td><td>4281</td><td>Open Machine Intelligence Framework for Hackers.</td></tr><tr><td><a href="https://github.com/karpathy/char-rnn" target="_blank" rel="external">Char RNN</a></td><td>3820</td><td>Multi-layer Recurrent Neural Networks (LSTM, GRU, RNN) for character-level language models in Torch.</td></tr><tr><td><a href="https://github.com/karpathy/neuraltalk" target="_blank" rel="external">Neural Talk</a></td><td>3694</td><td>NeuralTalk is a Python+numpy project for learning Multimodal Recurrent Neural Networks that describe images with sentences.</td></tr><tr><td><a href="https://github.com/deeplearning4j/deeplearning4j" target="_blank" rel="external">deeplearning4j</a></td><td>3673</td><td>Deep Learning for Java, Scala &amp; Clojure on Hadoop, Spark.</td></tr><tr><td><a href="https://github.com/tflearn/tflearn" target="_blank" rel="external">TFLearn</a></td><td>3368</td><td>Deep learning library featuring a higher-level API for TensorFlow.</td></tr><tr><td><a href="https://github.com/tensorflow/playground" target="_blank" rel="external">TensorFlow Playground</a></td><td>3352</td><td>Play with neural networks!</td></tr><tr><td><a href="https://github.com/openai/gym" target="_blank" rel="external">OpenAI Gym</a></td><td>3020</td><td>A toolkit for developing and comparing reinforcement learning algorithms.</td></tr><tr><td><a href="https://github.com/tensorflow/magenta" target="_blank" rel="external">Magenta</a></td><td>2914</td><td>Magenta: Music and Art Generation with Machine Intelligence</td></tr><tr><td><a href="https://github.com/pavelgonchar/colornet" target="_blank" rel="external">Colornet</a></td><td>2798</td><td>Neural Network to colorize grayscale images.</td></tr><tr><td><a href="https://github.com/cazala/synaptic" target="_blank" rel="external">Synaptic</a></td><td>2666</td><td>architecture-free neural network library for node.js and the browser</td></tr><tr><td><a href="https://github.com/karpathy/neuraltalk2" target="_blank" rel="external">Neural Talk 2</a></td><td>2550</td><td>Efficient Image Captioning code in Torch, runs on GPU.</td></tr><tr><td><a href="https://github.com/awentzonline/image-analogies" target="_blank" rel="external">Image Analogies</a></td><td>2540</td><td>Generate image analogies using neural matching and blending.</td></tr><tr><td><a href="https://github.com/pkmital/tensorflow_tutorials" target="_blank" rel="external">TensorFlow Tutorials</a></td><td>2413</td><td>From the basics to slightly more interesting applications of Tensorflow.</td></tr><tr><td><a href="https://github.com/Lasagne/Lasagne" target="_blank" rel="external">Lasagne</a></td><td>2355</td><td>Lightweight library to build and train neural networks in Theano.</td></tr><tr><td><a href="https://github.com/lisa-lab/pylearn2" target="_blank" rel="external">PyLearn2</a></td><td>2153</td><td>A Machine Learning library based on Theano.</td></tr><tr><td><a href="https://github.com/lisa-lab/DeepLearningTutorials" target="_blank" rel="external">LISA-lab Deep Learning Tutorials</a></td><td>2134</td><td>Deep Learning Tutorial notes and code. See the wiki for more info.</td></tr><tr><td><a href="https://github.com/NervanaSystems/neon" target="_blank" rel="external">Neon</a></td><td>2121</td><td>Fast, scalable, easy-to-use Python based Deep Learning Framework by Nervana™.</td></tr><tr><td><a href="https://github.com/rasmusbergpalm/DeepLearnToolbox" target="_blank" rel="external">Matlab Deep Learning Toolbox</a></td><td>2032</td><td>Matlab/Octave toolbox for deep learning. Includes Deep Belief Nets, Stacked Autoencoders, Convolutional Neural Nets, Convolutional Autoencoders and vanilla Neural Nets. Each method has examples to get you started.</td></tr><tr><td><a href="https://github.com/yenchenlin1994/DeepLearningFlappyBird" target="_blank" rel="external">Deep Learning Flappy Bird</a></td><td>1721</td><td>Flappy Bird hack using Deep Reinforcement Learning (Deep Q-learning).</td></tr><tr><td><a href="https://github.com/saiprashanths/dl-setup" target="_blank" rel="external">dl-setup</a></td><td>1607</td><td>Instructions for setting up the software on your deep learning machine.</td></tr><tr><td><a href="https://github.com/pfnet/chainer" target="_blank" rel="external">Chainer</a></td><td>1573</td><td>A flexible framework of neural networks for deep learning.</td></tr><tr><td><a href="https://github.com/ryankiros/neural-storyteller" target="_blank" rel="external">Neural Story Teller</a></td><td>1514</td><td>A recurrent neural network for generating little stories about images.</td></tr><tr><td><a href="https://github.com/NVIDIA/DIGITS" target="_blank" rel="external">DIGITS</a></td><td>1353</td><td>Deep Learning GPU Training System.</td></tr><tr><td><a href="https://github.com/jisungk/deepjazz" target="_blank" rel="external">Deep Jazz</a></td><td>1229</td><td>Deep learning driven jazz generation using Keras &amp; Theano!</td></tr><tr><td><a href="https://github.com/tiny-dnn/tiny-dnn" target="_blank" rel="external">Tiny DNN</a></td><td>1183</td><td>header only, dependency-free deep learning framework in C++11</td></tr><tr><td><a href="https://github.com/IDSIA/brainstorm" target="_blank" rel="external">Brainstorm</a></td><td>1143</td><td>Fast, flexible and fun neural networks.</td></tr><tr><td><a href="https://github.com/saiprashanths/dl-docker" target="_blank" rel="external">dl-docker</a></td><td>1044</td><td>An all-in-one Docker image for deep learning. Contains all the popular DL frameworks (TensorFlow, Theano, Torch, Caffe, etc.).</td></tr><tr><td><a href="https://github.com/pjreddie/darknet" target="_blank" rel="external">Darknet</a></td><td>937</td><td>Open Source Neural Networks in C</td></tr><tr><td><a href="https://github.com/Newmu/Theano-Tutorials" target="_blank" rel="external">Theano Tutorials</a></td><td>904</td><td>Bare bones introduction to machine learning from linear regression to convolutional neural networks using Theano.</td></tr><tr><td><a href="https://github.com/hexahedria/biaxial-rnn-music-composition" target="_blank" rel="external">RNN Music Composition</a></td><td>904</td><td>A recurrent neural network designed to generate classical music.</td></tr><tr><td><a href="https://github.com/mila-udem/blocks" target="_blank" rel="external">Blocks</a></td><td>866</td><td>A Theano framework for building and training neural networks.</td></tr><tr><td><a href="https://github.com/ericjang/tdb" target="_blank" rel="external">TDB</a></td><td>860</td><td>Interactive, node-by-node debugging and visualization for TensorFlow.</td></tr><tr><td><a href="https://github.com/aigamedev/scikit-neuralnetwork" target="_blank" rel="external">Scikit Neural Net</a></td><td>849</td><td>Deep neural networks without the learning cliff! Classifiers and regressors compatible with scikit-learn.</td></tr><tr><td><a href="https://github.com/samsung/veles" target="_blank" rel="external">Veles</a></td><td>760</td><td>Distributed machine learning platform (Python, CUDA, OpenCL)</td></tr><tr><td><a href="https://github.com/beniz/deepdetect" target="_blank" rel="external">Deep Detect</a></td><td>759</td><td>Deep Learning API and Server in C++11 with Python bindings and support for Caffe.</td></tr><tr><td><a href="https://github.com/nivwusquorum/tensorflow-deepq" target="_blank" rel="external">TensorFlow DeepQ</a></td><td>759</td><td>A deep Q learning demonstration using Google Tensorflow.</td></tr><tr><td><a href="https://github.com/yahoo/CaffeOnSpark" target="_blank" rel="external">Caffe on Spark</a></td><td>724</td><td>Caffe On Spark.</td></tr><tr><td><a href="https://github.com/dnouri/nolearn" target="_blank" rel="external">Nolearn</a></td><td>702</td><td>Abstractions around neural net libraries, most notably Lasagne.</td></tr><tr><td><a href="https://github.com/carpedm20/DCGAN-tensorflow" target="_blank" rel="external">DCGAN TensorFlow</a></td><td>568</td><td>A tensorflow implementation of Deep Convolutional Generative Adversarial Networks</td></tr><tr><td><a href="https://github.com/vlfeat/matconvnet" target="_blank" rel="external">MatConvNet</a></td><td>479</td><td>MATLAB CNN toolbox for computer vision applications.</td></tr><tr><td><a href="https://github.com/hughperkins/DeepCL" target="_blank" rel="external">DeepCL</a></td><td>413</td><td>OpenCL library to train deep convolutional neural networks.</td></tr><tr><td><a href="https://github.com/AKSHAYUBHAT/VisualSearchServer" target="_blank" rel="external">Visual Search Server</a></td><td>304</td><td>Visual Search using Tensorflow inception model &amp; Approximate Nearest Neighbors.</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://github.com/aymericdamien/TopDeepLearning&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Top Deep Learning Projects&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Tech" scheme="http://songit.cn/categories/Tech/"/>
    
    
      <category term="DeepLearning" scheme="http://songit.cn/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>修改Jupyter Notebook的启动目录</title>
    <link href="http://songit.cn/JupyterStartDict/"/>
    <id>http://songit.cn/JupyterStartDict/</id>
    <published>2017-11-04T02:37:33.000Z</published>
    <updated>2018-12-05T09:34:53.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>Python IDE有很多，诸如Pycharm，Spyder等。但对于刚学习Python的来说，Jupyter Notebook比较小巧，而且操作简单，很适合使用。<br>关于Jupyter Notebook的安装方法这里不再赘述，直接安装Anaconda3自带Jupyter，你值得拥有！<br><img src="/imgs/Jupyter.jpg" alt="Jupyter"></p><a id="more"></a><h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><p>由于不喜欢把一些文件放在C盘，而Jupyter Notebook的默认目录就是在C盘用户名目录下，下面介绍两种实用简单的方法修改Jupyter Notebook的启动目录。</p><h2 id="方法一（推荐）"><a href="#方法一（推荐）" class="headerlink" title="方法一（推荐）"></a>方法一（推荐）</h2><ol><li>通过cmd打开windows的命令操作面板，输入<code>jupyter notebook --generate-config</code>，生成一个jupyter_notebook_config.py文件，这个文件的目录在C:\User\Administrator.jupyter下（将Administrator替换为你的用户名即可）。</li><li>打开jupyter_notebook_config.py文件，通过Ctrl+F输入notebook_dir，回车，定位到<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">## The directory to use for notebooks and kernels. </div><div class="line">#c.NotebookApp.notebook_dir = &apos;&apos;</div></pre></td></tr></table></figure></li></ol><p>对其进行修改后<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">## The directory to use for notebooks and kernels. </div><div class="line">c.NotebookApp.notebook_dir = &apos;G:\Workspace\Jupyter&apos;</div></pre></td></tr></table></figure></p><p><strong>#c.NotebookApp.notebook_dir</strong>中<strong>#</strong>必须删除，否则系统还将认为是注释，修改无效。<br>将<code>G:\Workspace\Jupyter</code>替换为你想要更改的文件目录即可。</p><p><em>修改后启动后是不是发现启动目录还没有改变？</em><br><strong>接下来进行下一步！</strong></p><ol><li>打开Anaconda的Jupyter Notebook的快捷方式，右键点击属性，在目标栏里的内容为<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">E:\Anaconda3\python.exe E:\Anaconda3\cwp.py E:\Anaconda3 E:\Anaconda3\python.exe E:\Anaconda3\Scripts\jupyter-notebook-script.py %USERPROFILE%</div></pre></td></tr></table></figure></li></ol><p>其中<code>%USERPROFILE%</code>导致其启动目录固定在当前用户目录！将其<strong>删除</strong>！再启动Jupyter Notebook快捷方式我们发现已经操作成功了！</p><h2 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h2><ol><li>进入想要启动的目录下，点击<strong>shift</strong>，同时点击鼠标右键，选中<em>在此处打开Powershell窗口</em></li><li>输入<code>jupyter notebook</code>即可！</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;Python IDE有很多，诸如Pycharm，Spyder等。但对于刚学习Python的来说，Jupyter Notebook比较小巧，而且操作简单，很适合使用。&lt;br&gt;关于Jupyter Notebook的安装方法这里不再赘述，直接安装Anaconda3自带Jupyter，你值得拥有！&lt;br&gt;&lt;img src=&quot;/imgs/Jupyter.jpg&quot; alt=&quot;Jupyter&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Tech" scheme="http://songit.cn/categories/Tech/"/>
    
    
      <category term="Jupyter" scheme="http://songit.cn/tags/Jupyter/"/>
    
  </entry>
  
  <entry>
    <title>Anaconda+CUDA+CUDNN+Tensorflow在Win10上安装总结</title>
    <link href="http://songit.cn/Ana-CUD-Ten-Win/"/>
    <id>http://songit.cn/Ana-CUD-Ten-Win/</id>
    <published>2017-11-01T08:14:22.000Z</published>
    <updated>2017-11-05T13:30:04.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>今年实验室配了两个2万+的设备，显卡Quardo M4000 8G 很强了。我之前还用tensorflow cpu 训练数据，慢的我都怀疑人生了。于是便安装了gpu版本。速度66的。<br>本文是在Win10环境下安装Anaconda3 5.0.1(64-bit)，CUDA8.0，CUDNN-8.0-windows10-x64-v6.0，看了好多文章，折腾了差不多一下午和一晚上，发现<a href="http://www.jianshu.com/p/c245d46d43f0" target="_blank" rel="external">这篇文章</a>总结的比较全面，但还是有其他的问题。<br><a id="more"></a></p><h1 id="问题一"><a href="#问题一" class="headerlink" title="问题一"></a>问题一</h1><p>CUDA的环境变量的设置：<br>在环境变量Path加入一下三个，第一个很重要（很多网站都忽略了！！！）</p><ol><li>%CUDA_PATH%\extras\CUPTI\libx64;</li><li>%CUDA_PATH%\bin;</li><li>%CUDA_PATH%\lib\x64;</li></ol><h1 id="问题二"><a href="#问题二" class="headerlink" title="问题二"></a>问题二</h1><p>对于CUDNN的安装，详见文章<a href="https://www.hongweipeng.com/index.php/archives/312/" target="_blank" rel="external">《如何安装CUDNN》</a>，已经介绍的很清楚了。</p><h1 id="问题三"><a href="#问题三" class="headerlink" title="问题三"></a>问题三</h1><p>Win10，ANACONDA3(64-bit)，Python3.6.2。ANACONDA Prompt中不能用pip命令安装包，并且是在安装了TensorFlow后才发生的。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">Exception:  </div><div class="line">Traceback (most recent call last):  </div><div class="line">  File &quot;C:\ProgramData\Anaconda3\lib\site-packages\pip\basecommand.py&quot;, line 215, in main  </div><div class="line">    status = self.run(options, args)  </div><div class="line">  File &quot;C:\ProgramData\Anaconda3\lib\site-packages\pip\commands\install.py&quot;, line 335, in run  </div><div class="line">    wb.build(autobuilding=True)  </div><div class="line">  File &quot;C:\ProgramData\Anaconda3\lib\site-packages\pip\wheel.py&quot;, line 749, in build  </div><div class="line">    self.requirement_set.prepare_files(self.finder)  </div><div class="line">  File &quot;C:\ProgramData\Anaconda3\lib\site-packages\pip\req\req_set.py&quot;, line 380, in prepare_files  </div><div class="line">    ignore_dependencies=self.ignore_dependencies))  </div><div class="line">  File &quot;C:\ProgramData\Anaconda3\lib\site-packages\pip\req\req_set.py&quot;, line 554, in _prepare_file  </div><div class="line">    require_hashes  </div><div class="line">  File &quot;C:\ProgramData\Anaconda3\lib\site-packages\pip\req\req_install.py&quot;, line 278, in populate_link  </div><div class="line">    self.link = finder.find_requirement(self, upgrade)  </div><div class="line">  File &quot;C:\ProgramData\Anaconda3\lib\site-packages\pip\index.py&quot;, line 465, in find_requirement  </div><div class="line">    all_candidates = self.find_all_candidates(req.name)  </div><div class="line">  File &quot;C:\ProgramData\Anaconda3\lib\site-packages\pip\index.py&quot;, line 423, in find_all_candidates  </div><div class="line">    for page in self._get_pages(url_locations, project_name):  </div><div class="line">  File &quot;C:\ProgramData\Anaconda3\lib\site-packages\pip\index.py&quot;, line 568, in _get_pages  </div><div class="line">    page = self._get_page(location)  </div><div class="line">  File &quot;C:\ProgramData\Anaconda3\lib\site-packages\pip\index.py&quot;, line 683, in _get_page  </div><div class="line">    return HTMLPage.get_page(link, session=self.session)  </div><div class="line">  File &quot;C:\ProgramData\Anaconda3\lib\site-packages\pip\index.py&quot;, line 811, in get_page  </div><div class="line">    inst = cls(resp.content, resp.url, resp.headers)  </div><div class="line">  File &quot;C:\ProgramData\Anaconda3\lib\site-packages\pip\index.py&quot;, line 731, in __init__  </div><div class="line">    namespaceHTMLElements=False,  </div><div class="line">TypeError: parse() got an unexpected keyword argument &apos;transport_encoding&apos;</div></pre></td></tr></table></figure></p><p>解决办法：<br>输入<code>conda install -c anaconda html5lib</code><br>等待执行完后，发现pip安装指令可以成功执行。<br>这个问题参考文章点<a href="http://blog.csdn.net/cheese_pop/article/details/78201359" target="_blank" rel="external">这里</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;今年实验室配了两个2万+的设备，显卡Quardo M4000 8G 很强了。我之前还用tensorflow cpu 训练数据，慢的我都怀疑人生了。于是便安装了gpu版本。速度66的。&lt;br&gt;本文是在Win10环境下安装Anaconda3 5.0.1(64-bit)，CUDA8.0，CUDNN-8.0-windows10-x64-v6.0，看了好多文章，折腾了差不多一下午和一晚上，发现&lt;a href=&quot;http://www.jianshu.com/p/c245d46d43f0&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这篇文章&lt;/a&gt;总结的比较全面，但还是有其他的问题。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Tech" scheme="http://songit.cn/categories/Tech/"/>
    
    
      <category term="Python" scheme="http://songit.cn/tags/Python/"/>
    
      <category term="CUDA" scheme="http://songit.cn/tags/CUDA/"/>
    
      <category term="Tensorflow" scheme="http://songit.cn/tags/Tensorflow/"/>
    
      <category term="Win10" scheme="http://songit.cn/tags/Win10/"/>
    
  </entry>
  
  <entry>
    <title>鼓足干劲好好搞科研</title>
    <link href="http://songit.cn/PaperTo/"/>
    <id>http://songit.cn/PaperTo/</id>
    <published>2017-10-16T08:13:13.000Z</published>
    <updated>2018-12-05T09:36:37.000Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;这两天自己明确了自己的方向，开始好好搞论文了。<br><img src="/imgs/AI_ex.jpg" alt="人工智能"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&amp;emsp;&amp;emsp;这两天自己明确了自己的方向，开始好好搞论文了。&lt;br&gt;&lt;img src=&quot;/imgs/AI_ex.jpg&quot; alt=&quot;人工智能&quot;&gt;&lt;/p&gt;

      
    
    </summary>
    
      <category term="人生随笔" scheme="http://songit.cn/categories/%E4%BA%BA%E7%94%9F%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="研究生" scheme="http://songit.cn/tags/%E7%A0%94%E7%A9%B6%E7%94%9F/"/>
    
  </entry>
  
  <entry>
    <title>Python资源大全中文版</title>
    <link href="http://songit.cn/PythonResource/"/>
    <id>http://songit.cn/PythonResource/</id>
    <published>2017-10-08T22:12:39.000Z</published>
    <updated>2017-11-10T12:33:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;参考链接点<a href="https://github.com/jobbole/awesome-python-cn" target="_blank" rel="external">这里</a>，转载只为方便学习!</p><a id="more"></a><h1 id="Python-资源大全中文版"><a href="#Python-资源大全中文版" class="headerlink" title="Python 资源大全中文版"></a>Python 资源大全中文版</h1><p>我想很多程序员应该记得 GitHub 上有一个 Awesome - XXX 系列的资源整理。<a href="https://github.com/vinta/awesome-python" target="_blank" rel="external">awesome-python</a> 是 vinta 发起维护的 Python 资源列表，内容包括：Web框架、网络爬虫、网络内容提取、模板引擎、数据库、数据可视化、图片处理、文本处理、自然语言处理、机器学习、日志、代码分析等。由伯乐在线持续更新。</p><p>Awesome 系列虽然挺全，但基本只对收录的资源做了极为简要的介绍，如果有更详细的中文介绍，对相应开发者的帮助会更大。这也是我们发起这个开源项目的初衷。</p><hr><h3 id="我们要做什么？"><a href="#我们要做什么？" class="headerlink" title="我们要做什么？"></a>我们要做什么？</h3><ul><li>基于 awesome-python 列表，我们将对其中的各个资源项进行编译整理。此外还将从其他来源补充好资源。</li><li>整理后的内容，将收录在<a href="http://hao.jobbole.com/" target="_blank" rel="external">伯乐在线资源频道</a>。可参考已整理的内容：<ul><li>《<a href="http://hao.jobbole.com/python-scrapy/" target="_blank" rel="external">Scrapy：Python的爬虫框架</a>》</li><li>《<a href="http://hao.jobbole.com/flask/" target="_blank" rel="external">Flask：一个使用Python编写的轻量级Web应用框架</a>》</li></ul></li></ul><hr><h3 id="如何参与本项目？"><a href="#如何参与本项目？" class="headerlink" title="如何参与本项目？"></a>如何参与本项目？</h3><p>从下面的目录来看，本项目的工作量小不了，所以非常期待能有更多程序员一起来参与。</p><p>不过加入前，有几个小要求：</p><ul><li>英文还不错，能读懂英文并用自己的话复述；</li><li>在用 Python；</li></ul><p>如有兴趣，请加 QQ：50872495。加 Q 时请注明「Python大全」</p><hr><h3 id="如何为列表贡献新资源？"><a href="#如何为列表贡献新资源？" class="headerlink" title="如何为列表贡献新资源？"></a>如何为列表贡献新资源？</h3><p>欢迎大家为列表贡献高质量的新资源，提交PR时请参照以下要求：</p><ul><li>请确保推荐的资源自己使用过</li><li>提交PR时请注明推荐理由</li></ul><p>资源列表管理收到PR请求后，会定期（每周）在微博转发本周提交的PR列表，并在微博上面听取使用过这些资源的意见。确认通过后，会加入资源大全。</p><p>感谢您的贡献！</p><hr><h3 id="本项目的参与者"><a href="#本项目的参与者" class="headerlink" title="本项目的参与者"></a>本项目的参与者</h3><ul><li>维护者：</li><li>贡献者：<a href="https://github.com/hanxiaomax" target="_blank" rel="external">艾凌风</a>、Namco、<a href="https://github.com/Daetalus" target="_blank" rel="external">Daetalus</a>、<a href="http://www.jobbole.com/members/huanglimin/" target="_blank" rel="external">黄利民</a>、<a href="http://www.jobbole.com/members/atupal/" target="_blank" rel="external">atupal</a>、<a href="http://www.jobbole.com/members/rainbow/" target="_blank" rel="external">rainbow</a>、<a href="https://github.com/mutoulbj" target="_blank" rel="external">木头lbj</a>、<a href="http://www.jobbole.com/members/beyondwu/" target="_blank" rel="external">beyondwu</a>、<a href="https://github.com/cissoid" target="_blank" rel="external">cissoid</a>、<a href="https://github.com/liguangsheng" target="_blank" rel="external">李广胜</a>、<a href="https://github.com/polyval" target="_blank" rel="external">polyval</a>、<a href="http://www.jobbole.com/members/libing1209/" target="_blank" rel="external">冰斌</a>、<a href="http://www.jobbole.com/members/nelsonzhao/" target="_blank" rel="external">赵叶宇</a>、<a href="http://www.jobbole.com/members/fengfeng19910805/" target="_blank" rel="external">л stalgic</a>、<a href="http://www.jobbole.com/members/shawnw/" target="_blank" rel="external">硕恩</a>、<a href="https://github.com/strongit" target="_blank" rel="external">strongit</a>、<a href="http://www.jobbole.com/members/yuukilp/" target="_blank" rel="external">yuukilp</a></li></ul><p>注：名单不分排名，不定期补充更新</p><hr><h3 id="奖励计划"><a href="#奖励计划" class="headerlink" title="奖励计划"></a>奖励计划</h3><p>虽然奖励可能并不是你加入的主要原因，但还是有必要提一下：</p><ul><li>整理超过 20 个资源后，可在伯乐在线上开通打赏；</li><li>每整理 20 个资源，有机会获得技术书籍或各种有意思的创意、极客产品；</li><li><a href="http://hao.jobbole.com/rewards/" target="_blank" rel="external">奖励详情</a></li></ul><hr><h3 id="环境管理"><a href="#环境管理" class="headerlink" title="环境管理"></a>环境管理</h3><p>管理 Python 版本和环境的工具</p><ul><li>p：非常简单的交互式 python 版本管理工具。<a href="https://github.com/qw3rtman/p" target="_blank" rel="external">官网</a></li><li>pyenv：简单的 Python 版本管理工具。<a href="https://github.com/yyuu/pyenv" target="_blank" rel="external">官网</a></li><li>Vex：可以在虚拟环境中执行命令。<a href="https://github.com/sashahart/vex" target="_blank" rel="external">官网</a></li><li>virtualenv：创建独立 Python 环境的工具。<a href="https://pypi.python.org/pypi/virtualenv" target="_blank" rel="external">官网</a></li><li>virtualenvwrapper：virtualenv 的一组扩展。<a href="https://pypi.python.org/pypi/virtualenvwrapper" target="_blank" rel="external">官网</a></li></ul><h3 id="包管理"><a href="#包管理" class="headerlink" title="包管理"></a>包管理</h3><p>管理包和依赖的工具。</p><ul><li>pip：Python 包和依赖关系管理工具。<a href="https://pip.pypa.io/" target="_blank" rel="external">官网</a></li><li>pip-tools：保证 Python 包依赖关系更新的一组工具。<a href="https://github.com/nvie/pip-tools" target="_blank" rel="external">官网</a></li><li>conda：跨平台，Python 二进制包管理工具。<a href="https://github.com/conda/conda/" target="_blank" rel="external">官网</a></li><li>Curdling：管理 Python 包的命令行工具。<a href="http://clarete.li/curdling/" target="_blank" rel="external">官网</a></li><li>wheel：Python 分发的新标准，意在取代 eggs。<a href="http://pythonwheels.com/" target="_blank" rel="external">官网</a></li></ul><h3 id="包仓库"><a href="#包仓库" class="headerlink" title="包仓库"></a>包仓库</h3><p>本地 PyPI 仓库服务和代理。</p><ul><li>warehouse：下一代 PyPI。<a href="https://github.com/pypa/warehouse" target="_blank" rel="external">官网</a><ul><li>Warehouse：PyPA 提供的 PyPI 镜像工具。<a href="https://warehouse.python.org/" target="_blank" rel="external">官网</a> <a href="https://bitbucket.org/pypa/bandersnatch" target="_blank" rel="external">bandersnatch</a></li></ul></li><li>devpi：PyPI 服务和打包/测试/分发工具。<a href="http://doc.devpi.net/" target="_blank" rel="external">官网</a></li><li>localshop：本地 PyPI 服务（自定义包并且自动对 PyPI 镜像）。<a href="https://github.com/mvantellingen/localshop" target="_blank" rel="external">官网</a></li></ul><h3 id="分发"><a href="#分发" class="headerlink" title="分发"></a>分发</h3><p>打包为可执行文件以便分发。</p><ul><li>PyInstaller：将 Python 程序转换成独立的执行文件（跨平台）。<a href="https://github.com/pyinstaller/pyinstaller" target="_blank" rel="external">官网</a></li><li>dh-virtualenv：构建并将 virtualenv 虚拟环境作为一个 Debian 包来发布。<a href="http://dh-virtualenv.readthedocs.org/" target="_blank" rel="external">官网</a></li><li>Nuitka：将脚本、模块、包编译成可执行文件或扩展模块。<a href="http://nuitka.net/" target="_blank" rel="external">官网</a></li><li>py2app：将 Python 脚本变为独立软件包（Mac OS X）。<a href="http://pythonhosted.org/py2app/" target="_blank" rel="external">官网</a></li><li>py2exe：将 Python 脚本变为独立软件包（Windows）。<a href="http://www.py2exe.org/" target="_blank" rel="external">官网</a></li><li>pynsist：一个用来创建 Windows 安装程序的工具，可以在安装程序中打包 Python本身。<a href="http://pynsist.readthedocs.org/" target="_blank" rel="external">官网</a></li></ul><h3 id="构建工具"><a href="#构建工具" class="headerlink" title="构建工具"></a>构建工具</h3><p>将源码编译成软件。</p><ul><li>buildout：一个构建系统，从多个组件来创建，组装和部署应用。<a href="http://www.buildout.org/" target="_blank" rel="external">官网</a></li><li>BitBake：针对嵌入式 Linux 的类似 make 的构建工具。<a href="http://www.yoctoproject.org/docs/1.6/bitbake-user-manual/bitbake-user-manual.html" target="_blank" rel="external">官网</a></li><li>fabricate：对任何语言自动找到依赖关系的构建工具。<a href="https://code.google.com/archive/p/fabricate" target="_blank" rel="external">官网</a></li><li>PlatformIO：多平台命令行构建工具。<a href="https://github.com/platformio/platformio" target="_blank" rel="external">官网</a></li><li>PyBuilder：纯 Python 实现的持续化构建工具。<a href="https://github.com/pybuilder/pybuilder" target="_blank" rel="external">官网</a></li><li>SCons：软件构建工具。<a href="http://www.scons.org/" target="_blank" rel="external">官网</a></li></ul><h3 id="交互式解析器"><a href="#交互式解析器" class="headerlink" title="交互式解析器"></a>交互式解析器</h3><p>交互式 Python 解析器。</p><ul><li>IPython：功能丰富的工具，非常有效的使用交互式 Python。<a href="https://github.com/ipython/ipython" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/bpython/" target="_blank" rel="external">bpython</a>：界面丰富的 Python 解析器。<a href="http://bpython-interpreter.org/" target="_blank" rel="external">官网</a></li><li>ptpython：高级交互式Python解析器， 构建于<a href="https://github.com/jonathanslenders/python-prompt-toolkit" target="_blank" rel="external">python-prompt-toolkit</a> 之上。<a href="https://github.com/jonathanslenders/ptpython" target="_blank" rel="external">官网</a></li></ul><h3 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h3><p>文件管理和 MIME（多用途的网际邮件扩充协议）类型检测。</p><ul><li>imghdr：（Python 标准库）检测图片类型。<a href="https://docs.python.org/2/library/imghdr.html" target="_blank" rel="external">官网</a></li><li>mimetypes：（Python 标准库）将文件名映射为 MIME 类型。<a href="https://docs.python.org/2/library/mimetypes.html" target="_blank" rel="external">官网</a></li><li>path.py：对 os.path 进行封装的模块。<a href="https://github.com/jaraco/path.py" target="_blank" rel="external">官网</a></li><li>pathlib：（Python3.4+ 标准库）跨平台的、面向对象的路径操作库。<a href="https://pathlib.readthedocs.org/en/pep428/" target="_blank" rel="external">官网</a></li><li>python-magic：文件类型检测的第三方库 libmagic 的 Python 接口。<a href="https://github.com/ahupp/python-magic" target="_blank" rel="external">官网</a></li><li>Unipath：用面向对象的方式操作文件和目录。<a href="https://github.com/mikeorr/Unipath" target="_blank" rel="external">官网</a></li><li>watchdog：管理文件系统事件的 API 和 shell 工具<a href="https://github.com/gorakhargosh/watchdog" target="_blank" rel="external">官网</a></li></ul><h3 id="日期和时间"><a href="#日期和时间" class="headerlink" title="日期和时间"></a>日期和时间</h3><p>操作日期和时间的类库。</p><ul><li>arrow：更好的 Python 日期时间操作类库。<a href="https://github.com/crsmithdev/arrow" target="_blank" rel="external">官网</a></li><li>Chronyk：Python 3 的类库，用于解析手写格式的时间和日期。<a href="https://github.com/KoffeinFlummi/Chronyk" target="_blank" rel="external">官网</a></li><li>dateutil：Python datetime 模块的扩展。<a href="https://pypi.python.org/pypi/python-dateutil" target="_blank" rel="external">官网</a></li><li>delorean：解决 Python 中有关日期处理的棘手问题的库。<a href="https://github.com/myusuf3/delorean/" target="_blank" rel="external">官网</a></li><li>moment：一个用来处理时间和日期的Python库。灵感来自于Moment.js。<a href="https://github.com/zachwill/moment" target="_blank" rel="external">官网</a></li><li>PyTime：一个简单易用的Python模块，用于通过字符串来操作日期/时间。<a href="https://github.com/shinux/PyTime" target="_blank" rel="external">官网</a></li><li>pytz：现代以及历史版本的世界时区定义。将时区数据库引入Python。<a href="https://launchpad.net/pytz" target="_blank" rel="external">官网</a></li><li>when.py：提供用户友好的函数来帮助用户进行常用的日期和时间操作。<a href="https://github.com/dirn/When.py" target="_blank" rel="external">官网</a></li></ul><h3 id="文本处理"><a href="#文本处理" class="headerlink" title="文本处理"></a>文本处理</h3><p>用于解析和操作文本的库。</p><ul><li>通用<ul><li><a href="http://hao.jobbole.com/chardet/" target="_blank" rel="external">chardet</a>：字符编码检测器，兼容 Python2 和 Python3。<a href="https://github.com/chardet/chardet" target="_blank" rel="external">官网</a></li><li>difflib：(Python 标准库)帮助我们进行差异化比较。<a href="https://docs.python.org/2/library/difflib.html" target="_blank" rel="external">官网</a></li><li>ftfy：让Unicode文本更完整更连贯。<a href="https://github.com/LuminosoInsight/python-ftfy" target="_blank" rel="external">官网</a></li><li>fuzzywuzzy：模糊字符串匹配。<a href="https://github.com/seatgeek/fuzzywuzzy" target="_blank" rel="external">官网</a></li><li>Levenshtein：快速计算编辑距离以及字符串的相似度。<a href="https://github.com/ztane/python-Levenshtein/" target="_blank" rel="external">官网</a></li><li>pangu.py：在中日韩语字符和数字字母之间添加空格。<a href="https://github.com/vinta/pangu.py" target="_blank" rel="external">官网</a></li><li>yfiglet-figlet：<a href="https://github.com/pwaller/pyfiglet" target="_blank" rel="external">pyfiglet -figlet</a> 的 Python实现。</li><li>shortuuid：一个生成器库，用以生成简洁的，明白的，URL 安全的 UUID。<a href="https://github.com/stochastic-technologies/shortuuid" target="_blank" rel="external">官网</a></li><li>unidecode：Unicode 文本的 ASCII 转换形式 。<a href="https://pypi.python.org/pypi/Unidecode" target="_blank" rel="external">官网</a></li><li>uniout：打印可读的字符，而不是转义的字符串。<a href="https://github.com/moskytw/uniout" target="_blank" rel="external">官网</a></li><li>xpinyin：一个用于把汉字转换为拼音的库。<a href="https://github.com/lxneng/xpinyin" target="_blank" rel="external">官网</a></li><li>simplejson：Python的JSON编码、解码器。<a href="https://simplejson.readthedocs.io/en/latest/" target="_blank" rel="external">官网</a>、<a href="https://github.com/simplejson/simplejson" target="_blank" rel="external">GitHub</a></li></ul></li><li>Slug化<ul><li>awesome-slugify：一个 Python slug 化库，可以保持 Unicode。<a href="https://github.com/dimka665/awesome-slugify" target="_blank" rel="external">官网</a></li><li>python-slugify：Python slug 化库，可以把 unicode 转化为 ASCII。<a href="https://github.com/un33k/python-slugify" target="_blank" rel="external">官网</a></li><li>unicode-slugify：一个 slug 工具，可以生成 unicode slugs ,需要依赖 Django 。<a href="https://github.com/mozilla/unicode-slugify" target="_blank" rel="external">官网</a></li></ul></li><li>解析器<ul><li>phonenumbers：解析，格式化，储存，验证电话号码。<a href="https://github.com/daviddrysdale/python-phonenumbers" target="_blank" rel="external">官网</a></li><li>PLY：lex 和 yacc 解析工具的 Python 实现。<a href="http://www.dabeaz.com/ply/" target="_blank" rel="external">官网</a></li><li>Pygments：通用语法高亮工具。<a href="http://pygments.org/" target="_blank" rel="external">官网</a></li><li>pyparsing：生成通用解析器的框架。<a href="http://pyparsing.wikispaces.com/" target="_blank" rel="external">官网</a></li><li>python-nameparser：把一个人名分解为几个独立的部分。<a href="https://github.com/derek73/python-nameparser" target="_blank" rel="external">官网</a></li><li>python-user-agents：浏览器 user agent 解析器。<a href="https://github.com/selwin/python-user-agents" target="_blank" rel="external">官网</a></li><li>sqlparse：一个无验证的 SQL 解析器。<a href="https://sqlparse.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li></ul></li></ul><h3 id="特殊文本格式处理"><a href="#特殊文本格式处理" class="headerlink" title="特殊文本格式处理"></a>特殊文本格式处理</h3><p>一些用来解析和操作特殊文本格式的库。</p><ul><li>通用<ul><li>tablib：一个用来处理中表格数据的模块。<a href="https://github.com/kennethreitz/tablib" target="_blank" rel="external">官网</a></li></ul></li><li>Office<ul><li>Marmir：把输入的Python 数据结构转换为电子表单。<a href="https://github.com/brianray/mm" target="_blank" rel="external">官网</a></li><li>openpyxl：一个用来读写 Excel 2010 xlsx/xlsm/xltx/xltm 文件的库。<a href="https://openpyxl.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>python-docx：读取，查询以及修改 Microsoft Word 2007/2008 docx 文件。<a href="https://github.com/python-openxml/python-docx" target="_blank" rel="external">官网</a></li><li>unoconv：在 LibreOffice/OpenOffice 支持的任意文件格式之间进行转换。<a href="https://github.com/dagwieers/unoconv" target="_blank" rel="external">官网</a></li><li>XlsxWriter：一个用于创建 Excel .xlsx 文件的 Python 模块。<a href="https://xlsxwriter.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>xlwings：一个使得在 Excel 中方便调用 Python 的库（反之亦然），基于 BSD 协议。<a href="http://xlwings.org/" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/xlwt/" target="_blank" rel="external">xlwt</a>：读写 Excel 文件的数据和格式信息。<a href="https://github.com/python-excel/xlwt" target="_blank" rel="external">官网</a> / <a href="https://github.com/python-excel/xlrd" target="_blank" rel="external">xlrd</a></li><li>relatorio：模板化OpenDocument 文件。<a href="http://relatorio.tryton.org/" target="_blank" rel="external">官网</a></li></ul></li><li>PDF<ul><li>PDFMiner：一个用于从PDF文档中抽取信息的工具。<a href="https://github.com/euske/pdfminer" target="_blank" rel="external">官网</a></li><li>PyPDF2：一个可以分割，合并和转换 PDF 页面的库。<a href="https://github.com/mstamy2/PyPDF2" target="_blank" rel="external">官网</a></li><li>ReportLab：快速创建富文本 PDF 文档。<a href="http://www.reportlab.com/opensource/" target="_blank" rel="external">官网</a></li></ul></li><li>Markdown<ul><li>Mistune：快速并且功能齐全的纯 Python 实现的 Markdown 解析器。<a href="https://github.com/lepture/mistune" target="_blank" rel="external">官网</a></li><li>Python-Markdown：John Gruber’s Markdown 的 Python 版实现。<a href="https://github.com/waylan/Python-Markdown" target="_blank" rel="external">官网</a></li><li>Python-Markdown2：纯 Python 实现的 Markdown 解析器，比 Python-Markdown 更快，更准确，可扩展。<a href="https://github.com/trentm/python-markdown2" target="_blank" rel="external">官网</a></li></ul></li><li>YAML<ul><li>PyYAML：Python 版本的 YAML 解析器。<a href="http://pyyaml.org/" target="_blank" rel="external">官网</a></li></ul></li><li>CSV<ul><li>csvkit：用于转换和操作 CSV 的工具。<a href="https://github.com/wireservice/csvkit" target="_blank" rel="external">官网</a></li></ul></li><li>Archive<ul><li>unp：一个用来方便解包归档文件的命令行工具。<a href="https://github.com/mitsuhiko/unp" target="_blank" rel="external">官网</a></li></ul></li></ul><h3 id="自然语言处理"><a href="#自然语言处理" class="headerlink" title="自然语言处理"></a>自然语言处理</h3><p>用来处理人类语言的库。</p><ul><li><a href="http://hao.jobbole.com/nltk/" target="_blank" rel="external">NLTK</a>：一个先进的平台，用以构建处理人类语言数据的 Python 程序。<a href="http://www.nltk.org/" target="_blank" rel="external">官网</a></li><li>jieba：中文分词工具。<a href="https://github.com/fxsjy/jieba" target="_blank" rel="external">官网</a></li><li>langid.py：独立的语言识别系统。<a href="https://github.com/saffsd/langid.py" target="_blank" rel="external">官网</a></li><li>Pattern：Python 网络信息挖掘模块。<a href="http://www.clips.ua.ac.be/pattern" target="_blank" rel="external">官网</a></li><li>SnowNLP：一个用来处理中文文本的库。<a href="https://github.com/isnowfy/snownlp" target="_blank" rel="external">官网</a></li><li>TextBlob：为进行普通自然语言处理任务提供一致的 API。<a href="http://textblob.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>TextGrocery：一简单高效的短文本分类工具，基于 LibLinear 和 Jieba。<a href="https://github.com/2shou/TextGrocery" target="_blank" rel="external">官网</a></li></ul><h3 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h3><p>用以生成项目文档的库。</p><ul><li><a href="http://hao.jobbole.com/sphinx/" target="_blank" rel="external">Sphinx</a>：Python 文档生成器。<a href="http://www.sphinx-doc.org/en/latest/" target="_blank" rel="external">官网</a><ul><li>awesome-sphinxdoc：<a href="https://github.com/yoloseem/awesome-sphinxdoc" target="_blank" rel="external">官网</a></li></ul></li><li>MkDocs：对 Markdown 友好的文档生成器。<a href="http://www.mkdocs.org/" target="_blank" rel="external">官网</a></li><li>pdoc：一个可以替换Epydoc 的库，可以自动生成 Python 库的 API 文档。<a href="https://github.com/BurntSushi/pdoc" target="_blank" rel="external">官网</a></li><li>Pycco：文学编程（literate-programming）风格的文档生成器。<a href="https://github.com/pycco-docs/pycco" target="_blank" rel="external">官网</a></li></ul><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>用来保存和解析配置的库。</p><ul><li>config：<a href="https://docs.python.org/2/library/logging.html" target="_blank" rel="external">logging</a> 模块作者写的分级配置模块。<a href="https://www.red-dove.com/config-doc/" target="_blank" rel="external">官网</a></li><li>ConfigObj：INI 文件解析器，带验证功能。<a href="http://www.voidspace.org.uk/python/configobj.html" target="_blank" rel="external">官网</a></li><li>ConfigParser：(Python 标准库) INI 文件解析器。<a href="https://docs.python.org/2/library/configparser.html" target="_blank" rel="external">官网</a></li><li>profig：通过多种格式进行配置，具有数值转换功能。<a href="http://profig.readthedocs.org/en/default/" target="_blank" rel="external">官网</a></li><li>python-decouple：将设置和代码完全隔离。<a href="https://github.com/henriquebastos/python-decouple" target="_blank" rel="external">官网</a></li></ul><h3 id="命令行工具"><a href="#命令行工具" class="headerlink" title="命令行工具"></a>命令行工具</h3><p>用于创建命令行程序的库。</p><ul><li>命令行程序开发<ul><li>asciimatics：跨平台，全屏终端包（即鼠标/键盘输入和彩色，定位文本输出），完整的复杂动画和特殊效果的高级API。<a href="https://github.com/peterbrittain/asciimatics" target="_blank" rel="external">官网</a></li><li>cement：Python 的命令行程序框架。<a href="http://builtoncement.com/" target="_blank" rel="external">官网</a></li><li>click：一个通过组合的方式来创建精美命令行界面的包。<a href="http://click.pocoo.org/dev/" target="_blank" rel="external">官网</a></li><li>cliff：一个用于创建命令行程序的框架，可以创建具有多层命令的命令行程序。<a href="http://docs.openstack.org/developer/cliff/" target="_blank" rel="external">官网</a></li><li>clint：Python 命令行程序工具。<a href="https://github.com/kennethreitz/clint" target="_blank" rel="external">官网</a></li><li>colorama：跨平台彩色终端文本。<a href="https://pypi.python.org/pypi/colorama" target="_blank" rel="external">官网</a></li><li>docopt：Python 风格的命令行参数解析器。<a href="http://docopt.org/" target="_blank" rel="external">官网</a></li><li>Gooey：一条命令，将命令行程序变成一个 GUI 程序。<a href="https://github.com/chriskiehl/Gooey" target="_blank" rel="external">官网</a></li><li>python-prompt-toolkit：一个用于构建强大的交互式命令行程序的库。<a href="https://github.com/jonathanslenders/python-prompt-toolkit" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/pythonpy/" target="_blank" rel="external">Pythonpy</a>：在命令行中直接执行任何Python指令。<a href="https://github.com/Russell91/pythonpy/wiki" target="_blank" rel="external">官网</a></li></ul></li><li>生产力工具<ul><li>aws-cli：Amazon Web Services 的通用命令行界面。<a href="https://github.com/aws/aws-cli" target="_blank" rel="external">官网</a></li><li>bashplotlib：在终端中进行基本绘图。<a href="https://github.com/glamp/bashplotlib" target="_blank" rel="external">官网</a></li><li>caniusepython3：判断是哪个项目妨碍你你移植到 Python 3。<a href="https://github.com/brettcannon/caniusepython3" target="_blank" rel="external">官网</a></li><li>cookiecutter：从 cookiecutters（项目模板）创建项目的一个命令行工具。<a href="https://github.com/audreyr/cookiecutter" target="_blank" rel="external">官网</a></li><li>doitlive：一个用来在终端中进行现场演示的工具。<a href="https://github.com/sloria/doitlive" target="_blank" rel="external">官网</a></li><li>howdoi：通过命令行获取即时的编程问题解答。<a href="https://github.com/gleitz/howdoi" target="_blank" rel="external">官网</a></li><li>httpie：一个命令行HTTP 客户端，cURL 的替代品，易用性更好。<a href="https://github.com/jkbrzt/httpie" target="_blank" rel="external">官网</a></li><li>PathPicker：从bash输出中选出文件。<a href="https://github.com/facebook/PathPicker" target="_blank" rel="external">官网</a></li><li>percol：向UNIX shell 传统管道概念中加入交互式选择功能。<a href="https://github.com/mooz/percol" target="_blank" rel="external">官网</a></li><li>SAWS：一个加强版的 AWS 命令行。<a href="https://github.com/donnemartin/saws" target="_blank" rel="external">官网</a></li><li>thefuck：修正你之前的命令行指令。<a href="https://github.com/nvbn/thefuck" target="_blank" rel="external">官网</a></li><li>mycli：一个 MySQL 命令行客户端，具有自动补全和语法高亮功能。<a href="https://github.com/dbcli/mycli" target="_blank" rel="external">官网</a></li><li>pgcli：Postgres 命令行工具，具有自动补全和语法高亮功能。<a href="https://github.com/dbcli/pgcli" target="_blank" rel="external">官网</a></li><li>try：一个从来没有更简单的命令行工具，用来试用python库。<a href="https://github.com/timofurrer/try" target="_blank" rel="external">官网</a></li></ul></li></ul><h3 id="下载器"><a href="#下载器" class="headerlink" title="下载器"></a>下载器</h3><p>用来进行下载的库.</p><ul><li>s3cmd：一个用来管理Amazon S3 和 CloudFront 的命令行工具。<a href="https://github.com/s3tools/s3cmd" target="_blank" rel="external">官网</a></li><li>s4cmd：超级 S3 命令行工具，性能更加强劲。<a href="https://github.com/bloomreach/s4cmd" target="_blank" rel="external">官网</a></li><li>you-get：一个 YouTube/Youku/Niconico 视频下载器，使用 Python3 编写。<a href="https://www.soimort.org/you-get/" target="_blank" rel="external">官网</a></li><li>youtube-dl：一个小巧的命令行程序，用来下载 YouTube 视频。<a href="http://rg3.github.io/youtube-dl/" target="_blank" rel="external">官网</a></li></ul><h3 id="图像处理"><a href="#图像处理" class="headerlink" title="图像处理"></a>图像处理</h3><p>用来操作图像的库.</p><ul><li><a href="http://hao.jobbole.com/pillow/" target="_blank" rel="external">pillow</a>：Pillow 是一个更加易用版的 <a href="http://www.pythonware.com/products/pil/" target="_blank" rel="external">PIL</a>。<a href="http://pillow.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>hmap：图像直方图映射。<a href="https://github.com/rossgoodwin/hmap" target="_blank" rel="external">官网</a></li><li>imgSeek：一个使用视觉相似性搜索一组图片集合的项目。<a href="https://sourceforge.net/projects/imgseek/" target="_blank" rel="external">官网</a></li><li>nude.py：裸体检测。<a href="https://github.com/hhatto/nude.py" target="_blank" rel="external">官网</a></li><li>pyBarcode：不借助 PIL 库在 Python 程序中生成条形码。<a href="https://pythonhosted.org/pyBarcode/" target="_blank" rel="external">官网</a></li><li>pygram：类似 Instagram 的图像滤镜。<a href="https://github.com/ajkumar25/pygram" target="_blank" rel="external">官网</a></li><li>python-qrcode：一个纯 Python 实现的二维码生成器。<a href="https://github.com/lincolnloop/python-qrcode" target="_blank" rel="external">官网</a></li><li>Quads：基于四叉树的计算机艺术。<a href="https://github.com/fogleman/Quads" target="_blank" rel="external">官网</a></li><li>scikit-image：一个用于（科学）图像处理的 Python 库。<a href="http://scikit-image.org/" target="_blank" rel="external">官网</a></li><li>thumbor：一个小型图像服务，具有剪裁，尺寸重设和翻转功能。<a href="https://github.com/thumbor/thumbor" target="_blank" rel="external">官网</a></li><li>wand：<a href="http://www.imagemagick.org/script/magick-wand.php" target="_blank" rel="external">MagickWand</a>的Python 绑定。MagickWand 是 ImageMagick的 C API 。<a href="https://github.com/dahlia/wand" target="_blank" rel="external">官网</a></li></ul><h3 id="OCR"><a href="#OCR" class="headerlink" title="OCR"></a>OCR</h3><p>光学字符识别库。</p><ul><li>pyocr：Tesseract 和 Cuneiform 的一个封装(wrapper)。<a href="https://github.com/jflesch/pyocr" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/pytesseract/" target="_blank" rel="external">pytesseract</a>：<a href="https://github.com/tesseract-ocr" target="_blank" rel="external">Google Tesseract OCR</a> 的另一个封装(wrapper)。<a href="https://github.com/madmaze/pytesseract" target="_blank" rel="external">官网</a></li><li>python-tesseract - <a href="https://github.com/tesseract-ocr" target="_blank" rel="external">Google Tesseract OCR</a> 的一个包装类。</li></ul><h3 id="音频"><a href="#音频" class="headerlink" title="音频"></a>音频</h3><p>用来操作音频的库</p><ul><li>audiolazy：Python 的数字信号处理包。<a href="https://github.com/danilobellini/audiolazy" target="_blank" rel="external">官网</a> </li><li>audioread：交叉库 (GStreamer + Core Audio + MAD + FFmpeg) 音频解码。<a href="https://github.com/beetbox/audioread" target="_blank" rel="external">官网</a></li><li>beets：一个音乐库管理工具及 <a href="https://musicbrainz.org/" target="_blank" rel="external">MusicBrainz</a> 标签添加工具<a href="http://beets.io/" target="_blank" rel="external">官网</a></li><li>dejavu：音频指纹提取和识别<a href="https://github.com/worldveil/dejavu" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/django-elastic-transcoder/" target="_blank" rel="external">django-elastic-transcoder</a>：Django + <a href="http://aws.amazon.com/elastictranscoder/" target="_blank" rel="external">Amazon Elastic Transcoder</a>。<a href="https://github.com/StreetVoice/django-elastic-transcoder" target="_blank" rel="external">官网</a></li><li>eyeD3：一个用来操作音频文件的工具，具体来讲就是包含 ID3 元信息的 MP3 文件。<a href="http://eyed3.nicfit.net/" target="_blank" rel="external">官网</a></li><li>id3reader：一个用来读取 MP3 元数据的 Python 模块。<a href="http://nedbatchelder.com/code/modules/id3reader.py" target="_blank" rel="external">官网</a></li><li>m3u8：一个用来解析 m3u8 文件的模块。<a href="https://github.com/globocom/m3u8" target="_blank" rel="external">官网</a></li><li>mutagen：一个用来处理音频元数据的 Python 模块。<a href="https://bitbucket.org/lazka/mutagen" target="_blank" rel="external">官网</a></li><li>pydub：通过简单、简洁的高层接口来操作音频文件。<a href="https://github.com/jiaaro/pydub" target="_blank" rel="external">官网</a></li><li>pyechonest：<a href="http://developer.echonest.com/" target="_blank" rel="external">Echo Nest</a> API 的 Python 客户端<a href="https://github.com/echonest/pyechonest" target="_blank" rel="external">官网</a></li><li>talkbox：一个用来处理演讲/信号的 Python 库<a href="http://scikits.appspot.com/talkbox" target="_blank" rel="external">官网</a></li><li>TimeSide：开源 web 音频处理框架。<a href="https://github.com/Parisson/TimeSide" target="_blank" rel="external">官网</a></li><li>tinytag：一个用来读取MP3, OGG, FLAC 以及 Wave 文件音乐元数据的库。<a href="https://github.com/devsnd/tinytag" target="_blank" rel="external">官网</a></li><li>mingus：一个高级音乐理论和曲谱包，支持 MIDI 文件和回放功能。<a href="http://bspaans.github.io/python-mingus/" target="_blank" rel="external">官网</a></li></ul><h3 id="Video"><a href="#Video" class="headerlink" title="Video"></a>Video</h3><p>用来操作视频和GIF的库。</p><ul><li>moviepy：一个用来进行基于脚本的视频编辑模块，适用于多种格式，包括动图 GIFs。<a href="http://zulko.github.io/moviepy/" target="_blank" rel="external">官网</a></li><li>scikit-video：SciPy 视频处理常用程序。<a href="https://github.com/aizvorski/scikit-video" target="_blank" rel="external">官网</a></li></ul><h3 id="地理位置"><a href="#地理位置" class="headerlink" title="地理位置"></a>地理位置</h3><p>地理编码地址以及用来处理经纬度的库。</p><ul><li>GeoDjango：世界级地理图形 web 框架。<a href="https://docs.djangoproject.com/en/dev/ref/contrib/gis/" target="_blank" rel="external">官网</a></li><li>GeoIP：MaxMind GeoIP Legacy 数据库的 Python API。<a href="https://github.com/maxmind/geoip-api-python" target="_blank" rel="external">官网</a></li><li>geojson：GeoJSON 的 Python 绑定及工具。<a href="https://github.com/frewsxcv/python-geojson" target="_blank" rel="external">官网</a></li><li>geopy：Python 地址编码工具箱。<a href="https://github.com/geopy/geopy" target="_blank" rel="external">官网</a></li><li>pygeoip：纯 Python GeoIP API。<a href="https://github.com/appliedsec/pygeoip" target="_blank" rel="external">官网</a></li><li>django-countries：一个 Django 应用程序，提供用于表格的国家选择功能，国旗图标静态文件以及模型中的国家字段。<a href="https://github.com/SmileyChris/django-countries" target="_blank" rel="external">官网</a></li></ul><h3 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h3><p>使用HTTP的库。</p><ul><li>requests：人性化的HTTP请求库。<a href="http://docs.python-requests.org/en/latest/" target="_blank" rel="external">官网</a></li><li>grequests：requests 库 + gevent ，用于异步 HTTP 请求.<a href="https://github.com/kennethreitz/grequests" target="_blank" rel="external">官网</a></li><li>httplib2：全面的 HTTP 客户端库。<a href="https://github.com/jcgregorio/httplib2" target="_blank" rel="external">官网</a></li><li>treq：类似 requests 的Python API 构建于 Twisted HTTP 客户端之上。<a href="https://github.com/twisted/treq" target="_blank" rel="external">官网</a></li><li>urllib3：一个具有线程安全连接池，支持文件 post，清晰友好的 HTTP 库。<a href="https://github.com/shazow/urllib3" target="_blank" rel="external">官网</a></li></ul><h3 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h3><p>Python实现的数据库。</p><ul><li>pickleDB：一个简单，轻量级键值储存数据库。<a href="https://pythonhosted.org/pickleDB/" target="_blank" rel="external">官网</a></li><li>PipelineDB：流式 SQL 数据库。<a href="https://www.pipelinedb.com/" target="_blank" rel="external">官网</a></li><li>TinyDB：一个微型的，面向文档型数据库。<a href="https://github.com/msiemens/tinydb" target="_blank" rel="external">官网</a></li><li>ZODB：一个 Python 原生对象数据库。一个键值和对象图数据库。<a href="http://www.zodb.org/en/latest/" target="_blank" rel="external">官网</a></li></ul><h3 id="数据库驱动"><a href="#数据库驱动" class="headerlink" title="数据库驱动"></a>数据库驱动</h3><p>用来连接和操作数据库的库。</p><ul><li>MySQL：<a href="http://shlomi-noach.github.io/awesome-mysql/" target="_blank" rel="external">awesome-mysql</a>系列<ul><li>mysql-python：Python 的 MySQL 数据库连接器。<a href="https://sourceforge.net/projects/mysql-python/" target="_blank" rel="external">官网</a></li><li>ysqlclient：<a href="https://github.com/PyMySQL/mysqlclient-python" target="_blank" rel="external">mysql-python</a> 分支，支持 Python 3。</li><li>oursql：一个更好的 MySQL 连接器，支持原生预编译指令和 BLOBs.<a href="https://pythonhosted.org/oursql/" target="_blank" rel="external">官网</a></li><li>PyMySQL：纯 Python MySQL 驱动，兼容 mysql-python。<a href="https://github.com/PyMySQL/PyMySQL" target="_blank" rel="external">官网</a></li></ul></li><li>PostgreSQL<ul><li>psycopg2：Python 中最流行的 PostgreSQL 适配器。<a href="http://initd.org/psycopg/" target="_blank" rel="external">官网</a></li><li>queries：psycopg2 库的封装，用来和 PostgreSQL 进行交互。<a href="https://github.com/gmr/queries" target="_blank" rel="external">官网</a></li><li>txpostgres：基于 Twisted 的异步 PostgreSQL 驱动。<a href="http://txpostgres.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li></ul></li><li>其他关系型数据库<ul><li>apsw：另一个 Python SQLite封装。<a href="http://rogerbinns.github.io/apsw/" target="_blank" rel="external">官网</a></li><li>dataset：在数据库中存储Python字典</li><li>pymssql：一个简单的Microsoft SQL Server数据库接口。<a href="http://www.pymssql.org/en/latest/" target="_blank" rel="external">官网</a></li></ul></li><li>NoSQL 数据库<ul><li>cassandra-python-driver：Cassandra 的 Python 驱动。<a href="https://github.com/datastax/python-driver" target="_blank" rel="external">官网</a></li><li>HappyBase：一个为 Apache HBase 设计的，对开发者友好的库。<a href="http://happybase.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>Plyvel：一个快速且功能丰富的 LevelDB 的 Python 接口。<a href="https://plyvel.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>py2neo：Neo4j restful 接口的Python 封装客户端。<a href="http://py2neo.org/2.0/" target="_blank" rel="external">官网</a></li><li>pycassa：Cassandra 的 Python Thrift 驱动。<a href="https://github.com/pycassa/pycassa" target="_blank" rel="external">官网</a></li><li>PyMongo：MongoDB 的官方 Python 客户端。<a href="https://docs.mongodb.org/ecosystem/drivers/python/" target="_blank" rel="external">官网</a></li><li>redis-py：Redis 的 Python 客户端。<a href="https://github.com/andymccurdy/redis-py" target="_blank" rel="external">官网</a></li><li>telephus：基于 Twisted 的 Cassandra 客户端。<a href="https://github.com/driftx/Telephus" target="_blank" rel="external">官网</a></li><li>txRedis：基于 Twisted 的 Redis 客户端。<a href="https://github.com/deldotdr/txRedis" target="_blank" rel="external">官网</a></li></ul></li></ul><h3 id="ORM"><a href="#ORM" class="headerlink" title="ORM"></a>ORM</h3><p>实现对象关系映射或数据映射技术的库。</p><ul><li>关系型数据库<ul><li>Django Models：Django 的一部分。<a href="https://docs.djangoproject.com/en/dev/topics/db/models/" target="_blank" rel="external">官网</a></li><li>SQLAlchemy：Python SQL 工具以及对象关系映射工具。<a href="http://www.sqlalchemy.org/" target="_blank" rel="external">官网</a><ul><li><a href="https://github.com/dahlia/awesome-sqlalchemy" target="_blank" rel="external">awesome-sqlalchemy</a>系列</li></ul></li><li><a href="http://hao.jobbole.com/peewee/" target="_blank" rel="external">Peewee</a>：一个小巧，富有表达力的 ORM。<a href="https://github.com/coleifer/peewee" target="_blank" rel="external">官网</a></li><li>PonyORM：提供面向生成器的 SQL 接口的 ORM。<a href="https://ponyorm.com/" target="_blank" rel="external">官网</a></li><li>python-sql：编写 Python 风格的 SQL 查询。<a href="https://pypi.python.org/pypi/python-sql" target="_blank" rel="external">官网</a></li></ul></li><li>NoSQL 数据库<ul><li>django-mongodb-engine：Django MongoDB 后端。<a href="https://github.com/django-nonrel/mongodb-engine" target="_blank" rel="external">官网</a></li><li>PynamoDB：<a href="https://aws.amazon.com/dynamodb/" target="_blank" rel="external">Amazon DynamoDB</a> 的一个 Python 风格接口。<a href="https://github.com/jlafon/PynamoDB" target="_blank" rel="external">官网</a></li><li>flywheel：Amazon DynamoDB 的对象映射工具。<a href="https://github.com/mathcamp/flywheel" target="_blank" rel="external">官网</a></li><li>MongoEngine：一个Python 对象文档映射工具，用于 MongoDB。<a href="http://mongoengine.org/" target="_blank" rel="external">官网</a></li><li>hot-redis：为 Redis 提供 Python 丰富的数据类型。<a href="https://github.com/stephenmcd/hot-redis" target="_blank" rel="external">官网</a></li><li>redisco：一个 Python 库，提供可以持续存在在 Redis 中的简单模型和容器。<a href="https://github.com/kiddouk/redisco" target="_blank" rel="external">官网</a></li></ul></li><li>其他<ul><li>butterdb：Google Drive 电子表格的 Python ORM。<a href="https://github.com/Widdershin/butterdb" target="_blank" rel="external">官网</a></li></ul></li></ul><h3 id="Web-框架"><a href="#Web-框架" class="headerlink" title="Web 框架"></a>Web 框架</h3><p>全栈 Web 框架。</p><ul><li><a href="http://hao.jobbole.com/django/" target="_blank" rel="external">Django</a>：Python 界最流行的 web 框架。<a href="https://www.djangoproject.com/" target="_blank" rel="external">官网</a><ul><li><a href="https://gitlab.com/rosarior/awesome-django" target="_blank" rel="external">awesome-django</a>系列</li></ul></li><li><a href="http://hao.jobbole.com/flask/" target="_blank" rel="external">Flask</a>：一个 Python 微型框架。<a href="http://flask.pocoo.org/" target="_blank" rel="external">官网</a><ul><li><a href="https://github.com/humiaozuzu/awesome-flask" target="_blank" rel="external">awesome-flask</a>系列</li></ul></li><li>pyramid：一个小巧，快速，接地气的开源Python web 框架。<ul><li><a href="https://github.com/uralbash/awesome-pyramid" target="_blank" rel="external">awesome-pyramid</a>系列</li></ul></li><li><a href="http://hao.jobbole.com/bottle/" target="_blank" rel="external">Bottle</a>：一个快速小巧，轻量级的 WSGI 微型 web 框架。<a href="http://bottlepy.org/docs/dev/index.html" target="_blank" rel="external">官网</a></li><li>CherryPy：一个极简的 Python web 框架，服从 HTTP/1.1 协议且具有WSGI 线程池。<a href="http://www.cherrypy.org/" target="_blank" rel="external">官网</a></li><li>TurboGears：一个可以扩展为全栈解决方案的微型框架。<a href="http://www.turbogears.org/" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/python-webpy/" target="_blank" rel="external">web.py</a>：一个 Python 的 web 框架，既简单，又强大。<a href="http://webpy.org/" target="_blank" rel="external">官网</a></li><li>web2py：一个全栈 web 框架和平台，专注于简单易用。<a href="http://www.web2py.com/" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/tornado/" target="_blank" rel="external">Tornado</a>：一个web 框架和异步网络库。<a href="http://www.tornadoweb.org/en/latest/" target="_blank" rel="external">官网</a></li></ul><h3 id="权限"><a href="#权限" class="headerlink" title="权限"></a>权限</h3><p>允许或拒绝用户访问数据或功能的库。</p><ul><li>Carteblanche：Module to align code with thoughts of users and designers. Also magically handles navigation and permissions.<a href="https://github.com/neuman/python-carteblanche/" target="_blank" rel="external">官网</a></li><li>django-guardian：Django 1.2+ 实现了单个对象权限。<a href="https://github.com/django-guardian/django-guardian" target="_blank" rel="external">官网</a></li><li>django-rules：一个小巧但是强大的应用，提供对象级别的权限管理，且不需要使用数据库。<a href="https://github.com/dfunckt/django-rules" target="_blank" rel="external">官网</a></li></ul><h3 id="CMS"><a href="#CMS" class="headerlink" title="CMS"></a>CMS</h3><p>内容管理系统</p><ul><li>odoo-cms: 一个开源的，企业级 CMS，基于odoo。<a href="http://www.odoo.com" target="_blank" rel="external">官网</a></li><li>django-cms：一个开源的，企业级 CMS，基于 Django。<a href="http://www.django-cms.org/en/" target="_blank" rel="external">官网</a></li><li>djedi-cms：一个轻量级但却非常强大的 Django CMS ，考虑到了插件，内联编辑以及性能。<a href="http://djedi-cms.org/" target="_blank" rel="external">官网</a></li><li>FeinCMS：基于 Django 构建的最先进的内容管理系统之一。<a href="http://www.feincms.org/" target="_blank" rel="external">官网</a></li><li>Kotti：一个高级的，Python 范的 web 应用框架，基于 Pyramid 构建。<a href="http://kotti.pylonsproject.org/" target="_blank" rel="external">官网</a></li><li>Mezzanine：一个强大的，持续的，灵活的内容管理平台。<a href="http://mezzanine.jupo.org/" target="_blank" rel="external">官网</a></li><li>Opps：一个为杂志，报纸网站以及大流量门户网站设计的 CMS 平台，基于 Django。<a href="http://opps.github.io/opps/" target="_blank" rel="external">官网</a></li><li>Plone：一个构建于开源应用服务器 Zope 之上的 CMS。<a href="https://plone.org/" target="_blank" rel="external">官网</a></li><li>Quokka：灵活，可扩展的小型 CMS，基于 Flask 和 MongoDB。<a href="http://quokkaproject.org/" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/wagtail/" target="_blank" rel="external">Wagtail</a>：一个 Django 内容管理系统。<a href="https://wagtail.io/" target="_blank" rel="external">官网</a></li><li>Widgy：最新的 CMS 框架，基于 Django。<a href="https://wid.gy/" target="_blank" rel="external">官网</a></li></ul><h3 id="电子商务"><a href="#电子商务" class="headerlink" title="电子商务"></a>电子商务</h3><p>用于电子商务以及支付的框架和库。</p><ul><li>django-oscar：一个用于 Django 的开源的电子商务框架。<a href="http://oscarcommerce.com/" target="_blank" rel="external">官网</a></li><li>django-shop：一个基于 Django 的店铺系统。<a href="https://github.com/awesto/django-shop" target="_blank" rel="external">官网</a></li><li>Cartridge：一个基于 Mezzanine 构建的购物车应用。<a href="https://github.com/stephenmcd/cartridge" target="_blank" rel="external">官网</a></li><li>shoop：一个基于 Django 的开源电子商务平台。<a href="https://www.shoop.io/en/" target="_blank" rel="external">官网</a></li><li>alipay：非官方的 Python 支付宝 API。<a href="https://github.com/lxneng/alipay" target="_blank" rel="external">官网</a></li><li>merchant：一个可以接收来自多种支付平台支付的 Django 应用。<a href="https://github.com/agiliq/merchant" target="_blank" rel="external">官网</a></li><li>money：货币类库with optional CLDR-backed locale-aware formatting and an extensible currency exchange solution.<a href="https://github.com/carlospalol/money" target="_blank" rel="external">官网</a></li><li>python-currencies：显示货币格式以及它的数值。<a href="https://github.com/Alir3z4/python-currencies" target="_blank" rel="external">官网</a></li></ul><h3 id="RESTful-API"><a href="#RESTful-API" class="headerlink" title="RESTful API"></a>RESTful API</h3><p>用来开发RESTful APIs的库</p><ul><li>Django<ul><li><a href="http://hao.jobbole.com/django-rest-framework/" target="_blank" rel="external">django-rest-framework</a>：一个强大灵活的工具，用来构建 web API。<a href="http://www.django-rest-framework.org/" target="_blank" rel="external">官网</a></li><li>django-tastypie：为Django 应用开发API。<a href="http://tastypieapi.org/" target="_blank" rel="external">官网</a></li><li>django-formapi：为 Django 的表单验证，创建 JSON APIs 。<a href="https://github.com/5monkeys/django-formapi" target="_blank" rel="external">官网</a></li></ul></li><li>Flask<ul><li>flask-api：为 flask 开发的，可浏览 Web APIs 。<a href="http://www.flaskapi.org/" target="_blank" rel="external">官网</a></li><li>flask-restful：为 flask 快速创建REST APIs 。<a href="http://flask-restful.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>flask-restless：为 SQLAlchemy 定义的数据库模型创建 RESTful APIs 。<a href="https://flask-restless.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>flask-api-utils：为 Flask 处理 API 表示和验证。<a href="https://github.com/marselester/flask-api-utils" target="_blank" rel="external">官网</a></li><li>eve：REST API 框架，由 Flask, MongoDB 等驱动。<a href="https://github.com/nicolaiarocci/eve" target="_blank" rel="external">官网</a></li></ul></li><li>Pyramid<ul><li>cornice：一个Pyramid 的 REST 框架 。<a href="https://cornice.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li></ul></li><li>与框架无关的<ul><li>falcon：一个用来建立云 API 和 web app 后端的高性能框架。<a href="http://falconframework.org/" target="_blank" rel="external">官网</a></li><li>sandman：为现存的数据库驱动系统自动创建 REST APIs 。<a href="https://github.com/jeffknupp/sandman" target="_blank" rel="external">官网</a></li><li>restless：框架无关的 REST 框架 ，基于从 Tastypie 学到的知识。<a href="http://restless.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>ripozo：快速创建 REST/HATEOAS/Hypermedia APIs。<a href="https://github.com/vertical-knowledge/ripozo" target="_blank" rel="external">官网</a></li></ul></li></ul><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><p>实现验证方案的库。</p><ul><li>OAuth<ul><li>Authomatic：简单但是强大的框架，身份验证/授权客户端。<a href="http://peterhudec.github.io/authomatic/" target="_blank" rel="external">官网</a></li><li>django-allauth：Django 的验证应用。<a href="https://github.com/pennersr/django-allauth" target="_blank" rel="external">官网</a></li><li>django-oauth-toolkit：为 Django 用户准备的 OAuth2。<a href="https://github.com/evonove/django-oauth-toolkit" target="_blank" rel="external">官网</a></li><li>django-oauth2-provider：为 Django 应用提供 OAuth2 接入。<a href="https://github.com/caffeinehit/django-oauth2-provider" target="_blank" rel="external">官网</a></li><li>Flask-OAuthlib：OAuth 1.0/a, 2.0 客户端实现，供 Flask 使用。<a href="https://github.com/lepture/flask-oauthlib" target="_blank" rel="external">官网</a></li><li>OAuthLib：一个 OAuth 请求-签名逻辑通用、 完整的实现。<a href="https://github.com/idan/oauthlib" target="_blank" rel="external">官网</a></li><li>python-oauth2：一个完全测试的抽象接口。用来创建 OAuth 客户端和服务端。<a href="https://github.com/joestump/python-oauth2" target="_blank" rel="external">官网</a></li><li>python-social-auth：一个设置简单的社会化验证方式。<a href="https://github.com/omab/python-social-auth" target="_blank" rel="external">官网</a></li><li>rauth：OAuth 1.0/a, 2.0, 和 Ofly 的 Python 库。<a href="https://github.com/litl/rauth" target="_blank" rel="external">官网</a></li><li>sanction：一个超级简单的OAuth2 客户端实现。<a href="https://github.com/demianbrecht/sanction" target="_blank" rel="external">官网</a></li></ul></li><li>其他<ul><li>jose：JavaScript 对象签名和加密草案的实现。<a href="https://github.com/demonware/jose" target="_blank" rel="external">官网</a></li><li>PyJWT：JSON Web 令牌草案 01。<a href="https://github.com/jpadilla/pyjwt" target="_blank" rel="external">官网</a></li><li>python-jws：JSON Web 签名草案 02 的实现。<a href="https://github.com/brianloveswords/python-jws" target="_blank" rel="external">官网</a></li><li>python-jwt：一个用来生成和验证 JSON Web 令牌的模块。<a href="https://github.com/davedoesdev/python-jwt" target="_blank" rel="external">官网</a></li></ul></li></ul><h3 id="模板引擎"><a href="#模板引擎" class="headerlink" title="模板引擎"></a>模板引擎</h3><p>模板生成和词法解析的库和工具。</p><ul><li><a href="http://hao.jobbole.com/jinja2/" target="_blank" rel="external">Jinja2</a>：一个现代的，对设计师友好的模板引擎。<a href="https://github.com/pallets/jinja" target="_blank" rel="external">官网</a></li><li>Chameleon：一个 HTML/XML 模板引擎。 模仿了 ZPT（Zope Page Templates）, 进行了速度上的优化。<a href="https://chameleon.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>Genshi：Python 模板工具，用以生成 web 感知的结果。<a href="https://genshi.edgewall.org/" target="_blank" rel="external">官网</a></li><li>Mako：Python 平台的超高速轻量级模板。<a href="http://www.makotemplates.org/" target="_blank" rel="external">官网</a></li></ul><h3 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h3><p>处理事件以及任务队列的库。</p><ul><li>celery：一个异步任务队列/作业队列，基于分布式消息传递。<a href="http://www.celeryproject.org/" target="_blank" rel="external">官网</a></li><li>huey：小型多线程任务队列。<a href="https://github.com/coleifer/huey" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/mrq/" target="_blank" rel="external">mrq</a>：Mr. Queue -一个 Python 的分布式 worker 任务队列， 使用 Redis 和 gevent。<a href="https://github.com/pricingassistant/mrq" target="_blank" rel="external">官网</a></li><li>rq：简单的 Python 作业队列。<a href="http://python-rq.org/" target="_blank" rel="external">官网</a></li><li>simpleq：一个简单的，可无限扩张的，基于亚马逊 SQS 的队列。<a href="https://github.com/rdegges/simpleq" target="_blank" rel="external">官网</a></li></ul><h3 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h3><p>对数据进行索引和执行搜索查询的库和软件。</p><ul><li>django-haystack：Django 模块化搜索。<a href="https://github.com/django-haystack/django-haystack" target="_blank" rel="external">官网</a></li><li>elasticsearch-py：Elasticsearch 的官方底层 Python 客户端。<a href="https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/index.html" target="_blank" rel="external">官网</a></li><li>elasticsearch-dsl-py：Elasticsearch 的官方高级 Python 客户端。<a href="https://github.com/elastic/elasticsearch-dsl-py" target="_blank" rel="external">官网</a> </li><li>solrpy：<a href="http://lucene.apache.org/solr/" target="_blank" rel="external">solr</a>的 Python 客户端。<a href="https://github.com/edsu/solrpy" target="_blank" rel="external">官网</a></li><li>Whoosh：一个快速的纯 Python 搜索引擎库。<a href="http://whoosh.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li></ul><h3 id="动态消息"><a href="#动态消息" class="headerlink" title="动态消息"></a>动态消息</h3><p>用来创建用户活动的库。</p><ul><li>django-activity-stream：从你的站点行为中生成通用活动信息流。<a href="https://github.com/justquick/django-activity-stream" target="_blank" rel="external">官网</a></li><li>Stream-Framework：使用 Cassandra 和 Redis 创建动态消息和通知系统。<a href="https://github.com/tschellenbach/Stream-Framework" target="_blank" rel="external">官网</a></li></ul><h3 id="资源管理"><a href="#资源管理" class="headerlink" title="资源管理"></a>资源管理</h3><p>管理、压缩、缩小网站资源的工具。</p><ul><li>django-compressor：将链接和内联的 JavaScript 或 CSS 压缩到一个单独的缓存文件中。<a href="https://github.com/django-compressor/django-compressor" target="_blank" rel="external">官网</a></li><li>django-storages：一个针对 Django 的自定义存储后端的工具集合。<a href="http://django-storages.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>fanstatic：打包、优化，并且把静态文件依赖作为 Python 的包来提供。<a href="http://www.fanstatic.org/en/latest/" target="_blank" rel="external">官网</a></li><li>File Conveyor：一个后台驻留的程序，用来发现和同步文件到 CDNs, S3 和 FTP。<a href="http://fileconveyor.org/" target="_blank" rel="external">官网</a></li><li>Flask-Assets：帮你将 web 资源整合到你的 Flask app 中。<a href="http://flask-assets.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>jinja-assets-compressor：一个 Jinja 扩展，用来编译和压缩你的资源。<a href="https://github.com/jaysonsantos/jinja-assets-compressor" target="_blank" rel="external">官网</a></li><li>webassets：为你的静态资源打包、优化和管理生成独一无二的缓存 URL。<a href="http://webassets.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li></ul><h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><p>缓存数据的库。</p><ul><li>Beaker：一个缓存和会话库，可以用在 web 应用和独立 Python脚本和应用上。<a href="http://beaker.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>django-cache-machine：Django 模型的自动缓存和失效。<a href="https://github.com/django-cache-machine/django-cache-machine" target="_blank" rel="external">官网</a></li><li>django-cacheops：具有自动颗粒化事件驱动失效功能的 ORM。<a href="https://github.com/Suor/django-cacheops" target="_blank" rel="external">官网</a></li><li>django-viewlet：渲染模板，同时具有额外的缓存控制功能。<a href="https://github.com/5monkeys/django-viewlet" target="_blank" rel="external">官网</a></li><li>dogpile.cache：dogpile.cache 是 Beaker 的下一代替代品，由同一作者开发。<a href="http://dogpilecache.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>HermesCache：Python 缓存库，具有基于标签的失效和 dogpile effect 保护功能。<a href="https://pypi.python.org/pypi/HermesCache" target="_blank" rel="external">官网</a></li><li>johnny-cache：django应用缓存框架。<a href="https://github.com/jmoiron/johnny-cache" target="_blank" rel="external">官网</a></li><li>pylibmc：<a href="http://libmemcached.org/libMemcached.html" target="_blank" rel="external">libmemcached</a> 接口的 Python 封装。<a href="https://github.com/lericson/pylibmc" target="_blank" rel="external">官网</a></li></ul><h3 id="电子邮件"><a href="#电子邮件" class="headerlink" title="电子邮件"></a>电子邮件</h3><p>用来发送和解析电子邮件的库。</p><ul><li>django-celery-ses：带有 AWS SES 和 Celery 的 Django email 后端。<a href="https://github.com/StreetVoice/django-celery-ses" target="_blank" rel="external">官网</a></li><li>envelopes：供人类使用的电子邮件库。<a href="http://tomekwojcik.github.io/envelopes/" target="_blank" rel="external">官网</a></li><li>flanker：一个 email 地址和 Mime 解析库。<a href="https://github.com/mailgun/flanker" target="_blank" rel="external">官网</a></li><li>imbox：Python IMAP 库<a href="https://github.com/martinrusev/imbox" target="_blank" rel="external">官网</a></li><li>inbox.py：Python SMTP 服务器。<a href="https://github.com/kennethreitz/inbox.py" target="_blank" rel="external">官网</a></li><li>inbox：一个开源电子邮件工具箱。<a href="https://github.com/nylas/sync-engine" target="_blank" rel="external">官网</a></li><li>lamson：Python 风格的 SMTP 应用服务器。<a href="https://github.com/zedshaw/lamson" target="_blank" rel="external">官网</a></li><li>mailjet：Mailjet API 实现，用来提供批量发送邮件，统计等功能。<a href="https://github.com/WoLpH/mailjet" target="_blank" rel="external">官网</a></li><li>marrow.mailer：高性能可扩展邮件分发框架。<a href="https://github.com/marrow/mailer" target="_blank" rel="external">官网</a></li><li>modoboa：一个邮件托管和管理平台，具有现代的、简约的 Web UI。<a href="https://github.com/tonioo/modoboa" target="_blank" rel="external">官网</a></li><li>pyzmail：创建，发送和解析电子邮件。<a href="http://www.magiksys.net/pyzmail/" target="_blank" rel="external">官网</a></li><li>Talon：Mailgun 库，用来抽取信息和签名。<a href="https://github.com/mailgun/talon" target="_blank" rel="external">官网</a></li></ul><h3 id="国际化"><a href="#国际化" class="headerlink" title="国际化"></a>国际化</h3><p>用来进行国际化的库。</p><ul><li>Babel：一个Python 的国际化库。<a href="http://babel.pocoo.org/en/latest/" target="_blank" rel="external">官网</a></li><li>Korean：一个韩语词态库。<a href="https://korean.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li></ul><h3 id="URL处理"><a href="#URL处理" class="headerlink" title="URL处理"></a>URL处理</h3><p>解析URLs的库</p><ul><li>furl：一个让处理 URL 更简单小型 Python 库。<a href="https://github.com/gruns/furl" target="_blank" rel="external">官网</a></li><li>purl：一个简单的，不可变的URL类，具有简洁的 API 来进行询问和处理。<a href="https://github.com/codeinthehole/purl" target="_blank" rel="external">官网</a></li><li>pyshorteners：一个纯 Python URL 缩短库。<a href="https://github.com/ellisonleao/pyshorteners" target="_blank" rel="external">官网</a></li><li>shorturl：生成短小 URL 和类似 bit.ly 短链的Python 实现。<a href="https://github.com/Alir3z4/python-shorturl" target="_blank" rel="external">官网</a></li><li>webargs：一个解析 HTTP 请求参数的库，内置对流行 web 框架的支持，包括 Flask, Django, Bottle, Tornado和 Pyramid。<a href="https://github.com/sloria/webargs" target="_blank" rel="external">官网</a></li></ul><h3 id="HTML处理"><a href="#HTML处理" class="headerlink" title="HTML处理"></a>HTML处理</h3><p>处理 HTML和XML的库。</p><ul><li>BeautifulSoup：以 Python 风格的方式来对 HTML 或 XML 进行迭代，搜索和修改。<a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/" target="_blank" rel="external">官网</a></li><li>bleach：一个基于白名单的 HTML 清理和文本链接库。<a href="http://bleach.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>cssutils：一个 Python 的 CSS 库。<a href="https://pypi.python.org/pypi/cssutils/" target="_blank" rel="external">官网</a></li><li>html5lib：一个兼容标准的 HTML 文档和片段解析及序列化库。<a href="https://github.com/html5lib/html5lib-python" target="_blank" rel="external">官网</a></li><li>lxml：一个非常快速，简单易用，功能齐全的库，用来处理 HTML 和 XML。<a href="http://lxml.de/" target="_blank" rel="external">官网</a></li><li>MarkupSafe：为Python 实现 XML/HTML/XHTML 标记安全字符串。<a href="https://github.com/pallets/markupsafe" target="_blank" rel="external">官网</a></li><li>pyquery：一个解析 HTML 的库，类似 jQuery。<a href="https://github.com/gawel/pyquery" target="_blank" rel="external">官网</a></li><li>untangle：将XML文档转换为Python对象，使其可以方便的访问。<a href="https://github.com/stchris/untangle" target="_blank" rel="external">官网</a></li><li>xhtml2pdf：HTML/CSS 转 PDF 工具。<a href="https://github.com/xhtml2pdf/xhtml2pdf" target="_blank" rel="external">官网</a></li><li>xmltodict：像处理 JSON 一样处理 XML。<a href="https://github.com/martinblech/xmltodict" target="_blank" rel="external">官网</a></li></ul><p>爬取网络站点的库</p><ul><li>Scrapy：一个快速高级的屏幕爬取及网页采集框架。<a href="http://scrapy.org/" target="_blank" rel="external">官网</a></li><li>cola：一个分布式爬虫框架。<a href="https://github.com/chineking/cola" target="_blank" rel="external">官网</a></li><li>Demiurge：基于PyQuery 的爬虫微型框架。<a href="https://github.com/matiasb/demiurge" target="_blank" rel="external">官网</a></li><li>feedparser：通用 feed 解析器。<a href="http://pythonhosted.org/feedparser/" target="_blank" rel="external">官网</a></li><li>Grab：站点爬取框架。<a href="http://grablib.org/" target="_blank" rel="external">官网</a></li><li>MechanicalSoup：用于自动和网络站点交互的 Python 库。<a href="https://github.com/hickford/MechanicalSoup" target="_blank" rel="external">官网</a></li><li>portia：Scrapy 可视化爬取。<a href="https://github.com/scrapinghub/portia" target="_blank" rel="external">官网</a></li><li>pyspider：一个强大的爬虫系统。<a href="https://github.com/binux/pyspider" target="_blank" rel="external">官网</a></li><li>RoboBrowser：一个简单的，Python 风格的库，用来浏览网站，而不需要一个独立安装的浏览器。<a href="https://github.com/jmcarp/robobrowser" target="_blank" rel="external">官网</a></li></ul><h3 id="网页内容提取"><a href="#网页内容提取" class="headerlink" title="网页内容提取"></a>网页内容提取</h3><p>用于进行网页内容提取的库。</p><ul><li>Haul：一个可以扩展的图像爬取工具。<a href="https://github.com/vinta/Haul" target="_blank" rel="external">官网</a></li><li>html2text：将 HTML 转换为 Markdown 格式文本<a href="https://github.com/Alir3z4/html2text" target="_blank" rel="external">官网</a></li><li>lassie：人性化的网页内容检索库。<a href="https://github.com/michaelhelmick/lassie" target="_blank" rel="external">官网</a></li><li>micawber：一个小型网页内容提取库，用来从 URLs 提取富内容。<a href="https://github.com/coleifer/micawber" target="_blank" rel="external">官网</a> </li><li><a href="http://hao.jobbole.com/python-newspaper/" target="_blank" rel="external">newspaper</a>：使用 Python 进行新闻提取，文章提取以及内容策展。<a href="https://github.com/codelucas/newspaper" target="_blank" rel="external">官网</a></li><li>opengraph：一个用来解析开放内容协议(Open Graph Protocol)的 Python模块。<a href="https://github.com/erikriver/opengraph" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/python-goose/" target="_blank" rel="external">python-goose</a>：HTML内容/文章提取器。<a href="https://github.com/grangier/python-goose" target="_blank" rel="external">官网</a></li><li>python-readability：arc90 公司 readability 工具的 Python 高速端口。<a href="https://github.com/buriy/python-readability" target="_blank" rel="external">官网</a></li><li>sanitize：为杂乱的数据世界带来调理性。<a href="https://github.com/Alir3z4/python-sanitize" target="_blank" rel="external">官网</a></li><li>sumy：一个为文本文件和 HTML 页面进行自动摘要的模块。<a href="https://github.com/miso-belica/sumy" target="_blank" rel="external">官网</a></li><li>textract：从任何格式的文档中提取文本，Word，PowerPoint，PDFs 等等。<a href="https://github.com/deanmalmgren/textract" target="_blank" rel="external">官网</a></li></ul><h3 id="表单"><a href="#表单" class="headerlink" title="表单"></a>表单</h3><p>进行表单操作的库。</p><ul><li>Deform：Python HTML 表单生成库，受到了 formish 表单生成库的启发。<a href="http://deform.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>django-bootstrap3：集成了 Bootstrap 3 的 Django。<a href="https://github.com/dyve/django-bootstrap3" target="_blank" rel="external">官网</a></li><li>django-crispy-forms：一个 Django 应用，他可以让你以一种非常优雅且 DRY（Don’t repeat yourself） 的方式来创建美观的表单。<a href="http://django-crispy-forms.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>django-remote-forms：一个平台独立的 Django 表单序列化工具。<a href="https://github.com/WiserTogether/django-remote-forms" target="_blank" rel="external">官网</a></li><li>WTForms：一个灵活的表单验证和呈现库。<a href="http://wtforms.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>WTForms-JSON：一个 WTForms 扩展，用来处理 JSON 数据。<a href="http://wtforms-json.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li></ul><h3 id="数据验证"><a href="#数据验证" class="headerlink" title="数据验证"></a>数据验证</h3><p>数据验证库。多用于表单验证。</p><ul><li>Cerberus：A mappings-validator with a variety of rules, normalization-features and simple customization that uses a pythonic schema-definition.<a href="http://docs.python-cerberus.org/en/stable/" target="_blank" rel="external">官网</a></li><li>colander：一个用于对从 XML, JSON，HTML 表单获取的数据或其他同样简单的序列化数据进行验证和反序列化的系统。<a href="http://docs.pylonsproject.org/projects/colander/en/latest/" target="_blank" rel="external">官网</a></li><li>kmatch：一种用于匹配/验证/筛选 Python 字典的语言。<a href="https://github.com/ambitioninc/kmatch" target="_blank" rel="external">官网</a></li><li>schema：一个用于对 Python 数据结构进行验证的库。<a href="https://github.com/keleshev/schema" target="_blank" rel="external">官网</a> </li><li>Schematics：数据结构验证。<a href="https://github.com/schematics/schematics" target="_blank" rel="external">官网</a></li><li>valideer：轻量级可扩展的数据验证和适配库。<a href="https://github.com/podio/valideer" target="_blank" rel="external">官网</a></li><li>voluptuous：一个 Python 数据验证库。主要是为了验证传入 Python的 JSON，YAML 等数据。<a href="https://github.com/alecthomas/voluptuous" target="_blank" rel="external">官网</a></li></ul><h3 id="反垃圾技术"><a href="#反垃圾技术" class="headerlink" title="反垃圾技术"></a>反垃圾技术</h3><p>帮助你和电子垃圾进行战斗的库。</p><ul><li>django-simple-captcha：一个简单、高度可定制的Django 应用，可以为任何Django表单添加验证码。<a href="https://github.com/mbi/django-simple-captcha" target="_blank" rel="external">官网</a></li><li>django-simple-spam-blocker：一个用于Django的简单的电子垃圾屏蔽工具。<a href="https://github.com/moqada/django-simple-spam-blocker" target="_blank" rel="external">官网</a></li></ul><h3 id="标记"><a href="#标记" class="headerlink" title="标记"></a>标记</h3><p>用来进行标记的库。</p><ul><li>django-taggit：简单的 Django 标记工具。<a href="https://github.com/alex/django-taggit" target="_blank" rel="external">官网</a></li></ul><h3 id="管理面板"><a href="#管理面板" class="headerlink" title="管理面板"></a>管理面板</h3><p>管理界面库。</p><ul><li>Ajenti：一个你的服务器值得拥有的管理面板。<a href="https://github.com/Eugeny/ajenti" target="_blank" rel="external">官网</a></li><li>django-suit：Django 管理界面的一个替代品 (仅对于非商业用途是免费的)。<a href="http://djangosuit.com/" target="_blank" rel="external">官网</a></li><li>django-xadmin：Django admin 的一个替代品，具有很多不错的功能。<a href="https://github.com/sshwsfc/django-xadmin" target="_blank" rel="external">官网</a></li><li>flask-admin：一个用于 Flask 的简单可扩展的管理界面框架。<a href="https://github.com/flask-admin/flask-admin" target="_blank" rel="external">官网</a></li><li>flower：一个对 Celery 集群进行实时监控和提供 web 管理界面的工具。<a href="https://github.com/mher/flower" target="_blank" rel="external">官网</a></li><li>Grappelli：Django 管理界面的一个漂亮的皮肤。<a href="http://grappelliproject.com/" target="_blank" rel="external">官网</a> </li><li>Wooey：一个 Django 应用，可以为 Python 脚本创建 web 用户界面。<a href="https://github.com/wooey/wooey" target="_blank" rel="external">官网</a></li></ul><h3 id="静态站点生成器"><a href="#静态站点生成器" class="headerlink" title="静态站点生成器"></a>静态站点生成器</h3><p>静态站点生成器是一个软件，它把文本和模板作为输入，然后输出HTML文件。</p><ul><li>Pelican：使用 Markdown 或 ReST 来处理内容， Jinja 2 来制作主题。支持 DVCS, Disqus.。AGPL 许可。<a href="http://blog.getpelican.com/" target="_blank" rel="external">官网</a></li><li>Cactus：为设计师设计的静态站点生成器。<a href="https://github.com/koenbok/Cactus/" target="_blank" rel="external">官网</a> </li><li>Hyde：基于 Jinja2 的静态站点生成器。<a href="http://hyde.github.io/" target="_blank" rel="external">官网</a></li><li>Nikola：一个静态网站和博客生成器。<a href="https://www.getnikola.com/" target="_blank" rel="external">官网</a></li><li>Tinkerer：Tinkerer 是一个博客引擎/静态站点生成器，由Sphinx驱动。<a href="http://tinkerer.me/" target="_blank" rel="external">官网</a></li><li>Lektor：一个简单易用的静态 CMS 和博客引擎。<a href="https://www.getlektor.com/" target="_blank" rel="external">官网</a></li></ul><h3 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h3><p>操作系统进程启动及通信库。</p><ul><li>envoy：比 Python <a href="https://docs.python.org/2/library/subprocess.html" target="_blank" rel="external">subprocess</a> 模块更人性化。<a href="https://github.com/kennethreitz/envoy" target="_blank" rel="external">官网</a></li><li>sarge：另一 种 subprocess 模块的封装。<a href="http://sarge.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>sh：一个完备的 subprocess 替代库。<a href="https://github.com/amoffat/sh" target="_blank" rel="external">官网</a></li></ul><h3 id="并发和并行"><a href="#并发和并行" class="headerlink" title="并发和并行"></a>并发和并行</h3><p>用以进行并发和并行操作的库。</p><ul><li>multiprocessing：(Python 标准库) 基于进程的“线程”接口。<a href="https://docs.python.org/2/library/multiprocessing.html" target="_blank" rel="external">官网</a></li><li>threading：(Python 标准库)更高层的线程接口。<a href="https://docs.python.org/2/library/threading.html" target="_blank" rel="external">官网</a></li><li>eventlet：支持 WSGI 的异步框架。<a href="http://eventlet.net/" target="_blank" rel="external">官网</a></li><li>gevent：一个基于协程的 Python 网络库，使用<a href="https://github.com/python-greenlet/greenlet" target="_blank" rel="external">greenlet</a>。<a href="http://www.gevent.org/" target="_blank" rel="external">官网</a></li><li>Tomorrow：用于产生异步代码的神奇的装饰器语法实现。<a href="https://github.com/madisonmay/Tomorrow" target="_blank" rel="external">官网</a></li><li>uvloop：在libuv之上超快速实现asyncio事件循环。<a href="https://github.com/MagicStack/uvloop" target="_blank" rel="external">官网</a></li></ul><h3 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h3><p>用于网络编程的库。</p><ul><li>asyncio：(Python 标准库) 异步 I/O, 事件循环, 协程以及任务。<a href="https://docs.python.org/3/library/asyncio.html" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/twisted/" target="_blank" rel="external">Twisted</a>：一个事件驱动的网络引擎。<a href="https://twistedmatrix.com/trac/" target="_blank" rel="external">官网</a></li><li>pulsar：事件驱动的并发框架。<a href="https://github.com/quantmind/pulsar" target="_blank" rel="external">官网</a></li><li>diesel：基于Greenlet 的事件 I/O 框架。<a href="https://github.com/dieseldev/diesel" target="_blank" rel="external">官网</a></li><li>pyzmq：一个 ZeroMQ 消息库的 Python 封装。<a href="http://zeromq.github.io/pyzmq/" target="_blank" rel="external">官网</a></li><li>txZMQ：基于 Twisted 的 ZeroMQ 消息库的 Python 封装。<a href="https://github.com/smira/txZMQ" target="_blank" rel="external">官网</a></li></ul><h3 id="WebSocket"><a href="#WebSocket" class="headerlink" title="WebSocket"></a>WebSocket</h3><p>帮助使用WebSocket的库。</p><ul><li>AutobahnPython：给 Python 、使用的 WebSocket &amp; WAMP 基于 Twisted 和 <a href="https://docs.python.org/3/library/asyncio.html" target="_blank" rel="external">asyncio</a>。<a href="https://github.com/crossbario/autobahn-python" target="_blank" rel="external">官网</a></li><li>Crossbar：开源统一应用路由(Websocket &amp; WAMP for Python on Autobahn).<a href="https://github.com/crossbario/crossbar/" target="_blank" rel="external">官网</a></li><li>django-socketio：给 Django 用的 WebSockets。<a href="https://github.com/stephenmcd/django-socketio" target="_blank" rel="external">官网</a></li><li>WebSocket-for-Python：为Python2/3 以及 PyPy 编写的 WebSocket 客户端和服务器库。<a href="https://github.com/Lawouach/WebSocket-for-Python" target="_blank" rel="external">官网</a></li></ul><h3 id="WSGI-服务器"><a href="#WSGI-服务器" class="headerlink" title="WSGI 服务器"></a>WSGI 服务器</h3><p>兼容 WSGI 的 web 服务器</p><ul><li>gunicorn：Pre-forked, 部分是由 C 语言编写的。<a href="https://pypi.python.org/pypi/gunicorn" target="_blank" rel="external">官网</a></li><li>uwsgi：uwsgi 项目的目的是开发一组全栈工具，用来建立托管服务， 由 C 语言编写。<a href="https://uwsgi-docs.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/bjoern/" target="_blank" rel="external">bjoern</a>：异步，非常快速，由 C 语言编写。<a href="https://pypi.python.org/pypi/bjoern" target="_blank" rel="external">官网</a></li><li>fapws3：异步 (仅对于网络端)，由 C 语言编写。<a href="http://www.fapws.org/" target="_blank" rel="external">官网</a></li><li>meinheld：异步，部分是由 C 语言编写的。<a href="https://pypi.python.org/pypi/meinheld" target="_blank" rel="external">官网</a></li><li>netius：异步，非常快速。<a href="https://github.com/hivesolutions/netius" target="_blank" rel="external">官网</a></li><li>paste：多线程，稳定，久经考验。<a href="http://pythonpaste.org/" target="_blank" rel="external">官网</a></li><li>rocket：多线程。<a href="https://pypi.python.org/pypi/rocket" target="_blank" rel="external">官网</a></li><li>waitress：多线程, 是它驱动着 Pyramid 框架。<a href="https://waitress.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>Werkzeug：一个 WSGI 工具库，驱动着 Flask ，而且可以很方便大嵌入到你的项目中去。<a href="http://werkzeug.pocoo.org/" target="_blank" rel="external">官网</a></li></ul><h3 id="RPC-服务器"><a href="#RPC-服务器" class="headerlink" title="RPC 服务器"></a>RPC 服务器</h3><p>兼容 RPC 的服务器。</p><ul><li>SimpleJSONRPCServer：这个库是 JSON-RPC 规范的一个实现。<a href="https://github.com/joshmarshall/jsonrpclib/" target="_blank" rel="external">官网</a></li><li>SimpleXMLRPCServer：(Python 标准库) 简单的 XML-RPC 服务器实现，单线程。<a href="https://docs.python.org/2/library/simplexmlrpcserver.html" target="_blank" rel="external">官网</a></li><li>zeroRPC：zerorpc 是一个灵活的 RPC 实现，基于 ZeroMQ 和 MessagePack。<a href="https://github.com/0rpc/zerorpc-python" target="_blank" rel="external">官网</a></li></ul><h3 id="密码学"><a href="#密码学" class="headerlink" title="密码学"></a>密码学</h3><ul><li>cryptography：这个软件包意在提供密码学基本内容和方法提供给 Python 开发者。<a href="https://cryptography.io/en/latest/" target="_blank" rel="external">官网</a></li><li>hashids：在 Python 中实现 <a href="http://hashids.org/" target="_blank" rel="external">hashids</a> 。<a href="https://github.com/davidaurelio/hashids-python" target="_blank" rel="external">官网</a></li><li>Paramiko：SSHv2 协议的 Python (2.6+, 3.3+) ，提供客户端和服务端的功能。<a href="http://www.paramiko.org/" target="_blank" rel="external">官网</a></li><li>Passlib：安全密码存储／哈希库，<a href="https://pythonhosted.org/passlib/" target="_blank" rel="external">官网</a></li><li>PyCrypto：Python 密码学工具箱。<a href="https://www.dlitz.net/software/pycrypto/" target="_blank" rel="external">官网</a></li><li>PyNacl：网络和密码学(NaCl) 库的 Python 绑定。<a href="https://github.com/pyca/pynacl" target="_blank" rel="external">官网</a></li></ul><h3 id="图形用户界面"><a href="#图形用户界面" class="headerlink" title="图形用户界面"></a>图形用户界面</h3><p>用来创建图形用户界面程序的库。</p><ul><li>curses：内建的 <a href="http://www.gnu.org/software/ncurses/" target="_blank" rel="external">ncurses</a> 封装，用来创建终端图形用户界面。<a href="https://docs.python.org/2/library/curses.html#module-curses" target="_blank" rel="external">官网</a></li><li>enaml：使用类似 QML 的Declaratic语法来创建美观的用户界面。<a href="https://github.com/nucleic/enaml" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/kivy/" target="_blank" rel="external">kivy</a>：一个用来创建自然用户交互（NUI）应用程序的库，可以运行在 Windows, Linux, Mac OS X, Android 以及 iOS平台上。<a href="https://kivy.org/" target="_blank" rel="external">官网</a></li><li>pyglet：一个Python 的跨平台窗口及多媒体库。<a href="https://bitbucket.org/pyglet/pyglet/wiki/Home" target="_blank" rel="external">官网</a></li><li>PyQt：跨平台用户界面框架 <a href="http://www.qt.io/" target="_blank" rel="external">Qt</a> 的 Python 绑定 ，支持Qt v4 和 Qt v5。<a href="https://riverbankcomputing.com/software/pyqt/intro" target="_blank" rel="external">官网</a></li><li>PySide：P跨平台用户界面框架 <a href="http://www.qt.io/" target="_blank" rel="external">Qt</a> 的 Python 绑定 ，支持Qt v4。<a href="https://wiki.qt.io/PySide" target="_blank" rel="external">官网</a></li><li>Tkinter：Tkinter 是 Python GUI 的一个事实标准库。<a href="https://wiki.python.org/moin/TkInter" target="_blank" rel="external">官网</a></li><li>Toga：一个 Python 原生的, 操作系统原生的 GUI 工具包。<a href="https://github.com/pybee/toga" target="_blank" rel="external">官网</a></li><li>urwid：一个用来创建终端 GUI 应用的库，支持组件，事件和丰富的色彩等。<a href="http://urwid.org/" target="_blank" rel="external">官网</a></li><li>wxPython：wxPython 是 wxWidgets C++ 类库和 Python 语言混合的产物。<a href="http://wxpython.org/" target="_blank" rel="external">官网</a></li><li>PyGObject：GLib/GObject/GIO/GTK+ (GTK+3) 的 Python 绑定<a href="https://wiki.gnome.org/Projects/PyGObject" target="_blank" rel="external">官网</a></li><li>Flexx：Flexx 是一个纯 Python 语言编写的用来创建 GUI 程序的工具集，它使用 web 技术进行界面的展示。<a href="https://github.com/zoofIO/flexx" target="_blank" rel="external">官网</a></li></ul><h3 id="游戏开发"><a href="#游戏开发" class="headerlink" title="游戏开发"></a>游戏开发</h3><p>超赞的游戏开发库。</p><ul><li>Cocos2d：cocos2d 是一个用来开发 2D 游戏， 示例和其他图形/交互应用的框架。基于 pyglet。<a href="http://cocos2d.org/" target="_blank" rel="external">官网</a></li><li>Panda3D：由迪士尼开发的 3D 游戏引擎，并由卡内基梅陇娱乐技术中心负责维护。使用C++编写, 针对 Python 进行了完全的封装。<a href="https://www.panda3d.org/" target="_blank" rel="external">官网</a></li><li>Pygame：Pygame 是一组 Python 模块，用来编写游戏。<a href="http://www.pygame.org/news.html" target="_blank" rel="external">官网</a></li><li>PyOgre：Ogre 3D 渲染引擎的 Python 绑定，可以用来开发游戏和仿真程序等任何 3D 应用。<a href="http://www.ogre3d.org/tikiwiki/PyOgre" target="_blank" rel="external">官网</a></li><li>PyOpenGL：OpenGL 的 Python 绑定及其相关 APIs。<a href="http://pyopengl.sourceforge.net/" target="_blank" rel="external">官网</a></li><li>PySDL2：SDL2 库的封装，基于 ctypes。<a href="http://pysdl2.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>RenPy：一个视觉小说（visual novel）引擎。<a href="https://www.renpy.org/" target="_blank" rel="external">官网</a></li></ul><h3 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h3><p>用来生成和操作日志的库。</p><ul><li>logging：(Python 标准库) 为 Python 提供日志功能。<a href="https://docs.python.org/2/library/logging.html" target="_blank" rel="external">官网</a></li><li>logbook：Logging 库的替代品。<a href="http://pythonhosted.org/Logbook/" target="_blank" rel="external">官网</a></li><li>Eliot：为复杂的和分布式系统创建日志。<a href="https://eliot.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>Raven：Sentry的 Python 客户端。<a href="http://raven.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>Sentry：实时记录和收集日志的服务器。<a href="https://pypi.python.org/pypi/sentry" target="_blank" rel="external">官网</a></li></ul><h3 id="Testing"><a href="#Testing" class="headerlink" title="Testing"></a>Testing</h3><p>进行代码库测试和生成测试数据的库。</p><ul><li>测试框架<ul><li>unittest：(Python 标准库) 单元测试框架。<a href="https://docs.python.org/2/library/unittest.html" target="_blank" rel="external">官网</a></li><li>nose：nose 扩展了 unittest 的功能。<a href="https://nose.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>contexts：一个 Python 3.3+ 的 BDD 框架。受到C# – Machine.Specifications的启发。<a href="https://github.com/benjamin-hodgson/Contexts" target="_blank" rel="external">官网</a></li><li>hypothesis：Hypothesis 是一个基于先进的 Quickcheck 风格特性的测试库。<a href="https://github.com/DRMacIver/hypothesis" target="_blank" rel="external">官网</a></li><li>mamba：Python 的终极测试工具， 拥护BDD。<a href="http://nestorsalceda.github.io/mamba/" target="_blank" rel="external">官网</a></li><li>PyAutoGUI：PyAutoGUI 是一个人性化的跨平台 GUI 自动测试模块。<a href="https://github.com/asweigart/pyautogui" target="_blank" rel="external">官网</a></li><li>pyshould：Should 风格的断言，基于 <a href="https://github.com/hamcrest/PyHamcrest" target="_blank" rel="external">PyHamcrest</a>。<a href="https://github.com/drslump/pyshould" target="_blank" rel="external">官网</a></li><li>pytest：一个成熟的全功能 Python 测试工具。<a href="http://pytest.org/latest/" target="_blank" rel="external">官网</a></li><li>green：干净，多彩的测试工具。<a href="https://github.com/CleanCut/green" target="_blank" rel="external">官网</a></li><li>pyvows：BDD 风格的测试工具，受Vows.js的启发。<a href="http://heynemann.github.io/pyvows/" target="_blank" rel="external">官网</a>-</li><li>Robot Framework：一个通用的自动化测试框架。<a href="https://github.com/robotframework/robotframework" target="_blank" rel="external">官网</a></li></ul></li><li>Web 测试<ul><li>Selenium：<a href="http://www.seleniumhq.org/" target="_blank" rel="external">Selenium</a> WebDriver 的 Python 绑定。<a href="https://pypi.python.org/pypi/selenium" target="_blank" rel="external">官网</a></li><li>locust：使用 Python 编写的，可扩展的用户加载测试工具。<a href="https://github.com/locustio/locust" target="_blank" rel="external">官网</a></li><li>sixpack：一个和语言无关的 A/B 测试框架。<a href="https://github.com/seatgeek/sixpack" target="_blank" rel="external">官网</a></li><li>splinter：开源的 web 应用测试工具。<a href="https://splinter.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li></ul></li><li>Mock测试<ul><li>mock：(Python 标准库) 一个用于伪造测试的库。<a href="https://docs.python.org/3/library/unittest.mock.html" target="_blank" rel="external">官网</a></li><li>doublex：Python 的一个功能强大的 doubles  测试框架。<a href="https://pypi.python.org/pypi/doublex" target="_blank" rel="external">官网</a></li><li>freezegun：通过伪造日期模块来生成不同的时间。<a href="https://github.com/spulec/freezegun" target="_blank" rel="external">官网</a></li><li>httmock：针对 Python 2.6+ 和 3.2+ 生成 伪造请求的库。<a href="https://github.com/patrys/httmock" target="_blank" rel="external">官网</a></li><li>httpretty：Python 的 HTTP 请求 mock 工具。<a href="http://falcao.it/HTTPretty/" target="_blank" rel="external">官网</a></li><li>responses：伪造 Python 中的 requests 库的一个通用库。<a href="https://github.com/getsentry/responses" target="_blank" rel="external">官网</a></li><li>VCR.py：在你的测试中记录和重放 HTTP 交互。<a href="https://github.com/kevin1024/vcrpy" target="_blank" rel="external">官网</a></li></ul></li><li>对象工厂<ul><li>factoryboy：一个 Python 用的测试固件 (test fixtures) 替代库。<a href="https://github.com/rbarrois/factoryboy" target="_blank" rel="external">官网</a></li><li>mixer：另外一个测试固件 (test fixtures) 替代库，支持 Django, Flask, SQLAlchemy, Peewee 等。<a href="https://github.com/klen/mixer" target="_blank" rel="external">官网</a></li><li>modelmommy：为 Django 测试创建随机固件<a href="https://github.com/vandersonmota/modelmommy" target="_blank" rel="external">官网</a></li></ul></li><li>代码覆盖率<ul><li>coverage：代码覆盖率测量。<a href="https://pypi.python.org/pypi/coverage" target="_blank" rel="external">官网</a></li></ul></li><li>伪数据<ul><li>faker：一个 Python 库，用来生成伪数据。<a href="http://www.joke2k.net/faker/" target="_blank" rel="external">官网</a></li><li>fake2db：伪数据库生成器。<a href="https://github.com/emirozer/fake2db" target="_blank" rel="external">官网</a></li><li>radar：生成随机的日期/时间。<a href="https://pypi.python.org/pypi/radar" target="_blank" rel="external">官网</a></li></ul></li><li>错误处理<ul><li>FuckIt.py：FuckIt.py 使用最先进的技术来保证你的 Python 代码无论对错都能继续运行。<a href="https://github.com/ajalt/fuckitpy" target="_blank" rel="external">官网</a></li></ul></li></ul><h3 id="代码分析和Lint工具"><a href="#代码分析和Lint工具" class="headerlink" title="代码分析和Lint工具"></a>代码分析和Lint工具</h3><p>进行代码分析，解析和操作代码库的库和工具。</p><ul><li>代码分析<ul><li>coala：语言独立和易于扩展的代码分析应用程序。<a href="http://coala-analyzer.org/" target="_blank" rel="external">官网</a></li><li>code2flow：把你的 Python 和 JavaScript 代码转换为流程图。<a href="https://github.com/scottrogowski/code2flow" target="_blank" rel="external">官网</a></li><li>pycallgraph：这个库可以把你的Python 应用的流程(调用图)进行可视化。<a href="https://github.com/gak/pycallgraph" target="_blank" rel="external">官网</a></li><li>pysonar2：Python 类型推断和检索工具。<a href="https://github.com/yinwang0/pysonar2" target="_blank" rel="external">官网</a></li></ul></li><li>Lint工具<ul><li>Flake8：模块化源码检查工具: pep8, pyflakes 以及 co。<a href="https://pypi.python.org/pypi/flake8" target="_blank" rel="external">官网</a></li><li>Pylint：一个完全可定制的源码分析器。<a href="https://www.pylint.org/" target="_blank" rel="external">官网</a></li><li>YAPF: Google的Python代码格式化工具。<a href="https://github.com/google/yapf" target="_blank" rel="external">官网</a></li><li>pylama：Python 和 JavaScript 的代码审查工具。<a href="https://pylama.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li></ul></li><li>代码格式化<ul><li>autopep8：自动格式化 Python 代码，以使其符合 PEP8 规范。<a href="https://github.com/hhatto/autopep8" target="_blank" rel="external">官网</a></li></ul></li></ul><h3 id="Debugging-Tools"><a href="#Debugging-Tools" class="headerlink" title="Debugging Tools"></a>Debugging Tools</h3><p>用来进行代码调试的库。</p><ul><li>调试器<ul><li>ipdb：IPython 启用的 <a href="https://docs.python.org/2/library/pdb.html" target="_blank" rel="external">pdb</a>。<a href="https://pypi.python.org/pypi/ipdb" target="_blank" rel="external">官网</a></li><li>pudb：全屏，基于控制台的 Python 调试器。<a href="https://pypi.python.org/pypi/pudb" target="_blank" rel="external">官网</a></li><li>pyringe：可以在 Python 进程中附加和注入代码的调试器。<a href="https://github.com/google/pyringe" target="_blank" rel="external">官网</a></li><li>wdb：一个奇异的 web 调试器，通过 WebSockets 工作。<a href="https://github.com/Kozea/wdb" target="_blank" rel="external">官网</a></li><li>winpdb：一个具有图形用户界面的 Python 调试器，可以进行远程调试，基于 rpdb2。<a href="http://winpdb.org/" target="_blank" rel="external">官网</a></li><li>django-debug-toolbar：为 Django 显示各种调试信息。<a href="https://github.com/django-debug-toolbar/django-debug-toolbar" target="_blank" rel="external">官网</a></li><li>django-devserver：一个 Django 运行服务器的替代品。<a href="https://github.com/dcramer/django-devserver" target="_blank" rel="external">官网</a></li><li>flask-debugtoolbar：django-debug-toolbar 的 flask 版。<a href="https://github.com/mgood/flask-debugtoolbar" target="_blank" rel="external">官网</a></li></ul></li><li>性能分析器<ul><li>lineprofiler：逐行性能分析。<a href="https://github.com/rkern/lineprofiler" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/memory_profiler/" target="_blank" rel="external">Memory Profiler</a>：监控 Python 代码的内存使用。<a href="http://pypi.python.org/pypi/memory_profiler" target="_blank" rel="external">官网</a>、<a href="https://github.com/fabianp/memoryprofiler" target="_blank" rel="external">内存</a></li><li>profiling：一个交互式 Python 性能分析工具。<a href="https://github.com/what-studio/profiling" target="_blank" rel="external">官网</a></li></ul></li><li>其他<ul><li>pyelftools：解析和分析 ELF 文件以及 DWARF 调试信息。<a href="https://github.com/eliben/pyelftools" target="_blank" rel="external">官网</a></li><li>python-statsd：<a href="https://github.com/etsy/statsd/" target="_blank" rel="external">statsd</a> 服务器的 Python 客户端。<a href="https://github.com/WoLpH/python-statsd" target="_blank" rel="external">官网</a></li></ul></li></ul><h3 id="Science-and-Data-Analysis"><a href="#Science-and-Data-Analysis" class="headerlink" title="Science and Data Analysis"></a>Science and Data Analysis</h3><p>用来进行科学计算和数据分析的库。</p><ul><li>astropy：一个天文学 Python 库。<a href="http://www.astropy.org/" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/bcbio-nextgen/" target="_blank" rel="external">bcbio-nextgen</a>：这个工具箱为全自动高通量测序分析提供符合最佳实践的处理流程。<a href="https://github.com/chapmanb/bcbio-nextgen" target="_blank" rel="external">官网</a></li><li>bccb：生物分析相关代码集合<a href="https://github.com/chapmanb/bcbb" target="_blank" rel="external">官网</a></li><li>Biopython：Biopython 是一组可以免费使用的用来进行生物计算的工具。<a href="http://biopython.org/wiki/MainPage" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/blaze/" target="_blank" rel="external">blaze</a>：NumPy 和 Pandas 的大数据接口。<a href="http://blaze.readthedocs.org/en/latest/index.html" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/cclib/" target="_blank" rel="external">cclib</a>：一个用来解析和解释计算化学软件包输出结果的库。<a href="http://cclib.github.io/" target="_blank" rel="external">官网</a></li><li>NetworkX：一个为复杂网络设计的高性能软件。<a href="https://networkx.github.io/" target="_blank" rel="external">官网</a></li><li>Neupy：执行和测试各种不同的人工神经网络算法。<a href="http://neupy.com/pages/home.html" target="_blank" rel="external">官网</a></li><li>Numba：Python JIT (just in time) 编译器，针对科学用的 Python ，由Cython 和 NumPy 的开发者开发。<a href="http://numba.pydata.org/" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/numpy/" target="_blank" rel="external">NumPy</a>：使用 Python 进行科学计算的基础包。<a href="http://www.numpy.org/" target="_blank" rel="external">官网</a></li><li>Open Babel：一个化学工具箱，用来描述多种化学数据。<a href="http://openbabel.org/wiki/MainPage" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/open-mining/" target="_blank" rel="external">Open Mining</a>：使用 Python 挖掘商业情报 (BI) (Pandas web 接口)。<a href="https://github.com/mining/mining" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/orange/" target="_blank" rel="external">orange</a>：通过可视化编程或 Python 脚本进行数据挖掘，数据可视化，分析和机器学习。<a href="http://orange.biolab.si/" target="_blank" rel="external">官网</a></li><li>Pandas：提供高性能，易用的数据结构和数据分析工具。<a href="http://pandas.pydata.org/" target="_blank" rel="external">官网</a></li><li>PyDy：PyDy 是 Python Dynamics 的缩写，用来为动力学运动建模工作流程提供帮助， 基于 NumPy, SciPy, IPython 和 matplotlib。<a href="http://www.pydy.org/" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/pymc/" target="_blank" rel="external">PyMC</a>：马尔科夫链蒙特卡洛采样工具。<a href="https://github.com/pymc-devs/pymc3" target="_blank" rel="external">官网</a></li><li>RDKit：化学信息学和机器学习软件。<a href="http://www.rdkit.org/" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/scipy/" target="_blank" rel="external">SciPy</a>：由一些基于 Python ，用于数学，科学和工程的开源软件构成的生态系统。<a href="http://www.scipy.org/" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/statsmodels/" target="_blank" rel="external">statsmodels</a>：统计建模和计量经济学。<a href="https://github.com/statsmodels/statsmodels" target="_blank" rel="external">官网</a></li><li>SymPy：一个用于符号数学的 Python 库。<a href="https://github.com/sympy/sympy" target="_blank" rel="external">官网</a></li><li>zipline：一个 Python 算法交易库。<a href="https://github.com/quantopian/zipline" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/bayesian-belief-networks/" target="_blank" rel="external">Bayesian-belief-networks</a>：优雅的贝叶斯信念网络框架。<a href="https://github.com/eBay/bayesian-belief-networks" target="_blank" rel="external">官网</a></li><li>keras: 以tensorflow或者theano为后端的深度学习封装库，快速上手神经网络<a href="https://keras.io/" target="_blank" rel="external">官网</a></li></ul><h3 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h3><p>进行数据可视化的库。 参见: <a href="https://github.com/sorrycc/awesome-javascript#data-visualization" target="_blank" rel="external">awesome-javascript</a>。</p><ul><li>matplotlib：一个 Python 2D 绘图库。<a href="http://matplotlib.org/" target="_blank" rel="external">官网</a></li><li>bokeh：用 Python 进行交互式 web 绘图。<a href="https://github.com/bokeh/bokeh" target="_blank" rel="external">官网</a></li><li>ggplot：ggplot2 给 R 提供的 API 的 Python 版本。<a href="https://github.com/yhat/ggplot" target="_blank" rel="external">官网</a></li><li>plotly：协同 Python 和 matplotlib 工作的 web 绘图库。<a href="https://plot.ly/python/" target="_blank" rel="external">官网</a></li><li>pygal：一个 Python SVG 图表创建工具。<a href="http://www.pygal.org/en/latest/" target="_blank" rel="external">官网</a></li><li>pygraphviz：Graphviz 的 Python 接口。<a href="https://pypi.python.org/pypi/pygraphviz" target="_blank" rel="external">官网</a></li><li>PyQtGraph：交互式实时2D/3D/图像绘制及科学/工程学组件。<a href="http://www.pyqtgraph.org/" target="_blank" rel="external">官网</a></li><li>SnakeViz：一个基于浏览器的 Python’s cProfile 模块输出结果查看工具。<a href="http://jiffyclub.github.io/snakeviz/" target="_blank" rel="external">官网</a></li><li>vincent：把 Python 转换为 Vega 语法的转换工具。<a href="https://github.com/wrobstory/vincent" target="_blank" rel="external">官网</a></li><li>VisPy：基于 OpenGL 的高性能科学可视化工具。<a href="http://vispy.org/" target="_blank" rel="external">官网</a></li></ul><h3 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h3><p>计算机视觉库。</p><ul><li>OpenCV：开源计算机视觉库。<a href="http://opencv.org/" target="_blank" rel="external">官网</a></li><li>pyocr：Tesseract和Cuneiform的包装库。<a href="https://github.com/jflesch/pyocr" target="_blank" rel="external">官网</a></li><li>pytesseract：<a href="https://github.com/tesseract-ocr" target="_blank" rel="external">Google Tesseract OCR</a>的另一包装库。<a href="https://github.com/madmaze/pytesseract" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/simplecv/" target="_blank" rel="external">SimpleCV</a>：一个用来创建计算机视觉应用的开源框架。<a href="http://simplecv.org/" target="_blank" rel="external">官网</a></li></ul><h3 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h3><p>机器学习库。 参见: <a href="https://github.com/josephmisiti/awesome-machine-learning#python" target="_blank" rel="external">awesome-machine-learning</a>.</p><ul><li>Crab：灵活、快速的推荐引擎。<a href="https://github.com/muricoca/crab" target="_blank" rel="external">官网</a></li><li>gensim：人性化的话题建模库。<a href="https://github.com/piskvorky/gensim" target="_blank" rel="external">官网</a></li><li>hebel：GPU 加速的深度学习库。<a href="https://github.com/hannes-brt/hebel" target="_blank" rel="external">官网</a></li><li>NuPIC：智能计算 Numenta 平台。<a href="https://github.com/numenta/nupic" target="_blank" rel="external">官网</a></li><li>pattern：Python 网络挖掘模块。<a href="https://github.com/clips/pattern" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/pybrain/" target="_blank" rel="external">PyBrain</a>：另一个 Python 机器学习库。<a href="https://github.com/pybrain/pybrain" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/pylearn2/" target="_blank" rel="external">Pylearn2</a>：一个基于 <a href="https://github.com/Theano/Theano" target="_blank" rel="external">Theano</a> 的机器学习库。<a href="https://github.com/lisa-lab/pylearn2" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/python-recsys/" target="_blank" rel="external">python-recsys</a>：一个用来实现推荐系统的 Python 库。<a href="https://github.com/ocelma/python-recsys" target="_blank" rel="external">官网</a></li><li>scikit-learn：基于 SciPy 构建的机器学习 Python 模块。<a href="http://scikit-learn.org/" target="_blank" rel="external">官网</a></li><li>pydeep：Python 深度学习库。<a href="https://github.com/andersbll/deeppy" target="_blank" rel="external">官网</a></li><li>vowpalporpoise：轻量级 <a href="https://github.com/JohnLangford/vowpalwabbit/" target="_blank" rel="external">Vowpal Wabbit</a> 的 Python 封装。<a href="https://github.com/josephreisinger/vowpalporpoise" target="_blank" rel="external">官网</a></li><li>skflow：一个 <a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="external">TensorFlow</a> 的简化接口(模仿 scikit-learn)。<a href="https://github.com/tensorflow/skflow" target="_blank" rel="external">官网</a></li><li>Caffe: 一个<a href="https://github.com/BVLC/caffe" target="_blank" rel="external">Caffe</a>的python接口。<a href="http://caffe.berkeleyvision.org" target="_blank" rel="external">官网</a><h3 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h3></li></ul><p>MapReduce 框架和库。</p><ul><li><a href="http://hao.jobbole.com/dpark/" target="_blank" rel="external">dpark</a>：Spark 的 Python 克隆版，一个类似 MapReduce 的框架。<a href="https://github.com/douban/dpark" target="_blank" rel="external">官网</a></li><li>dumbo：这个 Python 模块可以让人轻松的编写和运行 Hadoop 程序。<a href="https://github.com/klbostee/dumbo" target="_blank" rel="external">官网</a></li><li>luigi：这个模块帮你构建批处理作业的复杂流水线。<a href="https://github.com/spotify/luigi" target="_blank" rel="external">官网</a></li><li>mrjob：在 Hadoop 或 Amazon Web Services 上运行 MapReduce 任务。<a href="https://github.com/Yelp/mrjob" target="_blank" rel="external">官网</a></li><li>PySpark：Spark 的 Python API 。<a href="http://spark.apache.org/docs/latest/programming-guide.html" target="_blank" rel="external">官网</a></li><li>streamparse：运行针对事实数据流的 Python 代码。集成了<a href="http://storm.apache.org/" target="_blank" rel="external">Apache Storm</a>。<a href="https://github.com/Parsely/streamparse" target="_blank" rel="external">官网</a></li></ul><h3 id="函数式编程"><a href="#函数式编程" class="headerlink" title="函数式编程"></a>函数式编程</h3><p>使用 Python 进行函数式编程。</p><ul><li>CyToolz：Toolz 的 Cython 实现 : 高性能函数式工具。<a href="https://github.com/pytoolz/cytoolz/" target="_blank" rel="external">官网</a></li><li>fn.py：在 Python 中进行函数式编程 : 实现了一些享受函数式编程缺失的功能。<a href="https://github.com/kachayev/fn.py" target="_blank" rel="external">官网</a></li><li>funcy：炫酷又实用的函数式工具。<a href="https://github.com/Suor/funcy" target="_blank" rel="external">官网</a></li><li>Toolz：一组用于迭代器，函数和字典的函数式编程工具。<a href="https://github.com/pytoolz/toolz" target="_blank" rel="external">官网</a></li></ul><h3 id="第三方-API"><a href="#第三方-API" class="headerlink" title="第三方 API"></a>第三方 API</h3><p>用来访问第三方 API的库。 参见： <a href="https://github.com/realpython/list-of-python-api-wrappers" target="_blank" rel="external">List of Python API Wrappers and Libraries</a>。</p><ul><li>apache-libcloud：一个为各种云设计的 Python 库。<a href="https://libcloud.apache.org/" target="_blank" rel="external">官网</a></li><li>boto：Amazon Web Services 的 Python 接口。<a href="https://github.com/boto/boto" target="_blank" rel="external">官网</a></li><li>django-wordpress：WordPress models and views for Django.<a href="https://github.com/sunlightlabs/django-wordpress/" target="_blank" rel="external">官网</a></li><li>facebook-sdk：Facebook 平台的 Python SDK.<a href="https://github.com/mobolic/facebook-sdk" target="_blank" rel="external">官网</a></li><li>facepy：Facepy 让和 Facebook’s Graph API 的交互变得更容易。<a href="https://github.com/jgorset/facepy" target="_blank" rel="external">官网</a></li><li>gmail：Gmail 的 Python 接口。<a href="https://github.com/charlierguo/gmail" target="_blank" rel="external">官网</a></li><li>google-api-python-client：Python 用的 Google APIs 客户端库。<a href="https://github.com/google/google-api-python-client" target="_blank" rel="external">官网</a></li><li>gspread：Google 电子表格的 Python API.<a href="https://github.com/burnash/gspread" target="_blank" rel="external">官网</a></li><li>twython：Twitter API 的封装。<a href="https://github.com/ryanmcgrath/twython" target="_blank" rel="external">官网</a></li></ul><h3 id="DevOps-工具"><a href="#DevOps-工具" class="headerlink" title="DevOps 工具"></a>DevOps 工具</h3><p>用于 DevOps 的软件和库。</p><ul><li>Ansible：一个非常简单的 IT 自动化平台。<a href="https://github.com/ansible/ansible" target="_blank" rel="external">官网</a></li><li>SaltStack：基础设施自动化和管理系统。<a href="https://github.com/saltstack/salt" target="_blank" rel="external">官网</a></li><li>OpenStack：用于构建私有和公有云的开源软件。<a href="http://www.openstack.org/" target="_blank" rel="external">官网</a></li><li>Docker Compose：快速，分离的开发环境，使用 Docker。<a href="https://docs.docker.com/compose/" target="_blank" rel="external">官网</a></li><li>Fabric：一个简单的，Python 风格的工具，用来进行远程执行和部署。<a href="http://www.fabfile.org/" target="_blank" rel="external">官网</a></li><li>cuisine：为 Fabric 提供一系列高级函数。<a href="https://github.com/sebastien/cuisine" target="_blank" rel="external">官网</a></li><li>Fabtools：一个用来编写超赞的 Fabric 文件的工具。<a href="https://github.com/ronnix/fabtools" target="_blank" rel="external">官网</a></li><li>gitapi：Git 的纯 Python API。<a href="https://bitbucket.org/haard/gitapi" target="_blank" rel="external">官网</a></li><li>hgapi：Mercurial 的纯 Python API。<a href="https://bitbucket.org/haard/hgapi" target="_blank" rel="external">官网</a></li><li>honcho：<a href="https://github.com/ddollar/foreman" target="_blank" rel="external">Foreman</a>的 Python 克隆版，用来管理基于<a href="https://devcenter.heroku.com/articles/procfile" target="_blank" rel="external">Procfile</a>的应用。<a href="https://github.com/nickstenning/honcho" target="_blank" rel="external">官网</a></li><li>pexpect：Controlling interactive programs in a pseudo-terminal like 在一个伪终端中控制交互程序，就像 GNU expect 一样。<a href="https://github.com/pexpect/pexpect" target="_blank" rel="external">官网</a></li><li>psutil：一个跨平台进程和系统工具模块。<a href="https://github.com/giampaolo/psutil" target="_blank" rel="external">官网</a></li><li>supervisor：UNIX 的进程控制系统。<a href="https://github.com/Supervisor/supervisor" target="_blank" rel="external">官网</a></li></ul><h3 id="任务调度"><a href="#任务调度" class="headerlink" title="任务调度"></a>任务调度</h3><p>任务调度库。</p><ul><li>APScheduler：轻巧但强大的进程内任务调度，使你可以调度函数。<a href="http://apscheduler.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>django-schedule：一个 Django 排程应用。<a href="https://github.com/thauber/django-schedule" target="_blank" rel="external">官网</a></li><li>doit：一个任务执行和构建工具。<a href="http://pydoit.org/" target="_blank" rel="external">官网</a></li><li>gunnery：分布式系统使用的多用途任务执行工具 ，具有 web 交互界面。<a href="https://github.com/gunnery/gunnery" target="_blank" rel="external">官网</a></li><li>Joblib：一组为 Python 提供轻量级作业流水线的工具。<a href="http://pythonhosted.org/joblib/index.html" target="_blank" rel="external">官网</a></li><li>Plan：如有神助地编写 crontab 文件。<a href="https://github.com/fengsp/plan" target="_blank" rel="external">官网</a></li><li>schedule：人性化的 Python 任务调度库。<a href="https://github.com/dbader/schedule" target="_blank" rel="external">官网</a></li><li>Spiff：使用纯 Python 实现的强大的工作流引擎。<a href="https://github.com/knipknap/SpiffWorkflow" target="_blank" rel="external">官网</a></li><li>TaskFlow：一个可以让你方便执行任务的 Python 库，一致并且可靠。<a href="http://docs.openstack.org/developer/taskflow/" target="_blank" rel="external">官网</a></li></ul><h3 id="外来函数接口"><a href="#外来函数接口" class="headerlink" title="外来函数接口"></a>外来函数接口</h3><p>使用外来函数接口的库。</p><ul><li>cffi：用来调用 C 代码的外来函数接口。<a href="https://pypi.python.org/pypi/cffi" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/ctypes/" target="_blank" rel="external">ctypes</a>：(Python 标准库) 用来调用 C 代码的外来函数接口。<a href="https://docs.python.org/2/library/ctypes.html" target="_blank" rel="external">官网</a></li><li>PyCUDA：Nvidia CUDA API 的封装。<a href="https://mathema.tician.de/software/pycuda/" target="_blank" rel="external">官网</a></li><li>SWIG：简化的封装和接口生成器。<a href="http://www.swig.org/Doc1.3/Python.html" target="_blank" rel="external">官网</a></li></ul><h3 id="高性能"><a href="#高性能" class="headerlink" title="高性能"></a>高性能</h3><p>让 Python 更快的库。</p><ul><li>Cython：优化的 Python 静态编译器。使用类型混合使 Python 编译成 C 或 C++ 模块来获得性能的极大提升。<a href="http://cython.org/" target="_blank" rel="external">官网</a></li><li>PeachPy：嵌入 Python 的 x86-64 汇编器。可以被用作 Python 内联的汇编器或者是独立的汇编器，用于 Windows, Linux, OS X, Native Client 或者 Go 。<a href="https://github.com/Maratyszcza/PeachPy" target="_blank" rel="external">官网</a></li><li>PyPy：使用 Python 实现的 Python。解释器使用黑魔法加快 Python 运行速度且不需要加入额外的类型信息。<a href="http://pypy.org/" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/pyston-llvm-jit/" target="_blank" rel="external">Pyston</a>：使用 LLVM 和现代 JIT 技术构建的 Python 实现，目标是为了获得很好的性能。<a href="https://github.com/dropbox/pyston" target="_blank" rel="external">官网</a></li><li>Stackless Python：一个强化版的 Python。<a href="https://bitbucket.org/stackless-dev/stackless/overview" target="_blank" rel="external">官网</a></li></ul><h3 id="微软的-Windows平台"><a href="#微软的-Windows平台" class="headerlink" title="微软的 Windows平台"></a>微软的 Windows平台</h3><p>在 Windows 平台上进行 Python 编程。</p><ul><li>Python(x,y)：面向科学应用的 Python 发行版，基于 Qt 和 Spyder。<a href="http://python-xy.github.io/" target="_blank" rel="external">官网</a></li><li>pythonlibs：非官方的 Windows 平台 Python 扩展二进制包。<a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/" target="_blank" rel="external">官网</a></li><li>PythonNet：Python 与 .NET 公共语言运行库 (CLR)的集成。<a href="https://github.com/pythonnet/pythonnet" target="_blank" rel="external">官网</a></li><li>PyWin32：针对 Windows 的Python 扩展。<a href="https://sourceforge.net/projects/pywin32/" target="_blank" rel="external">官网</a></li><li>WinPython：Windows 7/8 系统下便携式开发环境。<a href="https://winpython.github.io/" target="_blank" rel="external">官网</a></li></ul><h3 id="网络可视化和SDN"><a href="#网络可视化和SDN" class="headerlink" title="网络可视化和SDN"></a>网络可视化和SDN</h3><p>用来进行网络可视化和SDN(软件定义网络)的工具和库。</p><ul><li>Mininet：一款流行的网络模拟器以及用 Python 编写的 API。<a href="http://mininet.org/" target="_blank" rel="external">官网</a></li><li>POX：一个针对基于 Python 的软件定义网络应用（例如 OpenFlow SDN 控制器）的开源开发平台。<a href="https://github.com/noxrepo/pox" target="_blank" rel="external">官网</a></li><li>Pyretic：火热的 SDN 编程语言中的一员，为网络交换机和模拟器提供强大的抽象能力。<a href="http://frenetic-lang.org/pyretic/" target="_blank" rel="external">官网</a></li><li>SDX Platform：基于 SDN 的 IXP 实现，影响了 Mininet, POX 和 Pyretic。<a href="https://github.com/sdn-ixp/internet2award" target="_blank" rel="external">官网</a></li></ul><h3 id="硬件"><a href="#硬件" class="headerlink" title="硬件"></a>硬件</h3><p>用来对硬件进行编程的库。</p><ul><li>ino：操作<a href="https://www.arduino.cc/" target="_blank" rel="external">Arduino</a>的命令行工具。<a href="http://inotool.org/" target="_blank" rel="external">官网</a> </li><li>Pyro：Python 机器人编程库。<a href="http://pyrorobotics.com/" target="_blank" rel="external">官网</a></li><li>PyUserInput：跨平台的，控制鼠标和键盘的模块。<a href="https://github.com/SavinaRoja/PyUserInput" target="_blank" rel="external">官网</a></li><li>scapy：一个非常棒的操作数据包的库。<a href="https://github.com/secdev/scapy" target="_blank" rel="external">官网</a></li><li>wifi：一个 Python 库和命令行工具用来在 Linux 平台上操作WiFi。<a href="https://wifi.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li><li>Pingo：Pingo 为类似Raspberry Pi，pcDuino， Intel Galileo等设备提供统一的API用以编程。<a href="http://www.pingo.io/" target="_blank" rel="external">官网</a></li></ul><h3 id="兼容性"><a href="#兼容性" class="headerlink" title="兼容性"></a>兼容性</h3><p>帮助从 Python 2 向 Python 3迁移的库。</p><ul><li>Python-Future：这就是 Python 2 和 Python 3 之间丢失的那个兼容性层。<a href="http://python-future.org/index.html" target="_blank" rel="external">官网</a></li><li>Python-Modernize：使 Python 代码更加现代化以便最终迁移到 Python 3。<a href="https://github.com/mitsuhiko/python-modernize" target="_blank" rel="external">官网</a></li><li>Six：Python 2 和 3 的兼容性工具。<a href="https://pypi.python.org/pypi/six" target="_blank" rel="external">官网</a></li></ul><h3 id="杂项"><a href="#杂项" class="headerlink" title="杂项"></a>杂项</h3><p>不属于上面任何一个类别，但是非常有用的库。</p><ul><li>blinker：一个快速的 Python 进程内信号/事件分发系统。<a href="https://github.com/jek/blinker" target="_blank" rel="external">官网</a></li><li>itsdangerous：一系列辅助工具用来将可信的数据传入不可信的环境。<a href="https://github.com/pallets/itsdangerous" target="_blank" rel="external">官网</a></li><li>pluginbase：一个简单但是非常灵活的 Python 插件系统。<a href="https://github.com/mitsuhiko/pluginbase" target="_blank" rel="external">官网</a></li><li>Pychievements：一个用来创建和追踪成就的 Python 框架。<a href="https://github.com/PacketPerception/pychievements" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/tryton/" target="_blank" rel="external">Tryton</a>：一个通用商务框架。<a href="http://www.tryton.org/" target="_blank" rel="external">官网</a></li></ul><h3 id="算法和设计模式"><a href="#算法和设计模式" class="headerlink" title="算法和设计模式"></a>算法和设计模式</h3><p>Python 实现的算法和设计模式。</p><ul><li><a href="http://hao.jobbole.com/algorithms/" target="_blank" rel="external">algorithms</a>：一个 Python 算法模块。<a href="https://github.com/nryoung/algorithms" target="_blank" rel="external">官网</a> </li><li>python-patterns：Python 设计模式的集合。<a href="https://github.com/faif/python-patterns" target="_blank" rel="external">官网</a></li><li>sortedcontainers：快速，纯 Python 实现的SortedList，SortedDict 和 SortedSet 类型。<a href="http://www.grantjenks.com/docs/sortedcontainers/" target="_blank" rel="external">官网</a></li></ul><h3 id="编辑器插件"><a href="#编辑器插件" class="headerlink" title="编辑器插件"></a>编辑器插件</h3><p>编辑器和 IDE 的插件</p><ul><li>Emacs<ul><li>Elpy：Emacs Python 开发环境。<a href="https://github.com/jorgenschaefer/elpy" target="_blank" rel="external">官网</a></li></ul></li><li>Sublime Text<ul><li>SublimeJEDI：一个 Sublime Text 插件，用来使用超赞的自动补全库 Jedi。<a href="https://github.com/srusskih/SublimeJEDI" target="_blank" rel="external">官网</a></li><li>Anaconda：Anaconda 把你的 Sublime Text 3 变成一个功能齐全的 Python IDE。<a href="https://github.com/DamnWidget/anaconda" target="_blank" rel="external">官网</a></li></ul></li><li>Vim<ul><li><a href="http://hao.jobbole.com/youcompleteme/" target="_blank" rel="external">YouCompleteMe</a>：引入基于 <a href="https://github.com/davidhalter/jedi" target="_blank" rel="external">Jedi</a> 的 Python 自动补全引擎。<a href="https://github.com/Valloric/YouCompleteMe" target="_blank" rel="external">官网</a></li><li>Jedi-vim：绑定 Vim 和 Jedi 自动补全库对 Python 进行自动补全。<a href="https://github.com/davidhalter/jedi-vim" target="_blank" rel="external">官网</a></li><li>Python-mode：将 Vim 变成 Python IDE 的一款多合一插件。<a href="https://github.com/klen/python-mode" target="_blank" rel="external">官网</a></li></ul></li><li>Visual Studio<ul><li>PTVS：Visual Studio 的 Python 工具<a href="https://github.com/Microsoft/PTVS" target="_blank" rel="external">官网</a></li></ul></li></ul><h3 id="集成开发环境"><a href="#集成开发环境" class="headerlink" title="集成开发环境"></a>集成开发环境</h3><p>流行的 Python 集成开发环境。</p><ul><li>PyCharm：商业化的 Python IDE ，由 JetBrains 开发。也有免费的社区版提供。<a href="https://www.jetbrains.com/pycharm/" target="_blank" rel="external">官网</a></li><li>LiClipse：基于 Eclipse 的免费多语言 IDE 。使用 PyDev 来支持 Python 。<a href="http://www.liclipse.com/" target="_blank" rel="external">官网</a></li><li>Spyder：开源 Python IDE。<a href="https://github.com/spyder-ide/spyder" target="_blank" rel="external">官网</a></li></ul><h3 id="自动聊天工具"><a href="#自动聊天工具" class="headerlink" title="自动聊天工具"></a>自动聊天工具</h3><p>用于开发聊天机器人的库</p><ul><li>Errbot：最简单和最流行的聊天机器人用来实现自动聊天工具。<a href="http://errbot.io/en/latest/" target="_blank" rel="external">官网</a></li></ul><h2 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h2><p>在线工具和简化开发的 API 。</p><h3 id="持续集成"><a href="#持续集成" class="headerlink" title="持续集成"></a>持续集成</h3><p>参见: <a href="https://github.com/ciandcd/awesome-ciandcd#online-build-system" target="_blank" rel="external">awesome-CIandCD</a>.</p><ul><li>Travis CI：一个流行的工具，为你的开源和<a href="https://travis-ci.com/" target="_blank" rel="external">私人</a>项目提供持续集成服务。(仅支持 GitHub)<a href="https://travis-ci.org/" target="_blank" rel="external">官网</a></li><li>CircleCI：一个持续集成工具，可以非常快速的进行并行测试。 (仅支持 GitHub)<a href="https://circleci.com/" target="_blank" rel="external">官网</a></li><li>Vexor CI：一个为私人 app 提供持续集成的工具，支持按分钟付费。<a href="https://vexor.io/" target="_blank" rel="external">官网</a></li><li>Wercker：基于 Docker 平台，用来构建和部署微服务。<a href="http://wercker.com/" target="_blank" rel="external">官网</a></li></ul><h3 id="代码质量"><a href="#代码质量" class="headerlink" title="代码质量"></a>代码质量</h3><ul><li>Codacy：自动化代码审查，更加快速的发布高质量代码。对于开源项目是免费的。<a href="https://www.codacy.com/" target="_blank" rel="external">官网</a></li><li>QuantifiedCode：一个数据驱动、自动、持续的代码审查工具。<a href="https://www.quantifiedcode.com/" target="_blank" rel="external">官网</a></li></ul><h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>在这里可以找到新的 Python 库。</p><h3 id="网站"><a href="#网站" class="headerlink" title="网站"></a>网站</h3><ul><li><a href="https://www.reddit.com/r/python" target="_blank" rel="external">r/Python</a></li><li><a href="https://www.coolgithubprojects.com/" target="_blank" rel="external">CoolGithubProjects</a></li><li><a href="https://www.djangopackages.com/" target="_blank" rel="external">Django Packages</a></li><li><a href="http://www.fullstackpython.com/" target="_blank" rel="external">Full Stack Python</a></li><li><a href="http://python3wos.appspot.com/" target="_blank" rel="external">Python 3 Wall of Superpowers</a></li><li><a href="http://pythonhackers.com/open-source/" target="_blank" rel="external">Python Hackers</a></li><li><a href="https://python.zeef.com/alan.richmond" target="_blank" rel="external">Python ZEEF</a></li><li><a href="https://github.com/trending?l=python" target="_blank" rel="external">Trending Python repositories on GitHub today</a></li><li><a href="http://pypi-ranking.info/alltime" target="_blank" rel="external">PyPI Ranking</a></li></ul><h3 id="周刊"><a href="#周刊" class="headerlink" title="周刊"></a>周刊</h3><ul><li><a href="http://importpython.com/newsletter/" target="_blank" rel="external">Import Python Newsletter</a></li><li><a href="http://pycoders.com/" target="_blank" rel="external">Pycoder’s Weekly</a></li><li><a href="http://www.pythonweekly.com/" target="_blank" rel="external">Python Weekly</a></li></ul><h3 id="Twitter"><a href="#Twitter" class="headerlink" title="Twitter"></a>Twitter</h3><ul><li><a href="https://twitter.com/codetengu" target="_blank" rel="external">@codetengu</a></li><li><a href="https://twitter.com/getpy" target="_blank" rel="external">@getpy</a></li><li><a href="https://twitter.com/planetpython" target="_blank" rel="external">@planetpython</a></li><li><a href="https://twitter.com/pycoders" target="_blank" rel="external">@pycoders</a></li><li><a href="https://twitter.com/pypi" target="_blank" rel="external">@pypi</a></li><li><a href="https://twitter.com/pythontrending" target="_blank" rel="external">@pythontrending</a></li><li><a href="https://twitter.com/PythonWeekly" target="_blank" rel="external">@PythonWeekly</a></li></ul><h3 id="学习指南"><a href="#学习指南" class="headerlink" title="学习指南"></a>学习指南</h3><ul><li><a href="http://hao.jobbole.com/scipy-lecture-notes/" target="_blank" rel="external">Scipy-lecture-notes</a>：如何用Python来做学术？<a href="https://github.com/scipy-lectures/scipy-lecture-notes" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/scientific-python-lectures/" target="_blank" rel="external">SScientific-python-lectures</a>：Python科学计算的资料。<a href="https://github.com/jrjohansson/scientific-python-lectures" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/mario-level-1/" target="_blank" rel="external">Mario-Level-1</a>：用Python和Pygame写的超级马里奥第一关。<a href="https://github.com/justinmeister/Mario-Level-1" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/python-koans/" target="_blank" rel="external">Python Koans</a>：Python的交互式学习工具。<a href="https://github.com/gregmalcolm/python_koans" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/minecraft-python/" target="_blank" rel="external">Minecraft</a>：用python写的Minecraft游戏。<a href="https://github.com/fogleman/Minecraft" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/python-pycrumbs/" target="_blank" rel="external">pycrumbs</a>：Python资源大全。<a href="https://github.com/kirang89/pycrumbs/blob/master/pycrumbs.md" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/python-patterns/" target="_blank" rel="external">python-patterns</a>：使用python实现设计模式。<a href="https://github.com/faif/python-patterns" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/python-projects/" target="_blank" rel="external">Projects</a>：Python项目大集合。<a href="https://github.com/karan/Projects" target="_blank" rel="external">官网</a></li><li><a href="http://hao.jobbole.com/the-hitchhikers-guide-to-python/" target="_blank" rel="external">The Hitchhiker’s Guide to Python</a>：旅行者的Python学习指南。<a href="http://docs.python-guide.org/en/latest/" target="_blank" rel="external">官网</a></li><li><a href="http://top.jobbole.com/18767/" target="_blank" rel="external">Code Like a Pythonista: Idiomatic Python</a>：如何像Python高手(Pythonista)一样编程。<a href="http://python.net/~goodger/projects/pycon/2007/idiomatic/handout.html" target="_blank" rel="external">官网</a></li></ul><p></p><h3 id="websites">知名网站</h3><br><em>值得关注的 Python 技术站点。</em><p></p><h4>中文站点</h4><ul><li>伯乐在线 Python 频道：分享 Python 开发技术、相关的行业动态。<a href="http://python.jobbole.com/" target="_blank" rel="external">官网</a></li></ul><h4>英文站点</h4><ul><li>《<a href="http://python.jobbole.com/81730/" target="_blank" rel="external">值得关注的 10 个 Python 英文博客</a>》</li></ul><p></p><h3 id="weibo-weixin">微博、微信公众号</h3><p></p><ul><li>Python开发者 微博：<a href="http://weibo.com/u/5305630013" target="_blank" rel="external">@Python开发者</a></li><li>Python开发者：人生苦短，我用 Python。Python 越来越受广大程序员的喜爱。「Python开发者」是最受欢迎的、专注分享Python技术的微信公众号，主要分享 Python 相关的技术文章、工具资源和资讯等。<br><br><img src="http://ww3.sinaimg.cn/small/63918611gw1epb2cbm6cmj2046046wek.jpg" width="150" height="150"></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;参考链接点&lt;a href=&quot;https://github.com/jobbole/awesome-python-cn&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这里&lt;/a&gt;，转载只为方便学习!&lt;/p&gt;
    
    </summary>
    
      <category term="Tech" scheme="http://songit.cn/categories/Tech/"/>
    
    
      <category term="Python" scheme="http://songit.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>html入门知识点</title>
    <link href="http://songit.cn/the-ABC-of-html/"/>
    <id>http://songit.cn/the-ABC-of-html/</id>
    <published>2017-07-13T09:02:31.000Z</published>
    <updated>2017-07-13T14:01:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近简单学习了一下html，看到这么一篇文章<a href="http://www.cnblogs.com/biehongli/p/5772432.html" target="_blank" rel="external">《HTML入门的简单学习》</a>，总结下来，方便以后查阅。<br><a id="more"></a></p><h1 id="HTML简介"><a href="#HTML简介" class="headerlink" title="HTML简介"></a>HTML简介</h1><p>1.1 HTML(Haper Text Markup language):超文本标记语言<br>超文本就是指页面内可以包含图片，链接，甚至音乐，程序等非文字元素。</p><p>1.2 开发工具：Adobe Dreamwearver cs5</p><p>1.3 HTML的基本结构<br>1.3.1：HTML文档标记：<html><br>1.3.2：HTML文档头标记：<head><br>1.3.3：标记内容可以存放：title,meta,style,link等<br>1.3.4：HTML文件标题标记：<title><br>1.3.5：页面的元信息：<meta><br>1.3.5.1:显示字符集的设定<meta http-equiv="content-Type" content="text/html charset=utf-8"><br>1.3.5.2:刷新<meta http-equiv="Refresh" content="5;url=http://www.baidu.com"><br>1.3.5.3:向搜索引擎提供查询关键字:<meta name="Keywords" content="vacation.greece"></title></head></html></p><p>1.2.6：HTML文档主题标记：<body></body></p><p>1.4：HTML文档保存格式<br>   包含两种，分别是html,htm;<br>1.5：HTML语法不区分大小写，建议尽量使用小写<br>   使用小写，阅读性比较高。<br>1.6：文档注释<!--注释内容--></p><h1 id="HTML字体实体"><a href="#HTML字体实体" class="headerlink" title="HTML字体实体"></a>HTML字体实体</h1><table><thead><tr><th>显示结果</th><th style="text-align:center">描述</th><th style="text-align:right">实体表述</th></tr></thead><tbody><tr><td></td><td style="text-align:center">空格</td><td style="text-align:right"><code>&amp;nbsp;</code></td></tr><tr><td>&lt;</td><td style="text-align:center">小于号</td><td style="text-align:right"><code>&amp;lt;</code></td></tr><tr><td>&gt;</td><td style="text-align:center">大于号</td><td style="text-align:right"><code>&amp;gt;</code></td></tr><tr><td>&amp;</td><td style="text-align:center">和号</td><td style="text-align:right"><code>&amp;amp;</code></td></tr><tr><td>“</td><td style="text-align:center">引号</td><td style="text-align:right"><code>&amp;quot;</code></td></tr><tr><td>‘</td><td style="text-align:center">撇号</td><td style="text-align:right"><code>&amp;qpos;</code></td></tr><tr><td>…</td><td style="text-align:center">…</td><td style="text-align:right">…</td></tr></tbody></table><h1 id="HTML常用文档设置标记"><a href="#HTML常用文档设置标记" class="headerlink" title="HTML常用文档设置标记"></a>HTML常用文档设置标记</h1><p>3.1. 格式标记<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">&lt;br/&gt;换行  &lt;p&gt;段落   &lt;center&gt;居中对齐</div><div class="line">&lt;pre&gt;预格式化标记   &lt;hr/&gt;水平线割线       </div><div class="line">&lt;div&gt;分区显示标记，也称为层标记，div+css进行网页标记</div><div class="line">列表标记：&lt;ul&gt;无序列表   &lt;ol&gt;有序列表   </div><div class="line">&lt;dl&gt;定义型列表，可以用来做软件说明</div></pre></td></tr></table></figure></p><p>3.2. 文本标记<br>   hn标题标记，h1最大，h6最小<br>   font字体设置标记<br>   b粗体<br>   i斜体<br>   em表示强调斜体<br>   strong表示强调显示粗体<br>   small小型字体<br>   u下划线<br>   del删除线</p><p><strong>案例的简单应用源码如下</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div></pre></td><td class="code"><pre><div class="line">&lt;html&gt;</div><div class="line">&lt;head&gt;</div><div class="line">&lt;meta http-equiv=&quot;Content-Type&quot; Content=&quot;text/html; charset=utf-8&quot; /&gt;</div><div class="line">    &lt;title&gt;html字符实体&lt;/title&gt;</div><div class="line">&lt;/head&gt;</div><div class="line">&lt;body bgcolor=&quot;green&quot;&gt;&lt;!--bgcolor设置背景颜色--&gt;</div><div class="line">&lt;center&gt;            </div><div class="line">&lt;p&gt;《春晓》&lt;/p&gt;&lt;hr width=80% color=&quot;red&quot; size=10/&gt;</div><div class="line">&lt;p&gt;春眠不觉晓，处处闻啼鸟。&lt;/p&gt;</div><div class="line"></div><div class="line">&lt;div&gt;夜来风雨声，花落知多少。&lt;/div&gt;</div><div class="line"></div><div class="line">&lt;pre&gt;</div><div class="line">《悯农》</div><div class="line">春种一粒粟，秋成万颗子。</div><div class="line">四海无闲田，农夫犹饿死。</div><div class="line">锄禾日当午，汗滴禾下土。</div><div class="line">谁知盘中餐，粒粒皆辛苦。</div><div class="line">&lt;/pre&gt;</div><div class="line">&lt;/center&gt;</div><div class="line">&lt;ul&gt;</div><div class="line">    &lt;li&gt;1:小米&lt;/li&gt;</div><div class="line">    &lt;li&gt;2:魅族&lt;/li&gt;</div><div class="line">    &lt;li&gt;3:华为&lt;/li&gt;</div><div class="line">    &lt;li&gt;4:vivo&lt;/li&gt;</div><div class="line">    &lt;li&gt;5:ppo&lt;/li&gt;</div><div class="line">&lt;/ul&gt;</div><div class="line">&lt;hr/&gt;</div><div class="line">&lt;ol type=&quot;A&quot;&gt;</div><div class="line">    &lt;li&gt;java&lt;/li&gt;</div><div class="line">    &lt;li&gt;c&lt;/li&gt;</div><div class="line">    &lt;li&gt;c++&lt;/li&gt;</div><div class="line">    &lt;li&gt;javascript&lt;/li&gt;</div><div class="line">&lt;/ol&gt;</div><div class="line">&lt;hr/&gt;</div><div class="line">&lt;ol type=&quot;a&quot;&gt;</div><div class="line">    &lt;li&gt;java&lt;/li&gt;</div><div class="line">    &lt;li&gt;c&lt;/li&gt;</div><div class="line">    &lt;li&gt;c++&lt;/li&gt;</div><div class="line">    &lt;li&gt;javascript&lt;/li&gt;</div><div class="line">&lt;/ol&gt;</div><div class="line">&lt;hr/&gt;</div><div class="line">&lt;ol type=&quot;i&quot;&gt;</div><div class="line">    &lt;li&gt;java&lt;/li&gt;</div><div class="line">    &lt;li&gt;c&lt;/li&gt;</div><div class="line">    &lt;li&gt;c++&lt;/li&gt;</div><div class="line">    &lt;li&gt;javascript&lt;/li&gt;</div><div class="line">&lt;/ol&gt;</div><div class="line">&lt;hr/&gt;</div><div class="line">&lt;dl&gt;</div><div class="line">    &lt;dt&gt;软件说明&lt;/dt&gt;</div><div class="line">    &lt;dd&gt;非常好用的软件&lt;/dd&gt;</div><div class="line">&lt;/dl&gt;</div><div class="line"></div><div class="line">&lt;h1&gt;《悯农》&lt;/h1&gt;</div><div class="line">&lt;h2&gt;《悯农》&lt;/h2&gt;</div><div class="line">&lt;h3&gt;《悯农》&lt;/h3&gt;</div><div class="line">&lt;h4&gt;《悯农》&lt;/h4&gt;</div><div class="line">&lt;h5&gt;《悯农》&lt;/h5&gt;</div><div class="line">&lt;h6&gt;《悯农》&lt;/h6&gt;</div><div class="line">&lt;pre&gt;</div><div class="line">&lt;b&gt;春种一粒粟，&lt;/b&gt;秋成万颗子。</div><div class="line">&lt;font face=&quot;楷体&quot; size=10&gt;四海无闲田，&lt;/font&gt;农夫犹饿死。</div><div class="line">&lt;u&gt;锄禾日当午，&lt;/u&gt;汗滴禾下土。</div><div class="line">&lt;del&gt;谁知盘中餐，&lt;/del&gt;&lt;i&gt;粒粒皆辛苦。&lt;/i&gt;</div><div class="line">&lt;/pre&gt;</div><div class="line">&lt;p&gt;&lt;small&gt;原价：&lt;/small&gt;&lt;del&gt;100元&lt;/del&gt;&lt;/p&gt;</div><div class="line">&lt;p&gt;现价：50元&lt;/p&gt;</div><div class="line">&lt;/body&gt;</div><div class="line">&lt;/html&gt;</div></pre></td></tr></table></figure></p><h1 id="图像标记"><a href="#图像标记" class="headerlink" title="图像标记"></a>图像标记</h1><p>知识分析：路径分为相对路径和绝对路径<br>   （1）相对路径，就是在同一个网站下，不同文件之间的的位置定位。引用的文件是相对当前网页的位置而言的，根据这个相对位置得出相对路径。<br>   （2）绝对路径，指的是完整的路径。<br><code>&lt;img&gt;</code>图像标记，格式支持jpg,png,gif,jpeg;<br>4.1. 使用方法，<code>&lt;img src=&quot;路径/文件名.图片格式&quot; width=&quot;属性值&quot; height=&quot;属性值&quot; border=&quot;属性值&quot; alt=&quot;属性值&quot;&gt;</code><br>4.2. <code>&lt;img&gt;</code>标记的属性<br>   src属性，作用指定我们要加载的图片的路径和图片的名称以及图片格式<br>   width属性，作用指定图片的宽度，单位px,em,cm,mm<br>   height属性，作用指图片的高度，单位px,em,cm,mm<br>   border属性，作用指定图标的边框宽度，单位px,em,cm,mm<br>   alt属性:<br>   作用1，当网页上的图片被加载完成后，鼠标移动到上面去，会显示这个图片指定的属性文字<br>   作用2，如果图像没有下载或者加载失败，会用文字来代替图像显示<br>   作用3，搜索引擎可以通过这个属性的文字来抓取图片</p><h1 id="超链接的使用"><a href="#超链接的使用" class="headerlink" title="超链接的使用"></a>超链接的使用</h1><p>5.1. 基本语法，<code>&lt;a href=&quot;&quot; target=&quot;打开方式&quot; name=&quot;页面锚点名称&quot;&gt;链接文字或者图片&lt;/a&gt;</code><br>5.2. 属性<br>   5.2.1. href属性<br>   链接的地址，链接的地址可以是一个网页，也可以是一个视频，图片，音乐等等<br>   5.2.2. name属性<br>   指定页面的锚点名称<br>   5.2.3. target属性，作用：定义超链接的打开方式<br>   _blank:在一个新的窗口中打开链接<br>   _self(默认值)：在当前窗口中打开链接<br>   _parent:在父窗口中打开页面，框架中使用较多<br>   _top:在顶层窗口中打开文件，框架中使用较多</p><p><strong>案例运行如下</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">&lt;html&gt;</div><div class="line">&lt;head&gt;</div><div class="line">&lt;meta http-equiv=&quot;Content-Type&quot; Content=&quot;text/html; charset=utf-8&quot; /&gt;</div><div class="line">    &lt;title&gt;html字符实体&lt;/title&gt;</div><div class="line">&lt;/head&gt;</div><div class="line">&lt;body bgcolor=&quot;green&quot;&gt;&lt;!--bgcolor设置背景颜色--&gt;</div><div class="line">    &lt;img src=&quot;2.jpg&quot; alt=&quot;美女&quot; title=&quot;美女&quot; width=150 height=200/&gt;</div><div class="line">    &lt;!--图像的学习关键在于路径的设置，如果在同一目录下，设置如上面一行代码所示--&gt;</div><div class="line">    &lt;img src=&quot;image/1.jpg&quot; alt=&quot;帅哥&quot; title=&quot;帅哥&quot; width=150 height=200/&gt;</div><div class="line">    &lt;!--图像的学习关键在于路径的设置，如果也是在同一目录下，设置如上面一行代码所示--&gt;</div><div class="line">    &lt;img src=&quot;../image/3.jpg&quot; alt=&quot;帅哥&quot; title=&quot;帅哥&quot; width=150 height=200/&gt;</div><div class="line">    &lt;!--图像的学习关键在于路径的设置，如果是在上一目录下，设置如上面一行代码所示--&gt;</div><div class="line">    &lt;a href=&quot;http://www.baidu.com&quot; target=&quot;_self&quot; name=&quot;不会就问百度&quot;&gt;百度&lt;/a&gt;</div><div class="line">    </div><div class="line">&lt;/body&gt;</div><div class="line">&lt;/html&gt;</div></pre></td></tr></table></figure></p><p><strong>小说文本案例代码如下</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">&lt;html&gt;</div><div class="line">&lt;head&gt;</div><div class="line">&lt;meta http-equiv=&quot;Content-Type&quot; Content=&quot;text/html; charset=utf-8&quot; /&gt;</div><div class="line">    &lt;title&gt;html字符实体&lt;/title&gt;</div><div class="line">&lt;/head&gt;</div><div class="line">&lt;body bgcolor=&quot;green&quot;&gt;&lt;!--bgcolor设置背景颜色--&gt;</div><div class="line">    &lt;a name=&quot;menu&quot;&gt;目录&lt;/a&gt;&lt;br/&gt;</div><div class="line">    &lt;a href=&quot;#text1&quot;&gt;第1章 大荒&lt;/a&gt;&lt;br/&gt;</div><div class="line">    &lt;a href=&quot;#text2&quot;&gt;第2章 祭祀&lt;/a&gt;&lt;br/&gt;</div><div class="line">    &lt;a href=&quot;#text3&quot;&gt;第3章 准备&lt;/a&gt;&lt;br/&gt;</div><div class="line">    &lt;a href=&quot;#text4&quot;&gt;第4章 返祖&lt;/a&gt;&lt;br/&gt;</div><div class="line">    </div><div class="line">    &lt;hr/&gt;</div><div class="line">        &lt;a name=&quot;text1&quot;&gt;&lt;/a&gt;</div><div class="line">        &lt;pre&gt;</div><div class="line">            小说文本1</div><div class="line">        &lt;/pre&gt;</div><div class="line">        </div><div class="line">        &lt;a name=&quot;text2&quot;&gt;&lt;/a&gt;</div><div class="line">        &lt;pre&gt;</div><div class="line">            小说文本1</div><div class="line">        &lt;/pre&gt;</div><div class="line">        </div><div class="line">        &lt;a name=&quot;text3&quot;&gt;&lt;/a&gt;</div><div class="line">        &lt;pre&gt;</div><div class="line">            小说文本1</div><div class="line">        &lt;/pre&gt;</div><div class="line">        </div><div class="line">        &lt;a name=&quot;text4&quot;&gt;&lt;/a&gt;</div><div class="line">        &lt;pre&gt;</div><div class="line">            小说文本1</div><div class="line">        &lt;/pre&gt;</div><div class="line">    &lt;a href=&quot;#menu&quot;&gt;顶部&lt;/a&gt;    </div><div class="line">&lt;/body&gt;</div><div class="line">&lt;/html&gt;</div></pre></td></tr></table></figure></p><h1 id="table表格"><a href="#table表格" class="headerlink" title="table表格"></a>table表格</h1><p>6.1. table标记<br>   基本格式:<code>&lt;table 属性1=&quot;属性值1&quot; 属性2=&quot;属性值2&quot;...&gt;表格内容&lt;/table&gt;</code><br>   table标记的属性<br>   width属性：表示表格的宽度，他的值可以是像素px也可以是父级元素的百分比%<br>   height属性：表示表格的高度，他的值可以是像素px也可以是父级元素的百分比%<br>   border属性：表示表格外边框的宽度<br>   align属性：表格的显示位置(默认值是left,值有left居左显示，center居中显示，right居右显示)<br>   cellpadding属性：单元格内容与单元格边框的显示距离，单位像素<br>   cellspacing属性：单元格之间的间距，默认是2px,单位像素<br>   frame属性：<br>   rules属性：none(默认值)表示无分割线，all表示包括所有分割线<br>   rows表示仅有行分割线，clos表示仅有列分割线，grouops表示仅有行组和列祖之间有分割线</p><p>6.2. <code>&lt;caption&gt;</code>标记<br>   什么时候使用：使用如果表格需要标题，那么就可以使用caption标记<br>   如何正确使用：caption属性的插入位置，直接位于table属性之后，tr表格行之前<br>   align属性：top标题放在表格的上部，botton标题放在表格的下部<br>   left标题放在表格的左部，right标题放在表格的右部<br>6.3. tr标记<br>   定义表格的一行，对于每一个表格行，都是有一对<code>&lt;tr&gt;&lt;/tr&gt;</code>标记表示，每一行<code>&lt;tr&gt;</code>标记内可以嵌套多个<code>&lt;td&gt;</code>或者<code>&lt;th&gt;</code>标记<br>   可选属性：bgcolor属性设置背景颜色<br>   align属性：设置垂直方向对齐方式<br>   valign属性：设置水平方向对齐方式<br>6.4. td和th标记<br>   bgcolor:设置单元格背景<br>   align:设置单元格对齐方式<br>   valign:设置单元格垂直对齐方式<br>   width:设置单元格宽度<br>   height:设置单元格高度<br>   rowspan:设置单元格所占行数<br>   colspan:设置单元格所占列数<br>6.5. thead(tr,th),tbody(tr,td),tfoot(tr,td);</p><p><strong>案例源码如下所示</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line">&lt;html&gt;</div><div class="line">&lt;head&gt;</div><div class="line">&lt;meta http-equiv=&quot;Content-Type&quot; Content=&quot;text/html; charset=utf-8&quot; /&gt;</div><div class="line">    &lt;title&gt;html字符实体&lt;/title&gt;</div><div class="line">&lt;/head&gt;</div><div class="line">&lt;body bgcolor=&quot;green&quot;&gt;&lt;!--bgcolor设置背景颜色--&gt;</div><div class="line">    &lt;table border=&quot;1&quot; bgcolor=&quot;blue&quot; width=&quot;60%&quot; height=&quot;60%&quot;&gt;</div><div class="line">        &lt;thead align=&quot;center&quot;&gt;</div><div class="line">            &lt;caption&gt;员工信息表&lt;/caption&gt;</div><div class="line">            &lt;tr&gt;</div><div class="line">                &lt;th&gt;&lt;a href=&quot;http://www.baidu.com&quot;&gt;姓名&lt;/a&gt;&lt;/th&gt;</div><div class="line">                &lt;th&gt;年龄&lt;/th&gt;</div><div class="line">                &lt;th&gt;性别&lt;/th&gt;</div><div class="line">                &lt;th&gt;电话&lt;/th&gt;</div><div class="line">                &lt;th&gt;QQ&lt;/th&gt;</div><div class="line">            &lt;/tr&gt;</div><div class="line">        &lt;/thead&gt;</div><div class="line">        &lt;tbody align=&quot;center&quot;&gt;</div><div class="line">            &lt;tr&gt;</div><div class="line">                &lt;td&gt;别先生&lt;/td&gt;</div><div class="line">                &lt;td&gt;22&lt;/td&gt;</div><div class="line">                &lt;td&gt;男&lt;/td&gt;</div><div class="line">                &lt;td&gt;152360****&lt;/td&gt;</div><div class="line">                &lt;td&gt;1748*****&lt;/td&gt;</div><div class="line">            &lt;/tr&gt;</div><div class="line">            &lt;tr&gt;</div><div class="line">                &lt;td&gt;刘先生&lt;/td&gt;</div><div class="line">                &lt;td&gt;22&lt;/td&gt;</div><div class="line">                &lt;td&gt;男&lt;/td&gt;</div><div class="line">                &lt;td&gt;158465****&lt;/td&gt;</div><div class="line">                &lt;td&gt;4548*****&lt;/td&gt;</div><div class="line">            &lt;/tr&gt;</div><div class="line">            &lt;tr&gt;</div><div class="line">                &lt;td&gt;李先生&lt;/td&gt;</div><div class="line">                &lt;td&gt;22&lt;/td&gt;</div><div class="line">                &lt;td&gt;男&lt;/td&gt;</div><div class="line">                &lt;td&gt;157516****&lt;/td&gt;</div><div class="line">                &lt;td&gt;1771*****&lt;/td&gt;</div><div class="line">            &lt;/tr&gt;</div><div class="line">        &lt;/tbody&gt;</div><div class="line">        &lt;tfoot&gt;</div><div class="line">            &lt;tr&gt;</div><div class="line">                &lt;td colspan=&quot;4&quot;&gt;一共多少人&lt;/td&gt;</div><div class="line">                &lt;td&gt;？？？&lt;/td&gt;</div><div class="line">            &lt;/tr&gt;</div><div class="line">        &lt;/tfoot&gt;</div><div class="line">    &lt;/table&gt;</div><div class="line">&lt;/body&gt;</div><div class="line">&lt;/html&gt;</div></pre></td></tr></table></figure></p><h1 id="HTML框架-切忌，不可以放在body标签之间"><a href="#HTML框架-切忌，不可以放在body标签之间" class="headerlink" title="HTML框架(切忌，不可以放在body标签之间)"></a>HTML框架(切忌，不可以放在body标签之间)</h1><p>7.1. 什么事框架？框架是将浏览器划分为不同的部分，每一部分加载不同的页面，实现在同一浏览器窗口中加载多个页面的效果<br>7.2. <code>&lt;frameset&gt;</code>划分框架标记<br>   语法格式：<code>&lt;frameset&gt;...&lt;frameset&gt;</code><br>   属性：<br>   cols:使用像素数和%分割左右窗口，”<em>“表示剩余部分<br>   如果使用`”</em>“<code>,</code>“<em>“<code>代表框架平均分成2个   如果使用</code>“</em>“<code>,</code>“<em>“<code>,</code>“</em>“<code>表示框架平均分成3个   rows:使用像素数和%分割上下窗口，</code>“*”<code>表示剩余部分   frameborder:指定是否显示边框，0不显示，1显示   border:设置边框的大小，默认值5像素7.3.</code><frame><code>子窗口标记</code><frame>`标记是一个单标记，该标记必须放在frameset中使用，在frameset中设置了几个窗口，就必须对应几个frame框架，而且还必须使用src属性指定一个网页<br>   属性：src属性加载网页文件的URL地址<br>   name:框架名称，是链接标记的target所要参数<br>   noresize:表示不能调整框架大小，没有设置时就可以调整<br>   scrolling:是否需要滚动条，值auto根据需要自动出现，yes有，no无<br>   frameborder:是否需要边框，值1显示边框，值0不显示边框</p><p>7.4. frame和iframe的区别</p><ol><li>frame不能脱离frameset单独使用，iframe可以</li><li>frame不能放在body中，iframe可以</li><li>iframe是被嵌入在网页的元素，而frame用于组成一个网页的多个框架</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">&lt;html&gt;</div><div class="line">&lt;head&gt;</div><div class="line">&lt;meta http-equiv=&quot;Content-Type&quot; Content=&quot;text/html; charset=utf-8&quot; /&gt;</div><div class="line">    &lt;title&gt;html中的框架&lt;/title&gt;</div><div class="line">&lt;/head&gt;</div><div class="line">&lt;frameset rows=&quot;25%,*&quot;&gt;</div><div class="line">    &lt;frame src=&quot;top.html&quot;&gt;</div><div class="line">        &lt;frameset cols=&quot;25%,*&quot;&gt;</div><div class="line">            &lt;frame src=&quot;left.html&quot;/&gt;</div><div class="line">            &lt;frame src=&quot;right.html&quot; name=&quot;rightname&quot;/&gt;</div><div class="line">        &lt;/frameset&gt;</div><div class="line">&lt;/frameset&gt;</div><div class="line">&lt;body&gt;</div><div class="line">    </div><div class="line">&lt;/body&gt;</div><div class="line">&lt;/html&gt;</div></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">&lt;html&gt;</div><div class="line">&lt;head&gt;</div><div class="line">&lt;meta http-equiv=&quot;Content-Type&quot; Content=&quot;text/html; charset=utf-8&quot; /&gt;</div><div class="line">    &lt;title&gt;html中的框架&lt;/title&gt;</div><div class="line">&lt;/head&gt;</div><div class="line">&lt;body&gt;</div><div class="line">    &lt;h1&gt;LOGO&lt;/h1&gt;</div><div class="line">&lt;/body&gt;</div><div class="line">&lt;/html&gt;</div></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">&lt;html&gt;</div><div class="line">&lt;head&gt;</div><div class="line">&lt;meta http-equiv=&quot;Content-Type&quot; Content=&quot;text/html; charset=utf-8&quot; /&gt;</div><div class="line">    &lt;title&gt;html中的框架&lt;/title&gt;</div><div class="line">&lt;/head&gt;</div><div class="line">&lt;body&gt;</div><div class="line">    &lt;a href=&quot;http://www.baidu.com&quot; target=&quot;rightname&quot;&gt;百度&lt;/a&gt;&lt;br/&gt;</div><div class="line">    &lt;a href=&quot;http://www.jd.com&quot; target=&quot;rightname&quot;&gt;京东&lt;/a&gt;&lt;br/&gt;</div><div class="line">    &lt;a href=&quot;http://www.taobao.com&quot; target=&quot;rightname&quot;&gt;淘宝&lt;/a&gt;&lt;br/&gt;</div><div class="line">    &lt;a href=&quot;&quot;&gt;注册&lt;/a&gt;&lt;br/&gt;</div><div class="line">    &lt;a href=&quot;&quot;&gt;登陆&lt;/a&gt;&lt;br/&gt;</div><div class="line">&lt;/body&gt;</div><div class="line">&lt;/html&gt;</div></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">&lt;html&gt;</div><div class="line">&lt;head&gt;</div><div class="line">&lt;meta http-equiv=&quot;Content-Type&quot; Content=&quot;text/html; charset=utf-8&quot; /&gt;</div><div class="line">    &lt;title&gt;html中的框架&lt;/title&gt;</div><div class="line">&lt;/head&gt;</div><div class="line">&lt;body&gt;</div><div class="line">    </div><div class="line">&lt;/body&gt;</div><div class="line">&lt;/html&gt;</div></pre></td></tr></table></figure><h1 id="表单设计"><a href="#表单设计" class="headerlink" title="表单设计"></a>表单设计</h1><p>8.1. 表单标记<code>&lt;form&gt;</code>表单元素放到这里<br>   <code>&lt;form&gt;&lt;/form&gt;</code>定义表单的开始位置和结束位置，表单提交时的内容就是<form>表单中单的内容<br>   基本格式：<code>&lt;form action=&quot;服务器端地址（接受表单内容的地址）&quot; name=&quot;表单名称&quot; method=&quot;post/get&quot;&gt;&lt;/form&gt;</code><br>   常用属性：<br>   name是表单名称，method是传送数据的方式，分为post(常用)和get两种方法，get方法提交时，会将表单的内容附加在url地址的后面，所以限制了提交的内容的长度，不超过8192个字符，且不具备保密性<br>   post方式，提交时，将表单中的数据一并包含在表单主体中，一起传送到服务器中处理，没有数据大小限制<br>   action:表单数据的处理程序的url地址，如果为空则使用当前文档的url地址，如果表单中不需要使用action属性也要指定其属性为其属性为”no”<br>   enctype:设置表单的资料的编码方式<br>   target:和超链接的属性类似，用来指定目标窗口</form></p><p>8.2. 文本框和密码<code>&lt;input&gt;</code><br>   基本语法：<code>&lt;input type=&quot;&quot; name=&quot;&quot; value=&quot;&quot; size=&quot;&quot; maxlength=&quot;&quot;&gt;</code><br>   属性介绍：<br>   type属性：type属性有两个值，当type=”text”,表示文本输入框，当type=”password”,表示密码输入框<br>   name属性：定义控件的名称<br>   value属性：初始化值，打开浏览器时，文本框中的内容<br>   size属性：设置控件的长度<br>   manlength属性：输入框中最大允许输入的字符数<br>8.3. 提交，重置(恢复至初始值，不是清空，name可以验证效果)，普通按钮<br>   提交按钮：当<code>&lt;input type=&quot;submit&quot;&gt;</code>时，为提交按钮<br>   重置按钮：当<code>&lt;input type=&quot;reset&quot;&gt;</code>时，为重置按钮<br>   《以上两个按钮必须放在form表单下才可以体现功能》<br>   普通按钮：当<code>&lt;input type=&quot;button&quot;&gt;</code>时，为普通按钮<br>8.4. 单选框和复选框<br>   单选按钮：当type=radio时，为单选按钮<br>   复选框：当type=checkbox时，为复选框<br>   注意：单选框和复选框都可以使用checked属性来设置默认选中项<br>8.5. 隐藏域<br>   隐藏文本框：当type=hidden时，为隐藏文本框<br>8.6. 多行文本域<br>   用法，使用textarea标记可以实现一个，能够输入多行文本的区域<br>   语法格式<code>&lt;textarea name=&quot;name&quot; rows=&quot;value&quot; cols=&quot;value&quot; value=&quot;value&quot;&gt;&lt;textarea&gt;</code><br>   rows属性和cols属性分别用来指定，显示的行数和列数，单位是字符个数<br>8.7. 菜单下拉列表域<br><code>&lt;select&gt;标记</code><br>   <code>&lt;option select=&quot;select默认选项&quot;&gt;选项</code><br><code>&lt;/select&gt;</code></p><p><strong>案例代码</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">&lt;html&gt;</div><div class="line">&lt;head&gt;</div><div class="line">&lt;meta http-equiv=&quot;Content-Type&quot; Content=&quot;text/html; charset=utf-8&quot; /&gt;</div><div class="line">    &lt;title&gt;html中的框架&lt;/title&gt;</div><div class="line">&lt;/head&gt;</div><div class="line">&lt;body&gt;</div><div class="line">    &lt;form method=&quot;post&quot; action=&quot;&quot;&gt;</div><div class="line">        账号&lt;input type=&quot;text&quot; name=&quot;text&quot;/&gt;&lt;br/&gt;</div><div class="line">        密码&lt;input type=&quot;password&quot; name=&quot;password&quot;&gt;&lt;br/&gt;</div><div class="line">        &lt;input type=&quot;submit&quot; value=&quot;提交&quot;&gt;</div><div class="line">        &lt;input type=&quot;reset&quot; value=&quot;重置&quot;&gt;</div><div class="line">        &lt;input type=&quot;button&quot; value=&quot;按钮&quot;&gt;&lt;br/&gt;</div><div class="line">        性别&lt;input type=&quot;radio&quot; name=&quot;sex&quot; value=&quot;男&quot;&gt;男</div><div class="line">        &lt;input type=&quot;radio&quot; name=&quot;sex&quot; value=&quot;女&quot;&gt;女</div><div class="line">        &lt;input type=&quot;radio&quot; name=&quot;sex&quot; value=&quot;保密&quot;&gt;保密&lt;br/&gt;</div><div class="line">        爱好&lt;input type=&quot;checkBox&quot; name=&quot;ball&quot; value=&quot;篮球&quot;&gt;篮球</div><div class="line">        &lt;input type=&quot;checkBox&quot; name=&quot;ball&quot; value=&quot;足球&quot;&gt;足球</div><div class="line">        &lt;input type=&quot;checkBox&quot; name=&quot;ball&quot; value=&quot;排球&quot;&gt;排球&lt;br/&gt;</div><div class="line">        注释&lt;textarea rows=&quot;10&quot; cols=&quot;20&quot;&gt;今晚回家&lt;/textarea&gt;&lt;br/&gt;</div><div class="line">        回家方式&lt;select&gt;</div><div class="line">            &lt;option select=&quot;select&quot;&gt;火车&lt;/option&gt;</div><div class="line">            &lt;option&gt;汽车&lt;/option&gt;</div><div class="line">            &lt;option&gt;轮船&lt;/option&gt;</div><div class="line">            &lt;option&gt;飞机&lt;/option&gt;</div><div class="line">        &lt;/select&gt;&lt;br/&gt;</div><div class="line">        文件&lt;input type=&quot;file&quot;/&gt;</div><div class="line">    &lt;/form&gt;</div><div class="line">&lt;/body&gt;</div><div class="line">&lt;/html&gt;</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近简单学习了一下html，看到这么一篇文章&lt;a href=&quot;http://www.cnblogs.com/biehongli/p/5772432.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;《HTML入门的简单学习》&lt;/a&gt;，总结下来，方便以后查阅。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Tech" scheme="http://songit.cn/categories/Tech/"/>
    
    
      <category term="Html" scheme="http://songit.cn/tags/Html/"/>
    
  </entry>
  
  <entry>
    <title>Windows下Mysql免安装版出现的常见错误（1045,1054,1820）</title>
    <link href="http://songit.cn/MysqlError/"/>
    <id>http://songit.cn/MysqlError/</id>
    <published>2017-06-08T01:10:36.000Z</published>
    <updated>2018-12-05T09:39:30.000Z</updated>
    
    <content type="html"><![CDATA[<p>由于有无法抗拒的理由，笔者又重新踏上安装mysql之旅。之前安装MySQL很顺利，这次安装出现了一系列问题，问题的源头是常见的ERROR 1045，最后终于解决了，下面是解决办法。如有不足之处请指出。<br><a id="more"></a></p><p>由于笔者使用安装的Windows系统，而且用的是MySQL5.7.18的免安装版所以在此只说明Windows平台下MySQL免安装版的问题解决办法。<br>Windows平台下：<br><strong>ERROR 1045</strong>错误具体显示为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ERROR 1045：Access denied for user &apos;root&apos;@&apos;localhost&apos; (using password:YES)</div></pre></td></tr></table></figure><h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><p>1.在MySQL安装路径下找到my.ini文件,在[mysqld]下添加<br><em>skip-grant-tables</em><br>添加后显示为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">[client]</div><div class="line">port=3306</div><div class="line">default-character-set=utf8</div><div class="line">[mysqld]</div><div class="line">skip-grant-tables</div><div class="line">port=3306</div><div class="line">character_set_server=utf8</div><div class="line">basedir=D:\learn\mysql-5.7.18-winx64</div><div class="line">datadir=D:\learn\mysql-5.7.18-winx64\data</div><div class="line">[WinMySQLAdmin]</div><div class="line">%MYSQL_HOME%\bin\mysqld.exe</div></pre></td></tr></table></figure><p>表示跳过密码选项。</p><p>2.重新启动mysql服务；</p><p>这里有两种办法：<br>（1） 用管理员权限进入windows命令行，输入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">net stop mysql</div></pre></td></tr></table></figure></p><p>再输入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">net start mysql</div></pre></td></tr></table></figure></p><p>即可。<br>（2） 右击我的电脑&gt;管理&gt;服务和应用程序&gt;服务，找到MySQL服务，点击重新启动即可。如图所示。<br><img src="/imgs/MySQL_Restart.PNG" alt="MySQL重启动"></p><p>3.在命令行内输入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mysql -u root -p</div></pre></td></tr></table></figure></p><p>后<em>Enter Password：</em>直接回车即可进入mysql。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mysql&gt;use mysql;</div></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mysql&gt;update user SET PASSWORD FOR &apos;root&apos;@&apos;localhost&apos; = PASSWORD(&apos;MyNewPassword&apos;);</div></pre></td></tr></table></figure><p>4.然而在这里又出现<strong>ERROR 1054</strong>错误：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ERROR 1054 (42S22): Unknown column &apos;password&apos; in &apos;field list&apos;</div></pre></td></tr></table></figure></p><p>后来发现果然是用户表没有password列，取而代之的是authentication_string列，所以此处应该输入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mysql&gt;update user set authentication_string = password(&apos;MyNewPassword&apos;) where user=&apos;root&apos;;</div></pre></td></tr></table></figure></p><p>提示成功后输入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">msyql&gt;FLUSH PRIVILEGES;</div></pre></td></tr></table></figure></p><p>最后退出，输入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mysql&gt;quit</div></pre></td></tr></table></figure></p><p>5.删除my.ini文件中之前加入的<em>skip-grant-tables</em>，重新启动mysql服务。</p><p>6.在输入相关命令便可进入mysql。<br>但是此时又出现<strong>ERROR 1820</strong>错误：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ERROR 1820 (HY000): You must SET PASSWORD before executing this statement</div></pre></td></tr></table></figure></p><p>这种问题的解决办法为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mysql&gt;SET PASSWORD = PASSWORD(&apos;MyNewPassword&apos;);</div></pre></td></tr></table></figure></p><p>这样便可解决。</p><p>这样安装mysql免安装版的一系列问题，让笔者搞了半天，记下来方便你我他，哈哈~</p><p>想了解更多关于MySQL的其他知识，可参考笔者的另一篇文章<a href="http://songit.cn/MySQLCrashCourse.html">《MySQL入门知识点》</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;由于有无法抗拒的理由，笔者又重新踏上安装mysql之旅。之前安装MySQL很顺利，这次安装出现了一系列问题，问题的源头是常见的ERROR 1045，最后终于解决了，下面是解决办法。如有不足之处请指出。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Tech" scheme="http://songit.cn/categories/Tech/"/>
    
    
      <category term="MySQL" scheme="http://songit.cn/tags/MySQL/"/>
    
      <category term="数据库" scheme="http://songit.cn/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Windows" scheme="http://songit.cn/tags/Windows/"/>
    
  </entry>
  
  <entry>
    <title>使用IIS实现域名跳转</title>
    <link href="http://songit.cn/URLJUMP/"/>
    <id>http://songit.cn/URLJUMP/</id>
    <published>2017-05-25T03:17:14.000Z</published>
    <updated>2018-12-05T09:33:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>大约一年前，笔者拥有了人生中的第一个域名<em>dreamsongmxs.cn</em>(已到期，未续费)，时间长了，就觉得这个域名太长了，不便于读者记忆，于是便想了又想，又买下了现在这个域名<a href="http://songit.cn">songit.cn</a>,所以你们要买域名一定要想好对于自己有意义的域名而且好记的啊，不然遇到合适的域名你还是会动心，到时候就浪费了。我的一个哥们就注册了3个，最后还是只用一个，他的域名点<a href="http://iamlay.com" target="_blank" rel="external">这里</a>查看。所以我之前的那个域名就被闲置下来，另外我还有一个闲置的云主机，于是就想通过云主机来实现域名的跳转，让我之前那个域名可以跳转到现在的这个域名。下面就来说下我怎么实现的吧。<br><a id="more"></a></p><p><strong>域名重定向的意义</strong>   当域名或者目录变更的情况，把旧域名的访问请求重新引导到新域名上。不管是对于普通用户还是搜索引擎都是十分友好的，也有人利用域名重定向来作弊。</p><p><strong>301重定向跳转对搜索引擎的好处</strong></p><ol><li>增加域名权重</li><li>对网页收录的优化</li><li>有利于网页PR传递 </li><li>可促进搜索引擎优化效果 </li><li>对用户体验表示友好</li></ol><p>由于笔者对Linux还不是太了解，就把云主机装了Windows Server 2012 R2系统。以后会学习Linux再用Linux实现这个功能。</p><h1 id="远程连接云主机"><a href="#远程连接云主机" class="headerlink" title="远程连接云主机"></a>远程连接云主机</h1><ol><li>同时按下<strong>win+R</strong>键</li><li>运行框中输入<em>mstsc</em></li><li>在计算机框中输入云主机的公网IP地址（笔者这里是118.89.33.43）</li><li>点击连接，输入云主机密码（为了方便下次连接云主机，可根据需要选择记住凭据）。</li><li>然后确定就可以进入云主机了。</li></ol><h1 id="Windows-Server-2012-IIS配置安装"><a href="#Windows-Server-2012-IIS配置安装" class="headerlink" title="Windows Server 2012 IIS配置安装"></a>Windows Server 2012 IIS配置安装</h1><ol><li>单击状态栏中的<strong>服务器管理器</strong></li><li>在“仪表板”中单击<strong>添加角色和功能</strong></li><li>在“开始之前”界面直接点击<strong>下一步</strong></li><li>在“安装类型”界面单击<strong>基于角色或基于功能的安装</strong>，再单击<strong>下一步</strong></li><li>在“服务器选择”界面单击<strong>从服务器池中选择服务器</strong>，再单击<strong>本服务器的计算机名</strong>，这个ip上只有本机，直接单击<strong>下一步</strong></li><li>在“服务器角色”界面找到并勾选<strong>Web服务器(IIS)</strong></li><li>弹出子对话框“添加角色和功能向导”，直接单击<strong>添加功能</strong></li><li>在“功能”界面，找到并勾选<strong>.Net Framewore 3.5</strong>和<strong>.Net Framewore 4.5</strong>（4.5一般已安装）</li><li>在“角色服务器”界面，中间角色服务列表选择需要安装的项目（如果你不知道需要选哪些，建议你全部都勾选它[Ftp服务器除外]，这里我们会用到Http重定向功能，这个一定要勾选），点击<strong>下一步</strong></li><li>在“确认”界面确认下所勾选的安装组件，然后单击<strong>安装</strong></li><li>在“结果”界面，windows 2012 Server IIS开始安装，等几分钟后，安装成功，点击<strong>关闭</strong></li><li>查看windows 2012 Server IIS8.0安装和运行结果：打开浏览器，输入本机公网ip，或者本机内网ip，或localhost均可，便能看到IIS界面显示出来</li></ol><h1 id="IIS实现HTTP重定向"><a href="#IIS实现HTTP重定向" class="headerlink" title="IIS实现HTTP重定向"></a>IIS实现HTTP重定向</h1><ol><li>在“仪表板”界面点击<strong>工具</strong>，选择<strong>Internet Information Services（IIS）管理器</strong>，如图所示。<br><img src="/imgs/IISManager.png" alt="IIS管理器"></li><li>在左侧栏里点中一串数字（内网IP），会出现应用程序池和网站两个小图标，网站还能下拉，点中<strong>Default Web Site</strong>(这个是服务器本身IP的网址)</li><li>在右侧“Default Web Site主页”有许多图标，双击<strong>HTTP重定向</strong></li><li>在“HTTP重定向”界面，设置自己要跳转到的网址，笔者的是<em><a href="http://songit.cn">http://songit.cn</a></em>（一定要记得加上<em>http://</em>），“重定向行为”选项中，勾选<strong>将所有请求重定向到确切的目标（而不是相对于目标）（E）</strong>，“状态代码”下拉栏中选择<strong>永久（301）</strong>，如图所示。<br><img src="/imgs/HTTP301.png" alt="HTTP重定向设置"></li><li>在“操作”栏中点击<strong>应用</strong>即可</li></ol><h1 id="原域名的域名解析"><a href="#原域名的域名解析" class="headerlink" title="原域名的域名解析"></a>原域名的域名解析</h1><p><img src="/imgs/dreamsongmxs_IP.png" alt="dreamsongmxs域名解析"><br>添加如上所示两条记录便可以实现原域名跳转到自己想要实现的域名了。其中A记录类型中的记录值为云主机的公网IP。</p><p>这就是笔者使用IIS管理器实现域名跳转的全部步骤了，笔者的<a href="http://dreamsongmxs.cn" target="_blank" rel="external">原域名</a>已经可以指向现在的这个<a href="http://songit.cn">新域名</a>了。想要实现的小伙伴可以试下。<br>如有不足之处，还请指出。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;大约一年前，笔者拥有了人生中的第一个域名&lt;em&gt;dreamsongmxs.cn&lt;/em&gt;(已到期，未续费)，时间长了，就觉得这个域名太长了，不便于读者记忆，于是便想了又想，又买下了现在这个域名&lt;a href=&quot;http://songit.cn&quot;&gt;songit.cn&lt;/a&gt;,所以你们要买域名一定要想好对于自己有意义的域名而且好记的啊，不然遇到合适的域名你还是会动心，到时候就浪费了。我的一个哥们就注册了3个，最后还是只用一个，他的域名点&lt;a href=&quot;http://iamlay.com&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这里&lt;/a&gt;查看。所以我之前的那个域名就被闲置下来，另外我还有一个闲置的云主机，于是就想通过云主机来实现域名的跳转，让我之前那个域名可以跳转到现在的这个域名。下面就来说下我怎么实现的吧。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Tech" scheme="http://songit.cn/categories/Tech/"/>
    
    
      <category term="Windows Server" scheme="http://songit.cn/tags/Windows-Server/"/>
    
      <category term="IIS" scheme="http://songit.cn/tags/IIS/"/>
    
      <category term="域名" scheme="http://songit.cn/tags/%E5%9F%9F%E5%90%8D/"/>
    
  </entry>
  
  <entry>
    <title>MySQL入门知识点</title>
    <link href="http://songit.cn/MySQLCrashCourse/"/>
    <id>http://songit.cn/MySQLCrashCourse/</id>
    <published>2017-05-23T08:20:07.000Z</published>
    <updated>2017-06-08T02:28:09.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近把《MySQL必知必会》读完了，跟着书上的例子敲了一遍，把一些常用的知识点记录到笔记本上。这本书是网友推荐全五星的一本书，书有三十章的内容，但是不厚，很适合当做MySQL入门书籍。这篇文章简要的介绍下我读完这本书对MySQL的了解，有什么不足之处还请在评论处指出。<br><a id="more"></a><br>《MySQL必知必会》的电子书和数据库脚本点下载链接：<a href="http://pan.baidu.com/s/1kVhwLr5" target="_blank" rel="external">http://pan.baidu.com/s/1kVhwLr5</a> 密码：6cds</p><h1 id="Windows下MySQL的安装与配置"><a href="#Windows下MySQL的安装与配置" class="headerlink" title="Windows下MySQL的安装与配置"></a>Windows下MySQL的安装与配置</h1><h2 id="MySQL软件下载"><a href="#MySQL软件下载" class="headerlink" title="MySQL软件下载"></a>MySQL软件下载</h2><p>首先先下载MySQL，笔者下载的是MySQL免安装版。<br>MySQL免安装版官方下载地址点<a href="https://dev.mysql.com/downloads/mysql/" target="_blank" rel="external">这里</a><br>MySQL安装版官方下载地址点<a href="https://dev.mysql.com/downloads/installer/" target="_blank" rel="external">这里</a></p><h2 id="MySQL的配置"><a href="#MySQL的配置" class="headerlink" title="MySQL的配置"></a>MySQL的配置</h2><ol><li>解压自己下载的安装包到安装位置，如<em>D:\learn\mysql-5.7.18-winx64</em>。笔者下载的是5.7.18版本的，里面没有my.ini文件。</li><li><p>新建文件my.ini文件，扩展名为.ini。用记事本打开，将以下内容输入进去。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[client]</div><div class="line">port=3306</div><div class="line">default-character-set=utf8</div><div class="line">[mysqld]</div><div class="line">port=3306</div><div class="line">character_set_server=utf8</div><div class="line">basedir=D:\learn\mysql-5.7.18-winx64</div><div class="line">datadir=D:\learn\mysql-5.7.18-winx64\data</div><div class="line">[WinMySQLAdmin]</div><div class="line">%MYSQL_HOME%\bin\mysqld.exe</div></pre></td></tr></table></figure></li><li><p>配置环境变量。<br>右击我的电脑&gt;属性&gt;高级系统设置&gt;高级&gt;环境变量<br>新建系统变量名MYSQL_HOME，变量值为MySQL安装目录路径，笔者这里为<em>D:\learn\mysql-5.7.18-winx64</em><br>在环境变量Path中变量中添加<em>;%MYSQL_HOME%\bin;</em> 笔者的电脑系统是win10系统，Path中变量比较多，新建了一个<em>D:\learn\mysql-5.7.18-winx64\bin</em>的Path变量。</p><h2 id="MySQL服务安装"><a href="#MySQL服务安装" class="headerlink" title="MySQL服务安装"></a>MySQL服务安装</h2><p>用管理员权限打开Windows命令提示符，输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mysqld --install MySQL --defaults-file=&quot;my.ini&quot;</div></pre></td></tr></table></figure></li></ol><p>提示”Service successfully installed.”表示成功安装。</p><h2 id="MySQL服务的启动、停止与卸载"><a href="#MySQL服务的启动、停止与卸载" class="headerlink" title="MySQL服务的启动、停止与卸载"></a>MySQL服务的启动、停止与卸载</h2><p>用管理员权限打开Windows命令提示符下运行:<br>启动:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">net start MySQL</div></pre></td></tr></table></figure></p><p>停止:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">net stop MySQL</div></pre></td></tr></table></figure></p><p>卸载:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sc delete MySQL</div></pre></td></tr></table></figure></p><h2 id="初始化MySQL"><a href="#初始化MySQL" class="headerlink" title="初始化MySQL"></a>初始化MySQL</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mysqladmin -u root password &apos;new-password&apos;</div></pre></td></tr></table></figure><p>想要进入mysql，首先用管理员权限打开Windows命令提示符，打开mysql服务，输入<em>mysql -u root -p</em>后再输入密码就可以进去了。</p><p><strong>注意</strong> MySQL安装出现1045，1054,1820常见错误的解决办法，见笔者的另一篇文章<a href="http://songit.cn/MysqlError.html">《Windows下Mysql免安装版出现的常见错误（1045,1054,1820）》</a></p><h1 id="可视化管理工具MySQL-Workbench"><a href="#可视化管理工具MySQL-Workbench" class="headerlink" title="可视化管理工具MySQL Workbench"></a>可视化管理工具MySQL Workbench</h1><p>MySQL Workbench就是MySQL官方为MySQL提供的一款可视化管理工具, 你可以在里面通过可视化的方式直接管理数据库中的内容, 并且MySQL Workbench的SQL脚本编辑器支持语法高亮以及输入时的语法检查, 它的功能很强大。笔者在看这本书是用管理员权限打开Windows命令提示符下通过一行行的输入来执行mysql语句, 但该方式效率较低。<br>想了解MySQL Workbench官方介绍点<a href="http://www.mysql.com/products/workbench/" target="_blank" rel="external">这里</a>，下载地址点<a href="http://dev.mysql.com/downloads/tools/workbench/" target="_blank" rel="external">这里</a></p><h1 id="MySQL创建样例表"><a href="#MySQL创建样例表" class="headerlink" title="MySQL创建样例表"></a>MySQL创建样例表</h1><p>在文章开头有两个可以下载的SQL脚本文件的链接，可自行下载。<br>其中create.sql包含创建6个数据库表（包含所有主键和外键约束）的MySQL语句；populate.sql包含用来填充这些表的INSERT语句。<br>将这两个文件导入MySQL，首先需要创建一个数据库database，这里数据库自命名为booktest，输入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mysql&gt;create database booktest;</div></pre></td></tr></table></figure></p><p>然后依次输入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">-- 这里指定create.sql和populate.sql文件的完全路径，并且使用正斜杠/，而不是反斜杠\。</div><div class="line">mysql&gt;source C:/Users/Dreamsongmxs/Desktop/mysql_scripts/create.sql;</div></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mysql&gt;source C:/Users/Dreamsongmxs/Desktop/mysql_scripts/populate.sql;</div></pre></td></tr></table></figure><p>这样数据脚本就导入成功了。</p><p>当然也可以使用MySQL Workbench导入，道理相同，具体操作过程在这里就不再详述了。</p><h1 id="了解SQL"><a href="#了解SQL" class="headerlink" title="了解SQL"></a>了解SQL</h1><h2 id="数据库基础"><a href="#数据库基础" class="headerlink" title="数据库基础"></a>数据库基础</h2><p><strong>数据库（database）</strong>  保存有组织的数据的容器（通常是一个文件或一组文件）。</p><p><strong>表（table）</strong>  某种特定类型数据的结构化清单。</p><p><strong>表名</strong>  表名的唯一性取决于多个因素，如数据库名和表名的结合。这表示，虽然在相同数据库中不能两次使用相同的表名，但在不同的数据库中却可以使用相同的表名。</p><p><strong>模式（schema）</strong>  关于数据库和表的布局及特性的信息。</p><p>表由列组成。列中存储着表中某部分的信息。<br><strong>列（column）</strong>  表中的一个字段。所有表都是由一个或多个列组成的。</p><p><strong>数据类型（datatype）</strong>  所容许的数据的类型。每个表列都有相应的数据类型，它限制（或容许）该列中存储的数据。</p><p>表中的数据是按行存储的，所保存的每个记录存储在自己的行内。<br><strong>行（row）</strong>  表中一个记录。</p><p><strong>主键（primary key）</strong>  一列（或一组列），其值能够唯一区分表中每个行。<br>表中的任何列都可以作为主键，只要它满足以下条件：</p><ol><li>任意两行都不具有相同的主键值；</li><li>每一行都必须具有一个主键值（主键列不允许NULL值）。<br>主键的最好习惯：</li><li>不更新主键列中的值；</li><li>不重用主键列的值；</li><li>不在主键列中使用可能会更改的值。</li></ol><h2 id="什么是SQL"><a href="#什么是SQL" class="headerlink" title="什么是SQL"></a>什么是SQL</h2><p>SQL是结构化查询语言（Structured Query Language）的缩写。SQL是一种专门用来与数据库通信的语言。<br>SQL的优点：</p><ol><li>SQL不是某个特定数据库供应商专有的语言。几乎所有重要的DBMS都支持SQL。</li><li>SQL简单易学。</li><li>SQL灵活使用其语言元素，可以进行非常复杂和高级的数据库操作。  </li></ol><h1 id="MySQL简介"><a href="#MySQL简介" class="headerlink" title="MySQL简介"></a>MySQL简介</h1><p>MySQL是一种DBMS（数据库管理系统）。<br>DBMS分为两类：一类为基于共享文件系统的DBMS，另一类为基于客户机-服务器的DBMS。其中服务器是负责所有数据访问和处理的一个软件；客户机是与用户打交道的软件。<br>MySQL为关系型数据库(Relational Database Management System), 这种所谓的”关系型”可以理解为”表格”的概念, 一个关系型数据库由一个或数个表格组成。<br>每个MySQL安装都有一个名为mysql的简单命令行实用程序。<br>请注意：</p><ol><li>命令输入在mysql&gt;之后；</li><li>命令用;或\g结束，换句话说，仅按Enter不执行命令；</li><li>输入help或\h获得帮助，也可以输入更多的文本获得特定命令的帮助（如输入help select获得实用SELECT的帮助）；</li><li>输入quit或exit退出命令行实用程序。</li><li>SQL语句不区分大小写。</li></ol><p>未完，待续。。。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近把《MySQL必知必会》读完了，跟着书上的例子敲了一遍，把一些常用的知识点记录到笔记本上。这本书是网友推荐全五星的一本书，书有三十章的内容，但是不厚，很适合当做MySQL入门书籍。这篇文章简要的介绍下我读完这本书对MySQL的了解，有什么不足之处还请在评论处指出。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Tech" scheme="http://songit.cn/categories/Tech/"/>
    
    
      <category term="MySQL" scheme="http://songit.cn/tags/MySQL/"/>
    
      <category term="数据库" scheme="http://songit.cn/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>20170520</title>
    <link href="http://songit.cn/20170520/"/>
    <id>http://songit.cn/20170520/</id>
    <published>2017-05-20T05:14:00.000Z</published>
    <updated>2018-12-05T09:41:59.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/imgs/sovtan.jpg" alt="sovtan"><br><a id="more"></a></p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=5249545&auto=1&height=66"></iframe><p>今天就像做梦一样，很庆幸这是现实，有点像梦境一般的现实。人生就像一场梦，有些东西就是注定会发生，该来的还是会来。顺其自然，若是注定发生，必会如你所愿。<br>在这里衷心希望你们都能如愿以偿！<br><img src="/imgs/Heart_to_Heart.jpg" alt="比心心"><br>一时竟无语凝塞，铭记今天，好好珍惜，以后平凡生活中努力能带给她惊喜与幸福！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/imgs/sovtan.jpg&quot; alt=&quot;sovtan&quot;&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="人生随笔" scheme="http://songit.cn/categories/%E4%BA%BA%E7%94%9F%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="Feelings" scheme="http://songit.cn/tags/Feelings/"/>
    
      <category term="感悟" scheme="http://songit.cn/tags/%E6%84%9F%E6%82%9F/"/>
    
      <category term="MUSIC" scheme="http://songit.cn/tags/MUSIC/"/>
    
  </entry>
  
  <entry>
    <title>戳心“乐评”</title>
    <link href="http://songit.cn/PokeHeartComments/"/>
    <id>http://songit.cn/PokeHeartComments/</id>
    <published>2017-03-23T11:11:14.000Z</published>
    <updated>2017-04-15T03:07:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>用网易云音乐两年了，有时候是因为神评论喜欢一首歌，都是有故事的人，在一首首有故事的歌，成就了这么多有故事的评论~<br><a id="more"></a></p><ol><li>你别皱眉，我走就好。      <pre><code>——来自用户 hhn呀 在刘若英《很爱很爱你》歌曲下方的评论</code></pre></li><li>最怕一生碌碌无为，还说平凡难能可贵。<pre><code>——来自用户 昂登 在白亮/赵静《孙大剩》歌曲下方的评论</code></pre></li><li>你那么孤独，却说一个人真好。<pre><code>——来自用户 数的绵羊都睡了 在丁可《If》歌曲下方的评论</code></pre></li><li>我在最没有能力的年纪，碰见了最想照顾一生的人。<pre><code>——来自《同桌的你》歌曲下方的评论</code></pre></li><li>理想就是离乡。</li><li>周杰伦把爱情比喻成龙卷风，我觉得特别贴切。因为很多人，像我。一辈子都没见过龙卷风。<pre><code>——来自《龙卷风》歌曲下方的评论</code></pre></li><li>喜欢这种东西，捂住嘴巴，也会从眼睛里跑出来。</li><li>十年前你说生如夏花般徇烂，十年后你说平凡才是唯一的答案。</li><li>“你还记得她吗？” “早忘了，哈哈” “我还没说是谁。”</li><li>年轻时我想变成任何人，除了我自己。</li><li>我不喜欢这世界，我只喜欢你。</li><li>我从未拥有过你一秒钟，心里却失去过你千万次。<pre><code>——来自《再见二丁目》歌曲下方的评论</code></pre></li><li>人生的出厂顺序太重要了。</li><li>世界如此广阔，人类却走进了悲伤的墙角。</li><li>我听过一万首歌，看过一千部电影，读过一百本书，却从未俘获一个人的心。</li><li>哭着吃过饭的人，是能够走下去的。</li><li>祝你们幸福是假的，祝你幸福是真的。</li><li>究竟有多喜欢你才能温柔成这个样子。</li><li>多少人以朋友的名义默默的爱着。<pre><code>——来自用户 月海浪花 在陈奕迅《十年》歌曲下方的评论</code></pre></li><li>别人一注意你，你就敞开心扉，你觉得这是坦率，其实这是孤独······</li><li>我喜欢我望向别处时你落在我身上的目光。<pre><code>——来自用户 亚索呼吸侬 在Kath Bloom《Come Here》歌曲下方的评论</code></pre></li><li>不在一起就不在一起吧，反正一辈子也没多长。</li><li>我想做一个能在你的葬礼上描述你一生的人。</li><li>一个人久了，煮个饺子看见两个黏在一起的也要给他们分开。</li><li>多数人25岁就死了，但直到75岁才埋。<pre><code>——来自《杀死那个石家庄人》歌曲下方的评论</code></pre></li><li>十年前第一次和你说晚安，我激动的失眠了一整夜，十年后的今晚和你说晚安，不再失眠，但你的头压得我胳膊好酸。<pre><code>——来自《晚安》歌曲下方的评论</code></pre></li><li>今天去看大圣归来。我旁边有个小孩儿问他妈妈“这个不是动画片么？为什么有这么多大人来看？” 他妈妈回答：“因为他们一直在等大圣归来啊，等啊等啊，就长大了。”<pre><code>——来自《悟空》歌曲下方的评论</code></pre></li><li>06年本科毕业，中午会餐，和人喝了一瓶白酒，而后稀里糊涂睡了过去，一觉醒来，发现室友已走了大半，床头的手机响个不停，接通之后好兄弟边哭边骂“老子都上火车了，老子再也看不到你了”霎时，泪如雨下，也许因为酒太多了，鼻血也流个不停，平生第一次，感觉到心揪着痛，那种滋味一辈子也忘不了。<pre><code>——来自《你离开了南京，从此没有人和我说话》歌曲下方的评论</code></pre></li><li>小时候想要快快长大，真正长大以后会懂得还是小时候最开心，可惜一旦错过了就永远都回不去了。<pre><code>——来自《7years》歌曲下方的评论</code></pre></li><li>昨天上班时间，我穿着西服站在二楼窗前看着路上来来往往的人们。觉得城市里天空太窄，忽然想回家种地。可是离我退休年龄还很遥远。我的影子说想杀死我，然后替代我好好生活。<pre><code>——来自《梵高先生》歌曲下方的评论</code></pre></li><li>你若安好，我备胎到老。<pre><code>——来自《鬼迷心窍》歌曲下方的评论</code></pre></li><li>毕业前的一个晚上，我们宿舍的6个人默默喝了20多瓶啤酒。第二天起床，谁也没叫谁，谁先起来先静静离开。我闭着眼听着他们5个人全都走了，默默起床收拾卫生，打扫最后一次宿舍。下楼梯交钥匙给阿姨的时候流眼泪了。<pre><code>——来自《凤凰花开的路口》歌曲下方的评论</code></pre></li><li>你说少年明媚如昨，怎知少年时光如梦。<pre><code>——来自《时光》歌曲下方的评论</code></pre></li><li>每当坐火车回家的时候我都会听这首曲子，看着窗外一闪而过却又绵绵不绝的田野，说不出的酸甜苦辣，讲不出的思乡之情。<pre><code>——来自《故乡的原风景》歌曲下方的评论</code></pre></li><li>要么荣归故里，要么客死他乡。<pre><code>——来自《500英里》歌曲下方的评论</code></pre></li><li>一个人北漂快十年，成为了我最不想成为的人模狗样，想想租过的地下室，洗了双袜子，4天没干，而我无奈的笑了笑后给穿上了。<pre><code>——来自《李导演》歌曲下方的评论</code></pre></li><li>18岁的时候可以为了一个牵手激动的整夜睡不着觉，20岁的时候会为了一个谎言流泪到深夜，而现在所有的事情都显得那么无关紧要。<pre><code>——来自《消失的光年》歌曲下方的评论</code></pre></li><li>我希望她三十岁没嫁，我也不希望她三十岁没嫁。<pre><code>——来自《三十岁的女人》歌曲下方的评论</code></pre></li><li>一房两人，三餐四季。<pre><code>——来自《给自己的歌》歌曲下方的评论</code></pre></li><li>曾经一个长者对我说，你看男人在外辛苦打拼，其实回家所求无多，只不过想下班回家的时候有口热饭吃，有口热汤喝，有人在家等你，你累的时候有句宽慰的话。所谓的高官厚禄、锦衣玉食、宝马貂裘都比不上这个。我深以为然。<pre><code>——来自《安河桥》歌曲下方的评论</code></pre></li><li>当你老了，我也老了，平行而进，平行而尽。<pre><code>——来自《当你老了》歌曲下方的评论</code></pre></li><li>光阴似箭催人老，日月如移越少年。<pre><code>——来自《少年锦时》歌曲下方的评论</code></pre></li><li>那时候没有手机没有网络，只能通过书信来往，才会有这样的依依不舍，现在人很难感受到那种离别后再无音讯的难舍了。<pre><code>——来自《离别的车站》歌曲下方的评论</code></pre></li><li>若是相互羁绊，不如各奔天涯。<pre><code>——来自《漂洋过海来看你》歌曲下方的评论</code></pre></li><li>女儿出嫁时父亲对她说：“女儿，一定要尊重你的丈夫。你甚至可以崇拜他。但是要记住，你们之间的矛盾和不高兴的事情不要跟我讲，因为你终会原谅他，而我不会。”<pre><code>——来自《囚鸟》歌曲下方的评论</code></pre></li><li>有个姑娘说，你听的歌都太矫情，我说，你一定是爱情里被爱的那一个。<pre><code>——来自《不找了》歌曲下方的评论</code></pre></li><li>等一个不爱自己的人，就像在机场等一艘船。<pre><code>——来自《旧情人，我是时间的新欢》歌曲下方的评论</code></pre></li><li>小时候，暑假都要去农村外婆家，外婆背着我踏过麦田坎儿一口浅井打谁洗衣服，井里好多小虾，20多年过去了，她80岁了，得了抑郁症和老年痴呆，再也背不动我了，还好，我能背得动她。<pre><code>——来自《稻香》歌曲下方的评论</code></pre></li><li>校服是我和她唯一穿过的情侣装，毕业照是我和她唯一的合影。<pre><code>——来自《好久不见》歌曲下方的评论</code></pre></li><li>友情以上，恋人未满，不甘朋友，不敢恋人。<pre><code>——来自《词不达意》歌曲下方的评论</code></pre></li><li>灯泡灭了，我仔细检查下，钨丝并没有断。我重新按下开关，灯泡闪了两下又灭了。我问，你怎么了，不开心么。灯泡回答，等会儿，有个蛾子在窗外看我好久了。我说，那不挺好，有人看得上你。灯泡说，我不是火，别让她看错了，误了人一辈子。<pre><code>——来自《我只在乎你》歌曲下方的评论</code></pre></li><li>今天鼓起勇气给他发了消息，我说了一长串话，他回了个嗯。真羡慕他，这么快放得下，哪像我这么傻。<pre><code>——来自《鸽子》歌曲下方的评论</code></pre></li><li>她的手只有我的手四分之三那么大，可我还是没能抓住。<pre><code>——来自《一生所爱》歌曲下方的评论</code></pre></li><li>年龄越来越大，朋友越来越多，兄弟越来越少。<pre><code>——来自《兄弟》歌曲下方的评论</code></pre></li><li>手机上存满了分手的歌，好像我谈过恋爱似的。<pre><code>——来自《忽然》歌曲下方的评论</code></pre></li><li>你那么擅长安慰他人，一定度过了很多自己安慰自己的日子吧。<pre><code>——来自《给少年的歌》歌曲下方的评论</code></pre></li><li>茕茕白兔，东走西顾，衣不如新，人不如故。<pre><code>——来自《窗外》歌曲下方的评论</code></pre></li><li>直到今天，你仍是我拒绝别人的原因。我今年72岁，我一年洗一次澡，最喜欢老鼠，我会飞，我爱你，我从来不哭。这几件事里，只有一件是真的，你永远不知道是哪件。<pre><code>——来自《最后一首情歌》歌曲下方的评论   </code></pre></li><li>我的愿望是——世界和平！</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;用网易云音乐两年了，有时候是因为神评论喜欢一首歌，都是有故事的人，在一首首有故事的歌，成就了这么多有故事的评论~&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="音乐心声" scheme="http://songit.cn/categories/%E9%9F%B3%E4%B9%90%E5%BF%83%E5%A3%B0/"/>
    
    
      <category term="感悟" scheme="http://songit.cn/tags/%E6%84%9F%E6%82%9F/"/>
    
  </entry>
  
</feed>
